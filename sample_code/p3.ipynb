{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x: int = 10\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "from env import StockTradingEnv\n",
    "from helper_function import check_and_make_directories\n",
    "from models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "from models import DRLAgent, DRLEnsembleAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_and_make_directories([config.TRAINED_MODEL_DIR,\n",
    "                            config.TENSORBOARD_LOG_DIR,\n",
    "                            config.RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.743889</td>\n",
       "      <td>746015200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965560</td>\n",
       "      <td>2.638021</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.743889</td>\n",
       "      <td>2.743889</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>42.406380</td>\n",
       "      <td>6547900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965560</td>\n",
       "      <td>2.638021</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>42.406380</td>\n",
       "      <td>42.406380</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.098143</td>\n",
       "      <td>10955700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965560</td>\n",
       "      <td>2.638021</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15.098143</td>\n",
       "      <td>15.098143</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941109</td>\n",
       "      <td>7010200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965560</td>\n",
       "      <td>2.638021</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>33.941109</td>\n",
       "      <td>33.941109</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>30.950010</td>\n",
       "      <td>7117200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965560</td>\n",
       "      <td>2.638021</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30.950010</td>\n",
       "      <td>30.950010</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>279.649536</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018924</td>\n",
       "      <td>295.342546</td>\n",
       "      <td>263.590737</td>\n",
       "      <td>52.413041</td>\n",
       "      <td>-26.061887</td>\n",
       "      <td>1.802109</td>\n",
       "      <td>279.886563</td>\n",
       "      <td>273.065547</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>12.918872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>188.127823</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.034439</td>\n",
       "      <td>196.031514</td>\n",
       "      <td>182.509933</td>\n",
       "      <td>53.021020</td>\n",
       "      <td>-51.683677</td>\n",
       "      <td>3.333755</td>\n",
       "      <td>188.865415</td>\n",
       "      <td>179.192232</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>12.918872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>44.822735</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.388919</td>\n",
       "      <td>47.973946</td>\n",
       "      <td>43.356943</td>\n",
       "      <td>48.097039</td>\n",
       "      <td>-51.451321</td>\n",
       "      <td>6.514530</td>\n",
       "      <td>45.388064</td>\n",
       "      <td>45.790726</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>12.918872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>35.170811</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.075671</td>\n",
       "      <td>38.390567</td>\n",
       "      <td>32.874518</td>\n",
       "      <td>48.830171</td>\n",
       "      <td>-14.803229</td>\n",
       "      <td>3.412675</td>\n",
       "      <td>35.260424</td>\n",
       "      <td>35.080173</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>12.918872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>39.740002</td>\n",
       "      <td>40.043331</td>\n",
       "      <td>39.513332</td>\n",
       "      <td>37.689484</td>\n",
       "      <td>20509200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.287752</td>\n",
       "      <td>38.777428</td>\n",
       "      <td>36.841923</td>\n",
       "      <td>48.159707</td>\n",
       "      <td>-70.023730</td>\n",
       "      <td>0.711666</td>\n",
       "      <td>38.230161</td>\n",
       "      <td>38.858410</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>12.918872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83897 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic        open        high         low       close  \\\n",
       "                                                                         \n",
       "0     2009-01-02  AAPL    3.067143    3.251429    3.041429    2.743889   \n",
       "0     2009-01-02  AMGN   58.590000   59.080002   57.750000   42.406380   \n",
       "0     2009-01-02   AXP   18.570000   19.520000   18.400000   15.098143   \n",
       "0     2009-01-02    BA   42.799999   45.560001   42.779999   33.941109   \n",
       "0     2009-01-02   CAT   44.910000   46.980000   44.709999   30.950010   \n",
       "...          ...   ...         ...         ...         ...         ...   \n",
       "2892  2020-06-30   UNH  288.570007  296.450012  287.660004  279.649536   \n",
       "2892  2020-06-30     V  191.490005  193.750000  190.160004  188.127823   \n",
       "2892  2020-06-30    VZ   54.919998   55.290001   54.360001   44.822735   \n",
       "2892  2020-06-30   WBA   42.119999   42.580002   41.759998   35.170811   \n",
       "2892  2020-06-30   WMT   39.740002   40.043331   39.513332   37.689484   \n",
       "\n",
       "           volume  day      macd     boll_ub     boll_lb      rsi_30  \\\n",
       "                                                                       \n",
       "0     746015200.0  4.0  0.000000    2.965560    2.638021  100.000000   \n",
       "0       6547900.0  4.0  0.000000    2.965560    2.638021  100.000000   \n",
       "0      10955700.0  4.0  0.000000    2.965560    2.638021  100.000000   \n",
       "0       7010200.0  4.0  0.000000    2.965560    2.638021  100.000000   \n",
       "0       7117200.0  4.0  0.000000    2.965560    2.638021  100.000000   \n",
       "...           ...  ...       ...         ...         ...         ...   \n",
       "2892    2932900.0  1.0 -0.018924  295.342546  263.590737   52.413041   \n",
       "2892    9040100.0  1.0  1.034439  196.031514  182.509933   53.021020   \n",
       "2892   17414800.0  1.0 -0.388919   47.973946   43.356943   48.097039   \n",
       "2892    4782100.0  1.0 -0.075671   38.390567   32.874518   48.830171   \n",
       "2892   20509200.0  1.0 -0.287752   38.777428   36.841923   48.159707   \n",
       "\n",
       "         cci_30       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "                                                                                \n",
       "0     66.666667  100.000000      2.743889      2.743889  39.189999    0.000000  \n",
       "0     66.666667  100.000000     42.406380     42.406380  39.189999    0.000000  \n",
       "0     66.666667  100.000000     15.098143     15.098143  39.189999    0.000000  \n",
       "0     66.666667  100.000000     33.941109     33.941109  39.189999    0.000000  \n",
       "0     66.666667  100.000000     30.950010     30.950010  39.189999    0.000000  \n",
       "...         ...         ...           ...           ...        ...         ...  \n",
       "2892 -26.061887    1.802109    279.886563    273.065547  30.430000   12.918872  \n",
       "2892 -51.683677    3.333755    188.865415    179.192232  30.430000   12.918872  \n",
       "2892 -51.451321    6.514530     45.388064     45.790726  30.430000   12.918872  \n",
       "2892 -14.803229    3.412675     35.260424     35.080173  30.430000   12.918872  \n",
       "2892 -70.023730    0.711666     38.230161     38.858410  30.430000   12.918872  \n",
       "\n",
       "[83897 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_data.csv') # 2009-01-02 to 2020-06-30\n",
    "\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 10000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "env_train, _ = e_train_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "    tmp_path = config.RESULTS_DIR + '/a2c'\n",
    "    new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0.447       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -9.44       |\n",
      "|    reward             | -0.10822373 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.0766      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 75          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0.255       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 3.94        |\n",
      "|    reward             | -0.21044973 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.059       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0.458     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -16.2     |\n",
      "|    reward             | 0.6244044 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.185     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 86          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.7       |\n",
      "|    explained_variance | 0.492       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 19.1        |\n",
      "|    reward             | -0.04559077 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 88         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 0.634      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 26.8       |\n",
      "|    reward             | -1.1216385 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.542      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 89            |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42           |\n",
      "|    explained_variance | 0.206         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -3.17         |\n",
      "|    reward             | 0.00025097415 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.0066        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.6      |\n",
      "|    explained_variance | 0.249      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -7.54      |\n",
      "|    reward             | -0.2986055 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0317     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 43          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | -0.311      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.767       |\n",
      "|    reward             | -0.12357454 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.0124      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0.732       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -2.25       |\n",
      "|    reward             | -0.15002427 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.00684     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | 0.537       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -3.98       |\n",
      "|    reward             | -0.49962428 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00915     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.6      |\n",
      "|    explained_variance | -0.102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -28.4      |\n",
      "|    reward             | 0.32327983 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.502      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.9        |\n",
      "|    explained_variance | -0.632       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -1.89        |\n",
      "|    reward             | 0.0048404722 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.00268      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.5       |\n",
      "|    explained_variance | 0.351       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -1.35       |\n",
      "|    reward             | -0.21867971 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.00646     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45        |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 15.3       |\n",
      "|    reward             | 0.07403447 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.132      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.4      |\n",
      "|    explained_variance | 0.75       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 3.34       |\n",
      "|    reward             | 0.15613702 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.00829    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.7      |\n",
      "|    explained_variance | 0.137      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -3.55      |\n",
      "|    reward             | 0.12556994 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.00955    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.9      |\n",
      "|    explained_variance | 0.459      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | 0.22347163 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.0821     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -46.4      |\n",
      "|    explained_variance | -0.61      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -2.41      |\n",
      "|    reward             | 0.03222586 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 0.00294    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47         |\n",
      "|    explained_variance | -1.07       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -5.64       |\n",
      "|    reward             | -0.02954076 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.5       |\n",
      "|    explained_variance | -0.781      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -2.93       |\n",
      "|    reward             | 0.038968667 |\n",
      "|    std                | 1.25        |\n",
      "|    value_loss         | 0.00953     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.8       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -3.8        |\n",
      "|    reward             | 0.037409164 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.00938     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.1     |\n",
      "|    explained_variance | 0.346     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -8.5      |\n",
      "|    reward             | -0.528188 |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.0757    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.3     |\n",
      "|    explained_variance | -0.00557  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -221      |\n",
      "|    reward             | 0.7405274 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 22.4      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.7       |\n",
      "|    explained_variance | -0.0253     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 3.6         |\n",
      "|    reward             | 0.019142698 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 0.0135      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.3       |\n",
      "|    explained_variance | 0.71        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -3.41       |\n",
      "|    reward             | -0.01433078 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 0.00497     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 94         |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.7      |\n",
      "|    explained_variance | -3.83      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 4.69       |\n",
      "|    reward             | 0.08652754 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 0.045      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50          |\n",
      "|    explained_variance | -1.6         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -3.13        |\n",
      "|    reward             | -0.073424935 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 0.00868      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.3      |\n",
      "|    explained_variance | 0.278      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 7.79       |\n",
      "|    reward             | 0.21734537 |\n",
      "|    std                | 1.37       |\n",
      "|    value_loss         | 0.0397     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.4        |\n",
      "|    explained_variance | -13          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 3.85         |\n",
      "|    reward             | 0.0062520807 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 0.00846      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.2       |\n",
      "|    explained_variance | -1.9        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.275      |\n",
      "|    reward             | 0.020383948 |\n",
      "|    std                | 1.42        |\n",
      "|    value_loss         | 0.000298    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -51.8         |\n",
      "|    explained_variance | 0.49          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | -0.0062150247 |\n",
      "|    std                | 1.44          |\n",
      "|    value_loss         | 0.00121       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.2       |\n",
      "|    explained_variance | 0.282       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -12.9       |\n",
      "|    reward             | -0.12534885 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.5       |\n",
      "|    explained_variance | -0.621      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 8.87        |\n",
      "|    reward             | 0.013027612 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.0306      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.8     |\n",
      "|    explained_variance | 0.287     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 3.88      |\n",
      "|    reward             | 0.2913015 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 0.0442    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.2       |\n",
      "|    explained_variance | -2.68       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | 0.009237531 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.00239     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -53.9      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -0.925     |\n",
      "|    reward             | 0.10346601 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 0.000657   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -54.4      |\n",
      "|    explained_variance | 0.548      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -6.28      |\n",
      "|    reward             | 0.15616186 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 0.0168     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -54.8      |\n",
      "|    explained_variance | 0.112      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | 12.7       |\n",
      "|    reward             | 0.17835557 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 0.0556     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 202        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -55.2      |\n",
      "|    explained_variance | -0.148     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | -14.1      |\n",
      "|    reward             | 0.11156156 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 0.0638     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 207        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -55.4      |\n",
      "|    explained_variance | 0.0887     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -20.5      |\n",
      "|    reward             | 0.33650395 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.8       |\n",
      "|    explained_variance | -3.88       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 4.59        |\n",
      "|    reward             | 0.002055326 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 0.0081      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -56.3      |\n",
      "|    explained_variance | 0.808      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 0.446      |\n",
      "|    reward             | 0.07083527 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.000692   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -56.9      |\n",
      "|    explained_variance | -0.464     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 11.4       |\n",
      "|    reward             | 0.20549114 |\n",
      "|    std                | 1.73       |\n",
      "|    value_loss         | 0.0439     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 228        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -57.3      |\n",
      "|    explained_variance | 0.901      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 0.934      |\n",
      "|    reward             | 0.13452968 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 0.00282    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.7       |\n",
      "|    explained_variance | 0.239       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 18.2        |\n",
      "|    reward             | 0.045098413 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 238        |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -58        |\n",
      "|    explained_variance | -0.0884    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | 6.22       |\n",
      "|    reward             | 0.12811014 |\n",
      "|    std                | 1.79       |\n",
      "|    value_loss         | 0.0259     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.5        |\n",
      "|    explained_variance | 0.489        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -6.64        |\n",
      "|    reward             | 0.0047971304 |\n",
      "|    std                | 1.82         |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.1        |\n",
      "|    explained_variance | 0.92         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | -4.02        |\n",
      "|    reward             | -0.035782073 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 0.00487      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 253       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | 0.847     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -1.84     |\n",
      "|    reward             | 0.0740416 |\n",
      "|    std                | 1.89      |\n",
      "|    value_loss         | 0.00144   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.1       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.283       |\n",
      "|    reward             | 0.022555968 |\n",
      "|    std                | 1.92        |\n",
      "|    value_loss         | 0.000534    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.4       |\n",
      "|    explained_variance | 0.653       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 1.44        |\n",
      "|    reward             | -0.03104563 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 0.00714     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 268        |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -60.6      |\n",
      "|    explained_variance | 0.0636     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | -28.4      |\n",
      "|    reward             | 0.60818535 |\n",
      "|    std                | 1.96       |\n",
      "|    value_loss         | 0.408      |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 53388872.71\n",
      "total_reward: 43388872.71\n",
      "total_cost: 181503.28\n",
      "total_trades: 57692\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.2       |\n",
      "|    explained_variance | -3.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | 5.32        |\n",
      "|    reward             | 0.007555232 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 0.00913     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 96             |\n",
      "|    iterations         | 5400           |\n",
      "|    time_elapsed       | 278            |\n",
      "|    total_timesteps    | 27000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -61.7          |\n",
      "|    explained_variance | 0.612          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5399           |\n",
      "|    policy_loss        | -0.782         |\n",
      "|    reward             | 0.000107431624 |\n",
      "|    std                | 2.04           |\n",
      "|    value_loss         | 0.0059         |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -62.2      |\n",
      "|    explained_variance | 0.733      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -2.75      |\n",
      "|    reward             | 0.13839167 |\n",
      "|    std                | 2.07       |\n",
      "|    value_loss         | 0.0105     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62.5       |\n",
      "|    explained_variance | 0.659       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -4.93       |\n",
      "|    reward             | 0.036216047 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.00977     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62.9       |\n",
      "|    explained_variance | 0.71        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -8.88       |\n",
      "|    reward             | -0.16145991 |\n",
      "|    std                | 2.12        |\n",
      "|    value_loss         | 0.0322      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.1       |\n",
      "|    explained_variance | 0.462       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.741       |\n",
      "|    reward             | 0.017144758 |\n",
      "|    std                | 2.14        |\n",
      "|    value_loss         | 0.000257    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -63.8        |\n",
      "|    explained_variance | 0.474        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -2.39        |\n",
      "|    reward             | -0.010105562 |\n",
      "|    std                | 2.19         |\n",
      "|    value_loss         | 0.00204      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.3        |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | 12.4         |\n",
      "|    reward             | -0.060455084 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 0.0462       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.8       |\n",
      "|    explained_variance | 0.788       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -1.92       |\n",
      "|    reward             | -0.19235134 |\n",
      "|    std                | 2.27        |\n",
      "|    value_loss         | 0.00399     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.3       |\n",
      "|    explained_variance | -0.117      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | -13.4       |\n",
      "|    reward             | -0.04140877 |\n",
      "|    std                | 2.3         |\n",
      "|    value_loss         | 0.0472      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 322        |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -65.6      |\n",
      "|    explained_variance | -0.0669    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 7.25       |\n",
      "|    reward             | 0.32904208 |\n",
      "|    std                | 2.33       |\n",
      "|    value_loss         | 0.0185     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.9       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 2.62        |\n",
      "|    reward             | 0.033316504 |\n",
      "|    std                | 2.35        |\n",
      "|    value_loss         | 0.00171     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 98          |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.6       |\n",
      "|    explained_variance | 0.804       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -0.987      |\n",
      "|    reward             | -0.15481274 |\n",
      "|    std                | 2.41        |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 98           |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.1        |\n",
      "|    explained_variance | 0.544        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -6.3         |\n",
      "|    reward             | -0.030392244 |\n",
      "|    std                | 2.45         |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 98          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.6       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 3.6         |\n",
      "|    reward             | -0.38037294 |\n",
      "|    std                | 2.49        |\n",
      "|    value_loss         | 0.0257      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 345        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -67.9      |\n",
      "|    explained_variance | 0.608      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -7.7       |\n",
      "|    reward             | 0.04649584 |\n",
      "|    std                | 2.52       |\n",
      "|    value_loss         | 0.0168     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 98           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.2        |\n",
      "|    explained_variance | 0.402        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | -28.2        |\n",
      "|    reward             | -0.029865496 |\n",
      "|    std                | 2.55         |\n",
      "|    value_loss         | 0.24         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 98          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68.7       |\n",
      "|    explained_variance | 0.198       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | 5.29        |\n",
      "|    reward             | 0.009332352 |\n",
      "|    std                | 2.59        |\n",
      "|    value_loss         | 0.00615     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 98          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.3       |\n",
      "|    explained_variance | 0.818       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 3.45        |\n",
      "|    reward             | 0.064159915 |\n",
      "|    std                | 2.64        |\n",
      "|    value_loss         | 0.00359     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 363       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0.865     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -7.92     |\n",
      "|    reward             | 0.0029962 |\n",
      "|    std                | 2.69      |\n",
      "|    value_loss         | 0.0144    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 99          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 368         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70.3       |\n",
      "|    explained_variance | 0.633       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -0.0961     |\n",
      "|    reward             | 0.017247692 |\n",
      "|    std                | 2.73        |\n",
      "|    value_loss         | 0.00355     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -70.7      |\n",
      "|    explained_variance | 0.18       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 10.4       |\n",
      "|    reward             | -0.3794706 |\n",
      "|    std                | 2.78       |\n",
      "|    value_loss         | 0.0353     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 377       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | 0.152     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 28.5      |\n",
      "|    reward             | -0.330751 |\n",
      "|    std                | 2.81      |\n",
      "|    value_loss         | 0.184     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.6     |\n",
      "|    explained_variance | 0.411     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -1.85     |\n",
      "|    reward             | 0.0398625 |\n",
      "|    std                | 2.86      |\n",
      "|    value_loss         | 0.00119   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 387        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72.2      |\n",
      "|    explained_variance | -0.0622    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | 4.1        |\n",
      "|    reward             | 0.08528401 |\n",
      "|    std                | 2.92       |\n",
      "|    value_loss         | 0.00616    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 99          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 391         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72.7       |\n",
      "|    explained_variance | 0.78        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -0.384      |\n",
      "|    reward             | -0.03730299 |\n",
      "|    std                | 2.97        |\n",
      "|    value_loss         | 0.000924    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 396        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -73.1      |\n",
      "|    explained_variance | 0.723      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 18.9       |\n",
      "|    reward             | 0.21604936 |\n",
      "|    std                | 3.02       |\n",
      "|    value_loss         | 0.0824     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 99          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 401         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -73.6       |\n",
      "|    explained_variance | 0.525       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -9.57       |\n",
      "|    reward             | -0.05992548 |\n",
      "|    std                | 3.07        |\n",
      "|    value_loss         | 0.0276      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 405        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -73.9      |\n",
      "|    explained_variance | 0.215      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 8.05       |\n",
      "|    reward             | 0.26123682 |\n",
      "|    std                | 3.1        |\n",
      "|    value_loss         | 0.0396     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 99           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 410          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.5        |\n",
      "|    explained_variance | -2.56        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -2.61        |\n",
      "|    reward             | 0.0001223547 |\n",
      "|    std                | 3.17         |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 99          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 415         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -75.1       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 0.855       |\n",
      "|    reward             | -0.06813498 |\n",
      "|    std                | 3.23        |\n",
      "|    value_loss         | 0.000297    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 99           |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 420          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.7        |\n",
      "|    explained_variance | 0.309        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.559        |\n",
      "|    reward             | -0.025816094 |\n",
      "|    std                | 3.3          |\n",
      "|    value_loss         | 0.000688     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 424        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -76.1      |\n",
      "|    explained_variance | 0.771      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 11.5       |\n",
      "|    reward             | 0.06425442 |\n",
      "|    std                | 3.35       |\n",
      "|    value_loss         | 0.0229     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 429        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -76.4      |\n",
      "|    explained_variance | 0.349      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 2.63       |\n",
      "|    reward             | -0.8269296 |\n",
      "|    std                | 3.39       |\n",
      "|    value_loss         | 0.0334     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 434         |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.7       |\n",
      "|    explained_variance | 0.0998      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -0.75       |\n",
      "|    reward             | 0.008509874 |\n",
      "|    std                | 3.41        |\n",
      "|    value_loss         | 0.000151    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -77.3       |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 7.07        |\n",
      "|    reward             | 0.019541034 |\n",
      "|    std                | 3.49        |\n",
      "|    value_loss         | 0.00898     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 443         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -77.8       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 5.98        |\n",
      "|    reward             | -0.03163317 |\n",
      "|    std                | 3.56        |\n",
      "|    value_loss         | 0.0065      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 100          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.4        |\n",
      "|    explained_variance | -2.02        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -2.13        |\n",
      "|    reward             | -0.055586956 |\n",
      "|    std                | 3.62         |\n",
      "|    value_loss         | 0.00626      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -78.9      |\n",
      "|    explained_variance | -0.988     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | 0.348      |\n",
      "|    reward             | 0.10844653 |\n",
      "|    std                | 3.68       |\n",
      "|    value_loss         | 0.000625   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 457        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -79.1      |\n",
      "|    explained_variance | 0.782      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 5.64       |\n",
      "|    reward             | 0.06163235 |\n",
      "|    std                | 3.72       |\n",
      "|    value_loss         | 0.00761    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 461         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -79.5       |\n",
      "|    explained_variance | 0.536       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -2.99       |\n",
      "|    reward             | 0.014518618 |\n",
      "|    std                | 3.76        |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80         |\n",
      "|    explained_variance | -0.0508     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 13          |\n",
      "|    reward             | 0.020067362 |\n",
      "|    std                | 3.83        |\n",
      "|    value_loss         | 0.0296      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 471        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -80.6      |\n",
      "|    explained_variance | 0.786      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 5.61       |\n",
      "|    reward             | 0.03679417 |\n",
      "|    std                | 3.91       |\n",
      "|    value_loss         | 0.00696    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 475         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -81.1       |\n",
      "|    explained_variance | -0.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 1.08        |\n",
      "|    reward             | -0.04308653 |\n",
      "|    std                | 3.97        |\n",
      "|    value_loss         | 0.00676     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 480         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -81.6       |\n",
      "|    explained_variance | 0.74        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -2.94       |\n",
      "|    reward             | 0.056791242 |\n",
      "|    std                | 4.04        |\n",
      "|    value_loss         | 0.00261     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 485       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.8     |\n",
      "|    explained_variance | 0.94      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 4.34      |\n",
      "|    reward             | 0.3569065 |\n",
      "|    std                | 4.07      |\n",
      "|    value_loss         | 0.00948   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 489         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -82.2       |\n",
      "|    explained_variance | -2.14       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.518       |\n",
      "|    reward             | 0.005610988 |\n",
      "|    std                | 4.13        |\n",
      "|    value_loss         | 0.000124    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 494         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -82.8       |\n",
      "|    explained_variance | -0.0555     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -8.8        |\n",
      "|    reward             | -0.01628442 |\n",
      "|    std                | 4.22        |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 499       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -83.4     |\n",
      "|    explained_variance | 0.898     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 8.08      |\n",
      "|    reward             | 0.0999395 |\n",
      "|    std                | 4.3       |\n",
      "|    value_loss         | 0.0103    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 10200       |\n",
      "|    time_elapsed       | 503         |\n",
      "|    total_timesteps    | 51000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83.9       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | -0.0636     |\n",
      "|    reward             | 0.022608904 |\n",
      "|    std                | 4.38        |\n",
      "|    value_loss         | 0.000446    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -84.3       |\n",
      "|    explained_variance | 0.66        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -16.8       |\n",
      "|    reward             | -0.05871712 |\n",
      "|    std                | 4.44        |\n",
      "|    value_loss         | 0.0491      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 512       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.6     |\n",
      "|    explained_variance | 0.314     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -37.1     |\n",
      "|    reward             | 0.6497989 |\n",
      "|    std                | 4.49      |\n",
      "|    value_loss         | 0.627     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 517         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -85.1       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 3.99        |\n",
      "|    reward             | 0.033832423 |\n",
      "|    std                | 4.57        |\n",
      "|    value_loss         | 0.00261     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 10600        |\n",
      "|    time_elapsed       | 522          |\n",
      "|    total_timesteps    | 53000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -85.7        |\n",
      "|    explained_variance | 0.445        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | -0.0374      |\n",
      "|    reward             | -0.019316819 |\n",
      "|    std                | 4.65         |\n",
      "|    value_loss         | 0.000413     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 10700        |\n",
      "|    time_elapsed       | 526          |\n",
      "|    total_timesteps    | 53500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -86.1        |\n",
      "|    explained_variance | 0.221        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | 7.17         |\n",
      "|    reward             | -0.008390224 |\n",
      "|    std                | 4.73         |\n",
      "|    value_loss         | 0.0122       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 10800        |\n",
      "|    time_elapsed       | 531          |\n",
      "|    total_timesteps    | 54000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -86.5        |\n",
      "|    explained_variance | -0.416       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | -9.9         |\n",
      "|    reward             | -0.018199446 |\n",
      "|    std                | 4.8          |\n",
      "|    value_loss         | 0.0167       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 536          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -86.9        |\n",
      "|    explained_variance | 0.642        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | -9.71        |\n",
      "|    reward             | -0.008200416 |\n",
      "|    std                | 4.86         |\n",
      "|    value_loss         | 0.0216       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 33722611.89\n",
      "total_reward: 23722611.89\n",
      "total_cost: 350599.59\n",
      "total_trades: 71760\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 541          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -87.2        |\n",
      "|    explained_variance | -3.33        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | -0.364       |\n",
      "|    reward             | -0.003679821 |\n",
      "|    std                | 4.9          |\n",
      "|    value_loss         | 9.99e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 11100        |\n",
      "|    time_elapsed       | 545          |\n",
      "|    total_timesteps    | 55500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -87.7        |\n",
      "|    explained_variance | 0.704        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | 4.14         |\n",
      "|    reward             | 0.0014211042 |\n",
      "|    std                | 5            |\n",
      "|    value_loss         | 0.00262      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 11200       |\n",
      "|    time_elapsed       | 550         |\n",
      "|    total_timesteps    | 56000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -88.2       |\n",
      "|    explained_variance | 0.372       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | -3.6        |\n",
      "|    reward             | 0.009752876 |\n",
      "|    std                | 5.08        |\n",
      "|    value_loss         | 0.00297     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -88.7       |\n",
      "|    explained_variance | 0.662       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | 15.8        |\n",
      "|    reward             | 0.121339664 |\n",
      "|    std                | 5.16        |\n",
      "|    value_loss         | 0.0456      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 11400       |\n",
      "|    time_elapsed       | 559         |\n",
      "|    total_timesteps    | 57000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -89.2       |\n",
      "|    explained_variance | 0.0159      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | -2.97       |\n",
      "|    reward             | -0.07304853 |\n",
      "|    std                | 5.25        |\n",
      "|    value_loss         | 0.00298     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 11500       |\n",
      "|    time_elapsed       | 564         |\n",
      "|    total_timesteps    | 57500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -89.5       |\n",
      "|    explained_variance | 0.423       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 51.1        |\n",
      "|    reward             | -0.33161506 |\n",
      "|    std                | 5.31        |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 11600        |\n",
      "|    time_elapsed       | 569          |\n",
      "|    total_timesteps    | 58000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -89.7        |\n",
      "|    explained_variance | 0.0307       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | 4.35         |\n",
      "|    reward             | -0.007808413 |\n",
      "|    std                | 5.35         |\n",
      "|    value_loss         | 0.0032       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 11700      |\n",
      "|    time_elapsed       | 574        |\n",
      "|    total_timesteps    | 58500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -90.3      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11699      |\n",
      "|    policy_loss        | 2.14       |\n",
      "|    reward             | 0.19554049 |\n",
      "|    std                | 5.46       |\n",
      "|    value_loss         | 0.000734   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 11800        |\n",
      "|    time_elapsed       | 579          |\n",
      "|    total_timesteps    | 59000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -90.7        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | 3.71         |\n",
      "|    reward             | -0.025777865 |\n",
      "|    std                | 5.55         |\n",
      "|    value_loss         | 0.00218      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 11900      |\n",
      "|    time_elapsed       | 584        |\n",
      "|    total_timesteps    | 59500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -91.3      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | -2.45      |\n",
      "|    reward             | 0.20123872 |\n",
      "|    std                | 5.65       |\n",
      "|    value_loss         | 0.00214    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 12000      |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 60000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -91.8      |\n",
      "|    explained_variance | 0.633      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11999      |\n",
      "|    policy_loss        | -4.5       |\n",
      "|    reward             | 0.06348478 |\n",
      "|    std                | 5.75       |\n",
      "|    value_loss         | 0.00256    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 12100      |\n",
      "|    time_elapsed       | 593        |\n",
      "|    total_timesteps    | 60500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -92.1      |\n",
      "|    explained_variance | 0.63       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12099      |\n",
      "|    policy_loss        | 19.3       |\n",
      "|    reward             | 0.19077651 |\n",
      "|    std                | 5.81       |\n",
      "|    value_loss         | 0.0631     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 599       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92.4     |\n",
      "|    explained_variance | -3.27     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 1.72      |\n",
      "|    reward             | 0.0111534 |\n",
      "|    std                | 5.87      |\n",
      "|    value_loss         | 0.000731  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 12300        |\n",
      "|    time_elapsed       | 604          |\n",
      "|    total_timesteps    | 61500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -92.8        |\n",
      "|    explained_variance | 0.441        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | -4.39        |\n",
      "|    reward             | -0.120646656 |\n",
      "|    std                | 5.97         |\n",
      "|    value_loss         | 0.00443      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 12400      |\n",
      "|    time_elapsed       | 609        |\n",
      "|    total_timesteps    | 62000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -93.3      |\n",
      "|    explained_variance | 0.272      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12399      |\n",
      "|    policy_loss        | 10.3       |\n",
      "|    reward             | 0.07055407 |\n",
      "|    std                | 6.06       |\n",
      "|    value_loss         | 0.0153     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 12500       |\n",
      "|    time_elapsed       | 614         |\n",
      "|    total_timesteps    | 62500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -93.7       |\n",
      "|    explained_variance | 0.614       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12499       |\n",
      "|    policy_loss        | -7.74       |\n",
      "|    reward             | 0.095346615 |\n",
      "|    std                | 6.15        |\n",
      "|    value_loss         | 0.00846     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 12600        |\n",
      "|    time_elapsed       | 618          |\n",
      "|    total_timesteps    | 63000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -94.2        |\n",
      "|    explained_variance | 0.746        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12599        |\n",
      "|    policy_loss        | 7.19         |\n",
      "|    reward             | -0.100330345 |\n",
      "|    std                | 6.24         |\n",
      "|    value_loss         | 0.00641      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 623         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -94.4       |\n",
      "|    explained_variance | 0.0806      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | 11.3        |\n",
      "|    reward             | -0.33832103 |\n",
      "|    std                | 6.31        |\n",
      "|    value_loss         | 0.0172      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 12800        |\n",
      "|    time_elapsed       | 628          |\n",
      "|    total_timesteps    | 64000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -94.8        |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12799        |\n",
      "|    policy_loss        | -8.17        |\n",
      "|    reward             | -0.063315205 |\n",
      "|    std                | 6.4          |\n",
      "|    value_loss         | 0.0096       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 632          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -95.3        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | -2.44        |\n",
      "|    reward             | 0.0049452386 |\n",
      "|    std                | 6.49         |\n",
      "|    value_loss         | 0.00151      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 13000       |\n",
      "|    time_elapsed       | 637         |\n",
      "|    total_timesteps    | 65000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -95.7       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | -3.57       |\n",
      "|    reward             | 0.030144392 |\n",
      "|    std                | 6.59        |\n",
      "|    value_loss         | 0.00212     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 13100      |\n",
      "|    time_elapsed       | 642        |\n",
      "|    total_timesteps    | 65500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -96.1      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13099      |\n",
      "|    policy_loss        | -5.3       |\n",
      "|    reward             | 0.12773472 |\n",
      "|    std                | 6.68       |\n",
      "|    value_loss         | 0.00416    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 13200      |\n",
      "|    time_elapsed       | 646        |\n",
      "|    total_timesteps    | 66000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -96.5      |\n",
      "|    explained_variance | 0.823      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13199      |\n",
      "|    policy_loss        | -10.4      |\n",
      "|    reward             | 0.15085073 |\n",
      "|    std                | 6.77       |\n",
      "|    value_loss         | 0.0194     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 651         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.7       |\n",
      "|    explained_variance | 0.322       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | 43.9        |\n",
      "|    reward             | -0.08547314 |\n",
      "|    std                | 6.83        |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 13400       |\n",
      "|    time_elapsed       | 656         |\n",
      "|    total_timesteps    | 67000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -97.2       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | -1.98       |\n",
      "|    reward             | -0.02458181 |\n",
      "|    std                | 6.93        |\n",
      "|    value_loss         | 0.000667    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 13500        |\n",
      "|    time_elapsed       | 660          |\n",
      "|    total_timesteps    | 67500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -97.6        |\n",
      "|    explained_variance | 0.557        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | -5.37        |\n",
      "|    reward             | -0.030685877 |\n",
      "|    std                | 7.03         |\n",
      "|    value_loss         | 0.00551      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 665         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98.1       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | -1.93       |\n",
      "|    reward             | -0.17450246 |\n",
      "|    std                | 7.15        |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 13700        |\n",
      "|    time_elapsed       | 670          |\n",
      "|    total_timesteps    | 68500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -98.5        |\n",
      "|    explained_variance | -0.303       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -10.7        |\n",
      "|    reward             | -0.064046636 |\n",
      "|    std                | 7.27         |\n",
      "|    value_loss         | 0.0129       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 674         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98.9       |\n",
      "|    explained_variance | 0.584       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | -12.5       |\n",
      "|    reward             | -0.57791173 |\n",
      "|    std                | 7.37        |\n",
      "|    value_loss         | 0.0171      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 13900         |\n",
      "|    time_elapsed       | 679           |\n",
      "|    total_timesteps    | 69500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -99.1         |\n",
      "|    explained_variance | -0.249        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13899         |\n",
      "|    policy_loss        | 3.66          |\n",
      "|    reward             | -0.0012706598 |\n",
      "|    std                | 7.41          |\n",
      "|    value_loss         | 0.00156       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 14000      |\n",
      "|    time_elapsed       | 684        |\n",
      "|    total_timesteps    | 70000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -99.6      |\n",
      "|    explained_variance | 0.886      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13999      |\n",
      "|    policy_loss        | 4.17       |\n",
      "|    reward             | 0.01699807 |\n",
      "|    std                | 7.54       |\n",
      "|    value_loss         | 0.00219    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 688         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -100        |\n",
      "|    explained_variance | 0.0469      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 0.881       |\n",
      "|    reward             | -0.18266681 |\n",
      "|    std                | 7.66        |\n",
      "|    value_loss         | 0.00367     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 14200       |\n",
      "|    time_elapsed       | 693         |\n",
      "|    total_timesteps    | 71000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | -0.399      |\n",
      "|    reward             | 0.043040697 |\n",
      "|    std                | 7.78        |\n",
      "|    value_loss         | 0.00121     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 14300        |\n",
      "|    time_elapsed       | 698          |\n",
      "|    total_timesteps    | 71500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -101         |\n",
      "|    explained_variance | 0.697        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | 2.38         |\n",
      "|    reward             | -0.016523682 |\n",
      "|    std                | 7.89         |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 702          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -101         |\n",
      "|    explained_variance | 0.645        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | -1.32        |\n",
      "|    reward             | -0.019952785 |\n",
      "|    std                | 7.99         |\n",
      "|    value_loss         | 0.0127       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 707          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -102         |\n",
      "|    explained_variance | 0.575        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | 0.0224       |\n",
      "|    reward             | 0.0052399626 |\n",
      "|    std                | 8.05         |\n",
      "|    value_loss         | 0.00033      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 712       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | 0.699     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 7.87      |\n",
      "|    reward             | 0.2366695 |\n",
      "|    std                | 8.19      |\n",
      "|    value_loss         | 0.00901   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 716         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -102        |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 2.08        |\n",
      "|    reward             | 0.048215073 |\n",
      "|    std                | 8.33        |\n",
      "|    value_loss         | 0.000638    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 14800      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 74000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -103       |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14799      |\n",
      "|    policy_loss        | -1.73      |\n",
      "|    reward             | 0.03545081 |\n",
      "|    std                | 8.48       |\n",
      "|    value_loss         | 0.000401   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 14900       |\n",
      "|    time_elapsed       | 726         |\n",
      "|    total_timesteps    | 74500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -104        |\n",
      "|    explained_variance | 0.676       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | -15.8       |\n",
      "|    reward             | -0.10393317 |\n",
      "|    std                | 8.64        |\n",
      "|    value_loss         | 0.0293      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 15000       |\n",
      "|    time_elapsed       | 730         |\n",
      "|    total_timesteps    | 75000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -104        |\n",
      "|    explained_variance | 0.325       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 30.7        |\n",
      "|    reward             | -0.24740124 |\n",
      "|    std                | 8.72        |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -104        |\n",
      "|    explained_variance | 0.33        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | 0.017372154 |\n",
      "|    std                | 8.83        |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 15200       |\n",
      "|    time_elapsed       | 740         |\n",
      "|    total_timesteps    | 76000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -105        |\n",
      "|    explained_variance | 0.173       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15199       |\n",
      "|    policy_loss        | 0.417       |\n",
      "|    reward             | 0.012045809 |\n",
      "|    std                | 8.98        |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 15300      |\n",
      "|    time_elapsed       | 744        |\n",
      "|    total_timesteps    | 76500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -105       |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15299      |\n",
      "|    policy_loss        | -1.98      |\n",
      "|    reward             | 0.19840108 |\n",
      "|    std                | 9.15       |\n",
      "|    value_loss         | 0.00099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 15400      |\n",
      "|    time_elapsed       | 749        |\n",
      "|    total_timesteps    | 77000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | 0.508      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15399      |\n",
      "|    policy_loss        | 10.4       |\n",
      "|    reward             | -0.3489279 |\n",
      "|    std                | 9.27       |\n",
      "|    value_loss         | 0.0161     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 15500      |\n",
      "|    time_elapsed       | 754        |\n",
      "|    total_timesteps    | 77500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | 0.924      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15499      |\n",
      "|    policy_loss        | -14.6      |\n",
      "|    reward             | 0.24116819 |\n",
      "|    std                | 9.41       |\n",
      "|    value_loss         | 0.0202     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 15600      |\n",
      "|    time_elapsed       | 758        |\n",
      "|    total_timesteps    | 78000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | 0.651      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15599      |\n",
      "|    policy_loss        | 19.7       |\n",
      "|    reward             | -0.2659636 |\n",
      "|    std                | 9.48       |\n",
      "|    value_loss         | 0.0403     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 763          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -107         |\n",
      "|    explained_variance | -0.413       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | 10.4         |\n",
      "|    reward             | -0.044314813 |\n",
      "|    std                | 9.62         |\n",
      "|    value_loss         | 0.0127       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 15800      |\n",
      "|    time_elapsed       | 768        |\n",
      "|    total_timesteps    | 79000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -107       |\n",
      "|    explained_variance | 0.828      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15799      |\n",
      "|    policy_loss        | 6.15       |\n",
      "|    reward             | 0.14572263 |\n",
      "|    std                | 9.8        |\n",
      "|    value_loss         | 0.00398    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 15900       |\n",
      "|    time_elapsed       | 772         |\n",
      "|    total_timesteps    | 79500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -108        |\n",
      "|    explained_variance | 0.735       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | -3.19       |\n",
      "|    reward             | -0.02623521 |\n",
      "|    std                | 9.98        |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 777        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -108       |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | 0.395      |\n",
      "|    reward             | 0.07628784 |\n",
      "|    std                | 10.1       |\n",
      "|    value_loss         | 0.00356    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 16100        |\n",
      "|    time_elapsed       | 782          |\n",
      "|    total_timesteps    | 80500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -109         |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16099        |\n",
      "|    policy_loss        | 5.44         |\n",
      "|    reward             | 0.0026646175 |\n",
      "|    std                | 10.3         |\n",
      "|    value_loss         | 0.0045       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 787       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -109      |\n",
      "|    explained_variance | 0.42      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 40        |\n",
      "|    reward             | 0.3909168 |\n",
      "|    std                | 10.4      |\n",
      "|    value_loss         | 0.24      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 16300       |\n",
      "|    time_elapsed       | 791         |\n",
      "|    total_timesteps    | 81500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -109        |\n",
      "|    explained_variance | 0.0679      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | -0.872      |\n",
      "|    reward             | 0.033941466 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.000249    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 16400      |\n",
      "|    time_elapsed       | 796        |\n",
      "|    total_timesteps    | 82000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -110       |\n",
      "|    explained_variance | -0.0146    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16399      |\n",
      "|    policy_loss        | 10.2       |\n",
      "|    reward             | 0.11591041 |\n",
      "|    std                | 10.7       |\n",
      "|    value_loss         | 0.013      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 16500      |\n",
      "|    time_elapsed       | 801        |\n",
      "|    total_timesteps    | 82500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -110       |\n",
      "|    explained_variance | -3.62      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | -1.79      |\n",
      "|    reward             | 0.21623343 |\n",
      "|    std                | 10.9       |\n",
      "|    value_loss         | 0.00203    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 805        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -111       |\n",
      "|    explained_variance | -1.9       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | -12.3      |\n",
      "|    reward             | -0.0376507 |\n",
      "|    std                | 11.1       |\n",
      "|    value_loss         | 0.0147     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 810       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -111      |\n",
      "|    explained_variance | 0.894     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -23.5     |\n",
      "|    reward             | 0.3115095 |\n",
      "|    std                | 11.2      |\n",
      "|    value_loss         | 0.0541    |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 35778856.92\n",
      "total_reward: 25778856.92\n",
      "total_cost: 436284.87\n",
      "total_trades: 74650\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 16800         |\n",
      "|    time_elapsed       | 815           |\n",
      "|    total_timesteps    | 84000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -111          |\n",
      "|    explained_variance | 0.167         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16799         |\n",
      "|    policy_loss        | 0.0884        |\n",
      "|    reward             | -0.0014561771 |\n",
      "|    std                | 11.3          |\n",
      "|    value_loss         | 0.000224      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 820         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -112        |\n",
      "|    explained_variance | 0.734       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | -0.444      |\n",
      "|    reward             | 0.006318462 |\n",
      "|    std                | 11.5        |\n",
      "|    value_loss         | 0.000285    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 17000       |\n",
      "|    time_elapsed       | 825         |\n",
      "|    total_timesteps    | 85000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -112        |\n",
      "|    explained_variance | 0.781       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | 15.1        |\n",
      "|    reward             | -0.04649041 |\n",
      "|    std                | 11.7        |\n",
      "|    value_loss         | 0.0187      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 831           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -113          |\n",
      "|    explained_variance | 0.899         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | -9.04         |\n",
      "|    reward             | -0.0018589578 |\n",
      "|    std                | 11.9          |\n",
      "|    value_loss         | 0.00701       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 836          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -113         |\n",
      "|    explained_variance | 0.248        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | -4.09        |\n",
      "|    reward             | -0.041431203 |\n",
      "|    std                | 12.1         |\n",
      "|    value_loss         | 0.00176      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 17300       |\n",
      "|    time_elapsed       | 841         |\n",
      "|    total_timesteps    | 86500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | -20.8       |\n",
      "|    reward             | -0.03633075 |\n",
      "|    std                | 12.2        |\n",
      "|    value_loss         | 0.0332      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 17400      |\n",
      "|    time_elapsed       | 846        |\n",
      "|    total_timesteps    | 87000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -114       |\n",
      "|    explained_variance | 0.164      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17399      |\n",
      "|    policy_loss        | -4.4       |\n",
      "|    reward             | 0.01522442 |\n",
      "|    std                | 12.4       |\n",
      "|    value_loss         | 0.00173    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 17500      |\n",
      "|    time_elapsed       | 852        |\n",
      "|    total_timesteps    | 87500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -114       |\n",
      "|    explained_variance | 0.295      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17499      |\n",
      "|    policy_loss        | 2.43       |\n",
      "|    reward             | 0.06331221 |\n",
      "|    std                | 12.6       |\n",
      "|    value_loss         | 0.00224    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 17600        |\n",
      "|    time_elapsed       | 857          |\n",
      "|    total_timesteps    | 88000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -115         |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | -5.33        |\n",
      "|    reward             | -0.056605488 |\n",
      "|    std                | 12.8         |\n",
      "|    value_loss         | 0.00444      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 17700       |\n",
      "|    time_elapsed       | 862         |\n",
      "|    total_timesteps    | 88500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -115        |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | -15.5       |\n",
      "|    reward             | -0.00936007 |\n",
      "|    std                | 13          |\n",
      "|    value_loss         | 0.0178      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 17800        |\n",
      "|    time_elapsed       | 867          |\n",
      "|    total_timesteps    | 89000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -116         |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17799        |\n",
      "|    policy_loss        | 4.69         |\n",
      "|    reward             | -0.038452644 |\n",
      "|    std                | 13.2         |\n",
      "|    value_loss         | 0.00214      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 17900      |\n",
      "|    time_elapsed       | 873        |\n",
      "|    total_timesteps    | 89500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -116       |\n",
      "|    explained_variance | 0.36       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17899      |\n",
      "|    policy_loss        | -80.6      |\n",
      "|    reward             | 0.12220696 |\n",
      "|    std                | 13.3       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 18000      |\n",
      "|    time_elapsed       | 878        |\n",
      "|    total_timesteps    | 90000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -116       |\n",
      "|    explained_variance | 0.222      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17999      |\n",
      "|    policy_loss        | -0.478     |\n",
      "|    reward             | 0.01923186 |\n",
      "|    std                | 13.5       |\n",
      "|    value_loss         | 5.67e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 18100       |\n",
      "|    time_elapsed       | 883         |\n",
      "|    total_timesteps    | 90500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -117        |\n",
      "|    explained_variance | 0.368       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | -5.37       |\n",
      "|    reward             | 0.021664092 |\n",
      "|    std                | 13.7        |\n",
      "|    value_loss         | 0.00334     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 18200      |\n",
      "|    time_elapsed       | 888        |\n",
      "|    total_timesteps    | 91000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -117       |\n",
      "|    explained_variance | -0.552     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18199      |\n",
      "|    policy_loss        | -16.5      |\n",
      "|    reward             | 0.08479625 |\n",
      "|    std                | 14         |\n",
      "|    value_loss         | 0.0268     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 18300       |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 91500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 3.8         |\n",
      "|    reward             | -0.13097408 |\n",
      "|    std                | 14.2        |\n",
      "|    value_loss         | 0.00212     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 899         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | 0.646       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | -4.9        |\n",
      "|    reward             | -0.22622323 |\n",
      "|    std                | 14.4        |\n",
      "|    value_loss         | 0.00884     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 904       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -119      |\n",
      "|    explained_variance | 0.767     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -38.1     |\n",
      "|    reward             | 1.8190408 |\n",
      "|    std                | 14.6      |\n",
      "|    value_loss         | 0.177     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 18600       |\n",
      "|    time_elapsed       | 909         |\n",
      "|    total_timesteps    | 93000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -119        |\n",
      "|    explained_variance | -0.471      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | 9.5         |\n",
      "|    reward             | 0.002497675 |\n",
      "|    std                | 14.8        |\n",
      "|    value_loss         | 0.00694     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 18700       |\n",
      "|    time_elapsed       | 914         |\n",
      "|    total_timesteps    | 93500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -120        |\n",
      "|    explained_variance | -1.09       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | 1.87        |\n",
      "|    reward             | 0.076079704 |\n",
      "|    std                | 15.1        |\n",
      "|    value_loss         | 0.00332     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 18800      |\n",
      "|    time_elapsed       | 919        |\n",
      "|    total_timesteps    | 94000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -120       |\n",
      "|    explained_variance | 0.929      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18799      |\n",
      "|    policy_loss        | 13.8       |\n",
      "|    reward             | 0.06460625 |\n",
      "|    std                | 15.4       |\n",
      "|    value_loss         | 0.0144     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 18900      |\n",
      "|    time_elapsed       | 924        |\n",
      "|    total_timesteps    | 94500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -121       |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18899      |\n",
      "|    policy_loss        | 1.52       |\n",
      "|    reward             | -0.0647961 |\n",
      "|    std                | 15.7       |\n",
      "|    value_loss         | 0.000222   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 930       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -121      |\n",
      "|    explained_variance | 0.72      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 8.64      |\n",
      "|    reward             | 0.0909208 |\n",
      "|    std                | 16        |\n",
      "|    value_loss         | 0.00855   |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 19100         |\n",
      "|    time_elapsed       | 935           |\n",
      "|    total_timesteps    | 95500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -122          |\n",
      "|    explained_variance | -24.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19099         |\n",
      "|    policy_loss        | -2.84         |\n",
      "|    reward             | 0.00028074603 |\n",
      "|    std                | 16.1          |\n",
      "|    value_loss         | 0.000993      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 19200         |\n",
      "|    time_elapsed       | 940           |\n",
      "|    total_timesteps    | 96000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -122          |\n",
      "|    explained_variance | 0.997         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19199         |\n",
      "|    policy_loss        | 1.54          |\n",
      "|    reward             | -0.0051463344 |\n",
      "|    std                | 16.4          |\n",
      "|    value_loss         | 0.000158      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 19300        |\n",
      "|    time_elapsed       | 945          |\n",
      "|    total_timesteps    | 96500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -123         |\n",
      "|    explained_variance | 0.135        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19299        |\n",
      "|    policy_loss        | -7.15        |\n",
      "|    reward             | -0.032503173 |\n",
      "|    std                | 16.8         |\n",
      "|    value_loss         | 0.00402      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 19400      |\n",
      "|    time_elapsed       | 950        |\n",
      "|    total_timesteps    | 97000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -123       |\n",
      "|    explained_variance | 0.862      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19399      |\n",
      "|    policy_loss        | 7.12       |\n",
      "|    reward             | 0.23336034 |\n",
      "|    std                | 17.1       |\n",
      "|    value_loss         | 0.00381    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 19500       |\n",
      "|    time_elapsed       | 955         |\n",
      "|    total_timesteps    | 97500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | 0.678       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -2.56       |\n",
      "|    reward             | 0.009928111 |\n",
      "|    std                | 17.5        |\n",
      "|    value_loss         | 0.000858    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 19600       |\n",
      "|    time_elapsed       | 960         |\n",
      "|    total_timesteps    | 98000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | -6.4        |\n",
      "|    reward             | -0.02892298 |\n",
      "|    std                | 17.7        |\n",
      "|    value_loss         | 0.00354     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 19700         |\n",
      "|    time_elapsed       | 966           |\n",
      "|    total_timesteps    | 98500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -125          |\n",
      "|    explained_variance | -2.38         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19699         |\n",
      "|    policy_loss        | 5.67          |\n",
      "|    reward             | -0.0059502507 |\n",
      "|    std                | 17.9          |\n",
      "|    value_loss         | 0.00219       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 19800       |\n",
      "|    time_elapsed       | 971         |\n",
      "|    total_timesteps    | 99000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -125        |\n",
      "|    explained_variance | 0.214       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | 3.76        |\n",
      "|    reward             | 0.024832845 |\n",
      "|    std                | 18.3        |\n",
      "|    value_loss         | 0.0025      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 976         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -126        |\n",
      "|    explained_variance | -0.0445     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -2.81       |\n",
      "|    reward             | 0.044172905 |\n",
      "|    std                | 18.7        |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 981         |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -126        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 4.55        |\n",
      "|    reward             | -0.18168157 |\n",
      "|    std                | 19.1        |\n",
      "|    value_loss         | 0.00166     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20100       |\n",
      "|    time_elapsed       | 986         |\n",
      "|    total_timesteps    | 100500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -127        |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20099       |\n",
      "|    policy_loss        | -4.32       |\n",
      "|    reward             | 0.081247136 |\n",
      "|    std                | 19.4        |\n",
      "|    value_loss         | 0.00147     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 20200        |\n",
      "|    time_elapsed       | 991          |\n",
      "|    total_timesteps    | 101000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -127         |\n",
      "|    explained_variance | 0.572        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20199        |\n",
      "|    policy_loss        | 24.7         |\n",
      "|    reward             | 0.0028338335 |\n",
      "|    std                | 19.7         |\n",
      "|    value_loss         | 0.0465       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20300       |\n",
      "|    time_elapsed       | 997         |\n",
      "|    total_timesteps    | 101500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -128        |\n",
      "|    explained_variance | -0.417      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20299       |\n",
      "|    policy_loss        | 1.8         |\n",
      "|    reward             | 0.008639077 |\n",
      "|    std                | 20          |\n",
      "|    value_loss         | 0.000336    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 20400         |\n",
      "|    time_elapsed       | 1002          |\n",
      "|    total_timesteps    | 102000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -128          |\n",
      "|    explained_variance | 0.893         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20399         |\n",
      "|    policy_loss        | -6.51         |\n",
      "|    reward             | -0.0065546324 |\n",
      "|    std                | 20.4          |\n",
      "|    value_loss         | 0.00283       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20500       |\n",
      "|    time_elapsed       | 1007        |\n",
      "|    total_timesteps    | 102500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -129        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20499       |\n",
      "|    policy_loss        | -4.1        |\n",
      "|    reward             | -0.06328268 |\n",
      "|    std                | 20.9        |\n",
      "|    value_loss         | 0.00105     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20600       |\n",
      "|    time_elapsed       | 1012        |\n",
      "|    total_timesteps    | 103000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -130        |\n",
      "|    explained_variance | -0.702      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20599       |\n",
      "|    policy_loss        | 4.54        |\n",
      "|    reward             | -0.08970898 |\n",
      "|    std                | 21.4        |\n",
      "|    value_loss         | 0.00188     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 20700        |\n",
      "|    time_elapsed       | 1017         |\n",
      "|    total_timesteps    | 103500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -130         |\n",
      "|    explained_variance | 0.262        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20699        |\n",
      "|    policy_loss        | -6.39        |\n",
      "|    reward             | -0.053913485 |\n",
      "|    std                | 21.8         |\n",
      "|    value_loss         | 0.00401      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 1023        |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -131        |\n",
      "|    explained_variance | 0.542       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | -2.79       |\n",
      "|    reward             | -0.07768979 |\n",
      "|    std                | 22          |\n",
      "|    value_loss         | 0.00208     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 20900       |\n",
      "|    time_elapsed       | 1028        |\n",
      "|    total_timesteps    | 104500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -131        |\n",
      "|    explained_variance | 0.779       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20899       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.044913083 |\n",
      "|    std                | 22.3        |\n",
      "|    value_loss         | 0.000201    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 21000      |\n",
      "|    time_elapsed       | 1033       |\n",
      "|    total_timesteps    | 105000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -132       |\n",
      "|    explained_variance | 0.443      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20999      |\n",
      "|    policy_loss        | 5.06       |\n",
      "|    reward             | 0.05413834 |\n",
      "|    std                | 22.9       |\n",
      "|    value_loss         | 0.00247    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 1038        |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -132        |\n",
      "|    explained_variance | 0.62        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | -2.14       |\n",
      "|    reward             | 0.042259097 |\n",
      "|    std                | 23.4        |\n",
      "|    value_loss         | 0.000893    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 21200       |\n",
      "|    time_elapsed       | 1044        |\n",
      "|    total_timesteps    | 106000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -133        |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21199       |\n",
      "|    policy_loss        | -0.279      |\n",
      "|    reward             | 0.011475134 |\n",
      "|    std                | 23.9        |\n",
      "|    value_loss         | 0.000534    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 21300         |\n",
      "|    time_elapsed       | 1049          |\n",
      "|    total_timesteps    | 106500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -134          |\n",
      "|    explained_variance | 0.581         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21299         |\n",
      "|    policy_loss        | -5.76         |\n",
      "|    reward             | 0.00029139614 |\n",
      "|    std                | 24.4          |\n",
      "|    value_loss         | 0.00722       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 1054         |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -134         |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | -4.54        |\n",
      "|    reward             | 0.0070226234 |\n",
      "|    std                | 24.5         |\n",
      "|    value_loss         | 0.00294      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 21500         |\n",
      "|    time_elapsed       | 1060          |\n",
      "|    total_timesteps    | 107500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -134          |\n",
      "|    explained_variance | 0.227         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21499         |\n",
      "|    policy_loss        | 1.41          |\n",
      "|    reward             | -0.0059740506 |\n",
      "|    std                | 25            |\n",
      "|    value_loss         | 0.000178      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 21600        |\n",
      "|    time_elapsed       | 1065         |\n",
      "|    total_timesteps    | 108000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -135         |\n",
      "|    explained_variance | 0.819        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21599        |\n",
      "|    policy_loss        | -7.03        |\n",
      "|    reward             | -0.003901169 |\n",
      "|    std                | 25.6         |\n",
      "|    value_loss         | 0.00322      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 21700        |\n",
      "|    time_elapsed       | 1070         |\n",
      "|    total_timesteps    | 108500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -136         |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21699        |\n",
      "|    policy_loss        | 19.4         |\n",
      "|    reward             | -0.019519085 |\n",
      "|    std                | 26.2         |\n",
      "|    value_loss         | 0.0224       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 1076        |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -136        |\n",
      "|    explained_variance | 0.74        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | 10          |\n",
      "|    reward             | -0.04302955 |\n",
      "|    std                | 26.8        |\n",
      "|    value_loss         | 0.00586     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 21900        |\n",
      "|    time_elapsed       | 1081         |\n",
      "|    total_timesteps    | 109500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -137         |\n",
      "|    explained_variance | 0.127        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21899        |\n",
      "|    policy_loss        | 30.3         |\n",
      "|    reward             | -0.016907547 |\n",
      "|    std                | 27.2         |\n",
      "|    value_loss         | 0.0548       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 22000       |\n",
      "|    time_elapsed       | 1086        |\n",
      "|    total_timesteps    | 110000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -137        |\n",
      "|    explained_variance | -0.958      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21999       |\n",
      "|    policy_loss        | -1.76       |\n",
      "|    reward             | 0.002391071 |\n",
      "|    std                | 27.5        |\n",
      "|    value_loss         | 0.000395    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 22100       |\n",
      "|    time_elapsed       | 1091        |\n",
      "|    total_timesteps    | 110500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -138        |\n",
      "|    explained_variance | -1.39       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22099       |\n",
      "|    policy_loss        | -7.28       |\n",
      "|    reward             | 0.024933865 |\n",
      "|    std                | 28          |\n",
      "|    value_loss         | 0.00355     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 22200        |\n",
      "|    time_elapsed       | 1097         |\n",
      "|    total_timesteps    | 111000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -138         |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22199        |\n",
      "|    policy_loss        | -0.964       |\n",
      "|    reward             | -0.032200318 |\n",
      "|    std                | 28.7         |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 22300       |\n",
      "|    time_elapsed       | 1102        |\n",
      "|    total_timesteps    | 111500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -139        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22299       |\n",
      "|    policy_loss        | 8.08        |\n",
      "|    reward             | -0.18076706 |\n",
      "|    std                | 29.5        |\n",
      "|    value_loss         | 0.0037      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 1107        |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | 0.534       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | -3.86       |\n",
      "|    reward             | -0.02251499 |\n",
      "|    std                | 30.1        |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 22500      |\n",
      "|    time_elapsed       | 1112       |\n",
      "|    total_timesteps    | 112500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -140       |\n",
      "|    explained_variance | 0.718      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22499      |\n",
      "|    policy_loss        | -17.8      |\n",
      "|    reward             | 0.16595872 |\n",
      "|    std                | 30.6       |\n",
      "|    value_loss         | 0.0294     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 21955321.55\n",
      "total_reward: 11955321.55\n",
      "total_cost: 549296.69\n",
      "total_trades: 81998\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 22600       |\n",
      "|    time_elapsed       | 1117        |\n",
      "|    total_timesteps    | 113000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | 0.0934      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22599       |\n",
      "|    policy_loss        | -3.86       |\n",
      "|    reward             | 0.011040348 |\n",
      "|    std                | 30.9        |\n",
      "|    value_loss         | 0.000927    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 22700       |\n",
      "|    time_elapsed       | 1122        |\n",
      "|    total_timesteps    | 113500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22699       |\n",
      "|    policy_loss        | -3.12       |\n",
      "|    reward             | -0.06015486 |\n",
      "|    std                | 31.6        |\n",
      "|    value_loss         | 0.000646    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 22800        |\n",
      "|    time_elapsed       | 1128         |\n",
      "|    total_timesteps    | 114000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -142         |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22799        |\n",
      "|    policy_loss        | 3.74         |\n",
      "|    reward             | 0.0036300763 |\n",
      "|    std                | 32.5         |\n",
      "|    value_loss         | 0.000735     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 22900      |\n",
      "|    time_elapsed       | 1133       |\n",
      "|    total_timesteps    | 114500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -143       |\n",
      "|    explained_variance | 0.836      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22899      |\n",
      "|    policy_loss        | 2.75       |\n",
      "|    reward             | 0.38162813 |\n",
      "|    std                | 33.3       |\n",
      "|    value_loss         | 0.000708   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 23000       |\n",
      "|    time_elapsed       | 1139        |\n",
      "|    total_timesteps    | 115000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -143        |\n",
      "|    explained_variance | 0.754       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22999       |\n",
      "|    policy_loss        | -1.44       |\n",
      "|    reward             | 0.036875375 |\n",
      "|    std                | 34          |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 23100      |\n",
      "|    time_elapsed       | 1144       |\n",
      "|    total_timesteps    | 115500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -144       |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23099      |\n",
      "|    policy_loss        | 7.32       |\n",
      "|    reward             | 0.23220979 |\n",
      "|    std                | 34.5       |\n",
      "|    value_loss         | 0.00413    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 100           |\n",
      "|    iterations         | 23200         |\n",
      "|    time_elapsed       | 1149          |\n",
      "|    total_timesteps    | 116000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -144          |\n",
      "|    explained_variance | 0.75          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23199         |\n",
      "|    policy_loss        | 0.171         |\n",
      "|    reward             | -0.0039331154 |\n",
      "|    std                | 35            |\n",
      "|    value_loss         | 5.45e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 100          |\n",
      "|    iterations         | 23300        |\n",
      "|    time_elapsed       | 1155         |\n",
      "|    total_timesteps    | 116500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -145         |\n",
      "|    explained_variance | -0.901       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23299        |\n",
      "|    policy_loss        | -3.11        |\n",
      "|    reward             | 0.0058083143 |\n",
      "|    std                | 35.8         |\n",
      "|    value_loss         | 0.000651     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 23400      |\n",
      "|    time_elapsed       | 1160       |\n",
      "|    total_timesteps    | 117000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -146       |\n",
      "|    explained_variance | 0.864      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23399      |\n",
      "|    policy_loss        | -0.591     |\n",
      "|    reward             | 0.04226147 |\n",
      "|    std                | 36.8       |\n",
      "|    value_loss         | 0.00133    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 23500      |\n",
      "|    time_elapsed       | 1165       |\n",
      "|    total_timesteps    | 117500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -146       |\n",
      "|    explained_variance | 0.844      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23499      |\n",
      "|    policy_loss        | 0.21       |\n",
      "|    reward             | 0.22638583 |\n",
      "|    std                | 37.6       |\n",
      "|    value_loss         | 0.00211    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 23600       |\n",
      "|    time_elapsed       | 1169        |\n",
      "|    total_timesteps    | 118000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -147        |\n",
      "|    explained_variance | 0.0825      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | -8.19       |\n",
      "|    reward             | 0.008751706 |\n",
      "|    std                | 38.4        |\n",
      "|    value_loss         | 0.0176      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 23700       |\n",
      "|    time_elapsed       | 1174        |\n",
      "|    total_timesteps    | 118500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -147        |\n",
      "|    explained_variance | 0.353       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23699       |\n",
      "|    policy_loss        | -18.1       |\n",
      "|    reward             | -0.15660822 |\n",
      "|    std                | 38.9        |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 23800       |\n",
      "|    time_elapsed       | 1179        |\n",
      "|    total_timesteps    | 119000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -148        |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23799       |\n",
      "|    policy_loss        | 3.97        |\n",
      "|    reward             | 0.006325079 |\n",
      "|    std                | 39.6        |\n",
      "|    value_loss         | 0.00084     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 100          |\n",
      "|    iterations         | 23900        |\n",
      "|    time_elapsed       | 1183         |\n",
      "|    total_timesteps    | 119500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -148         |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23899        |\n",
      "|    policy_loss        | 4.35         |\n",
      "|    reward             | -0.008742519 |\n",
      "|    std                | 40.6         |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 24000       |\n",
      "|    time_elapsed       | 1188        |\n",
      "|    total_timesteps    | 120000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | 0.165       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23999       |\n",
      "|    policy_loss        | -4.4        |\n",
      "|    reward             | 0.041284356 |\n",
      "|    std                | 41.7        |\n",
      "|    value_loss         | 0.00091     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 24100       |\n",
      "|    time_elapsed       | 1193        |\n",
      "|    total_timesteps    | 120500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -150        |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24099       |\n",
      "|    policy_loss        | -6.72       |\n",
      "|    reward             | 0.024842529 |\n",
      "|    std                | 42.7        |\n",
      "|    value_loss         | 0.0024      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 24200       |\n",
      "|    time_elapsed       | 1198        |\n",
      "|    total_timesteps    | 121000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24199       |\n",
      "|    policy_loss        | -12.9       |\n",
      "|    reward             | -0.09034771 |\n",
      "|    std                | 43.7        |\n",
      "|    value_loss         | 0.00902     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 100         |\n",
      "|    iterations         | 24300       |\n",
      "|    time_elapsed       | 1203        |\n",
      "|    total_timesteps    | 121500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | 0.734       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24299       |\n",
      "|    policy_loss        | -7.15       |\n",
      "|    reward             | 0.053445384 |\n",
      "|    std                | 44.2        |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 24400         |\n",
      "|    time_elapsed       | 1207          |\n",
      "|    total_timesteps    | 122000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -151          |\n",
      "|    explained_variance | 0.0899        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24399         |\n",
      "|    policy_loss        | 2.4           |\n",
      "|    reward             | -0.0028806343 |\n",
      "|    std                | 45            |\n",
      "|    value_loss         | 0.000308      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 1212         |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -152         |\n",
      "|    explained_variance | -0.0514      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | 6.19         |\n",
      "|    reward             | -0.017409286 |\n",
      "|    std                | 46.2         |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 24600        |\n",
      "|    time_elapsed       | 1217         |\n",
      "|    total_timesteps    | 123000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -153         |\n",
      "|    explained_variance | 0.66         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24599        |\n",
      "|    policy_loss        | 3.97         |\n",
      "|    reward             | -0.034070283 |\n",
      "|    std                | 47.3         |\n",
      "|    value_loss         | 0.000758     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 24700         |\n",
      "|    time_elapsed       | 1221          |\n",
      "|    total_timesteps    | 123500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -154          |\n",
      "|    explained_variance | 0.915         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24699         |\n",
      "|    policy_loss        | -0.614        |\n",
      "|    reward             | -0.0013783003 |\n",
      "|    std                | 48.4          |\n",
      "|    value_loss         | 5.28e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 24800      |\n",
      "|    time_elapsed       | 1226       |\n",
      "|    total_timesteps    | 124000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -154       |\n",
      "|    explained_variance | 0.347      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24799      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.49313015 |\n",
      "|    std                | 49.6       |\n",
      "|    value_loss         | 0.0248     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 24900        |\n",
      "|    time_elapsed       | 1231         |\n",
      "|    total_timesteps    | 124500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -155         |\n",
      "|    explained_variance | 0.109        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24899        |\n",
      "|    policy_loss        | -1.34        |\n",
      "|    reward             | 0.0035055638 |\n",
      "|    std                | 50.2         |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 1235         |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -155         |\n",
      "|    explained_variance | -3.54        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | 1.82         |\n",
      "|    reward             | -0.023643335 |\n",
      "|    std                | 51.3         |\n",
      "|    value_loss         | 0.000742     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 25100        |\n",
      "|    time_elapsed       | 1240         |\n",
      "|    total_timesteps    | 125500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -156         |\n",
      "|    explained_variance | -0.0782      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25099        |\n",
      "|    policy_loss        | 2.07         |\n",
      "|    reward             | -0.004551566 |\n",
      "|    std                | 52.8         |\n",
      "|    value_loss         | 0.000479     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 25200      |\n",
      "|    time_elapsed       | 1245       |\n",
      "|    total_timesteps    | 126000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -157       |\n",
      "|    explained_variance | 0.768      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25199      |\n",
      "|    policy_loss        | -0.0743    |\n",
      "|    reward             | 0.08778284 |\n",
      "|    std                | 54.1       |\n",
      "|    value_loss         | 0.000293   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 25300        |\n",
      "|    time_elapsed       | 1249         |\n",
      "|    total_timesteps    | 126500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -157         |\n",
      "|    explained_variance | 0.491        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25299        |\n",
      "|    policy_loss        | -0.51        |\n",
      "|    reward             | -0.010994806 |\n",
      "|    std                | 55.5         |\n",
      "|    value_loss         | 0.000261     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 25400        |\n",
      "|    time_elapsed       | 1254         |\n",
      "|    total_timesteps    | 127000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -158         |\n",
      "|    explained_variance | -3.93        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25399        |\n",
      "|    policy_loss        | -36.5        |\n",
      "|    reward             | -0.022193134 |\n",
      "|    std                | 56.6         |\n",
      "|    value_loss         | 0.0785       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 25500       |\n",
      "|    time_elapsed       | 1259        |\n",
      "|    total_timesteps    | 127500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -158        |\n",
      "|    explained_variance | -0.15       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25499       |\n",
      "|    policy_loss        | -0.926      |\n",
      "|    reward             | 0.025672354 |\n",
      "|    std                | 57.3        |\n",
      "|    value_loss         | 0.000166    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 25600       |\n",
      "|    time_elapsed       | 1263        |\n",
      "|    total_timesteps    | 128000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -159        |\n",
      "|    explained_variance | -1.09       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25599       |\n",
      "|    policy_loss        | -7.03       |\n",
      "|    reward             | 0.021803742 |\n",
      "|    std                | 58.6        |\n",
      "|    value_loss         | 0.00213     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 101            |\n",
      "|    iterations         | 25700          |\n",
      "|    time_elapsed       | 1268           |\n",
      "|    total_timesteps    | 128500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -160           |\n",
      "|    explained_variance | 0.856          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 25699          |\n",
      "|    policy_loss        | -3.63          |\n",
      "|    reward             | -0.00066244573 |\n",
      "|    std                | 60.3           |\n",
      "|    value_loss         | 0.00104        |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 25800    |\n",
      "|    time_elapsed       | 1273     |\n",
      "|    total_timesteps    | 129000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -161     |\n",
      "|    explained_variance | 0.968    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | 0.915    |\n",
      "|    reward             | 0.160608 |\n",
      "|    std                | 62       |\n",
      "|    value_loss         | 0.000505 |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 25900       |\n",
      "|    time_elapsed       | 1277        |\n",
      "|    total_timesteps    | 129500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -161        |\n",
      "|    explained_variance | 0.0379      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25899       |\n",
      "|    policy_loss        | 16.9        |\n",
      "|    reward             | 0.016234009 |\n",
      "|    std                | 63.4        |\n",
      "|    value_loss         | 0.0127      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 26000        |\n",
      "|    time_elapsed       | 1282         |\n",
      "|    total_timesteps    | 130000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -162         |\n",
      "|    explained_variance | 0.416        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25999        |\n",
      "|    policy_loss        | -11          |\n",
      "|    reward             | -0.013920598 |\n",
      "|    std                | 64.2         |\n",
      "|    value_loss         | 0.00603      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 101            |\n",
      "|    iterations         | 26100          |\n",
      "|    time_elapsed       | 1287           |\n",
      "|    total_timesteps    | 130500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -162           |\n",
      "|    explained_variance | 0.694          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 26099          |\n",
      "|    policy_loss        | -0.916         |\n",
      "|    reward             | -0.00010255886 |\n",
      "|    std                | 65.2           |\n",
      "|    value_loss         | 3.99e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 26200        |\n",
      "|    time_elapsed       | 1291         |\n",
      "|    total_timesteps    | 131000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -163         |\n",
      "|    explained_variance | 0.473        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26199        |\n",
      "|    policy_loss        | -2.78        |\n",
      "|    reward             | -0.019651106 |\n",
      "|    std                | 66.8         |\n",
      "|    value_loss         | 0.000336     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 26300       |\n",
      "|    time_elapsed       | 1296        |\n",
      "|    total_timesteps    | 131500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26299       |\n",
      "|    policy_loss        | 1.59        |\n",
      "|    reward             | -0.03462351 |\n",
      "|    std                | 68.9        |\n",
      "|    value_loss         | 0.00027     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 26400        |\n",
      "|    time_elapsed       | 1301         |\n",
      "|    total_timesteps    | 132000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -164         |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26399        |\n",
      "|    policy_loss        | 0.864        |\n",
      "|    reward             | 0.0012087744 |\n",
      "|    std                | 70.8         |\n",
      "|    value_loss         | 7.27e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 26500      |\n",
      "|    time_elapsed       | 1305       |\n",
      "|    total_timesteps    | 132500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -165       |\n",
      "|    explained_variance | 0.428      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26499      |\n",
      "|    policy_loss        | 8.51       |\n",
      "|    reward             | 0.06334117 |\n",
      "|    std                | 72.8       |\n",
      "|    value_loss         | 0.00584    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 26600       |\n",
      "|    time_elapsed       | 1310        |\n",
      "|    total_timesteps    | 133000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -166        |\n",
      "|    explained_variance | 0.601       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26599       |\n",
      "|    policy_loss        | 58.1        |\n",
      "|    reward             | -0.91301537 |\n",
      "|    std                | 74          |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 1315         |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -166         |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | -2.33        |\n",
      "|    reward             | -0.012128875 |\n",
      "|    std                | 75.3         |\n",
      "|    value_loss         | 0.000203     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 26800         |\n",
      "|    time_elapsed       | 1319          |\n",
      "|    total_timesteps    | 134000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -167          |\n",
      "|    explained_variance | -0.256        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 26799         |\n",
      "|    policy_loss        | 0.359         |\n",
      "|    reward             | -0.0026130641 |\n",
      "|    std                | 77.2          |\n",
      "|    value_loss         | 0.000188      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 26900        |\n",
      "|    time_elapsed       | 1324         |\n",
      "|    total_timesteps    | 134500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -168         |\n",
      "|    explained_variance | 0.43         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26899        |\n",
      "|    policy_loss        | -4.17        |\n",
      "|    reward             | 0.0066841645 |\n",
      "|    std                | 79.6         |\n",
      "|    value_loss         | 0.00124      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 27000        |\n",
      "|    time_elapsed       | 1329         |\n",
      "|    total_timesteps    | 135000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -169         |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26999        |\n",
      "|    policy_loss        | 3.51         |\n",
      "|    reward             | -0.011726221 |\n",
      "|    std                | 81.8         |\n",
      "|    value_loss         | 0.000467     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 27100      |\n",
      "|    time_elapsed       | 1334       |\n",
      "|    total_timesteps    | 135500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -169       |\n",
      "|    explained_variance | 0.615      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27099      |\n",
      "|    policy_loss        | -5.72      |\n",
      "|    reward             | 0.17625071 |\n",
      "|    std                | 84.1       |\n",
      "|    value_loss         | 0.00172    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 27200         |\n",
      "|    time_elapsed       | 1338          |\n",
      "|    total_timesteps    | 136000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -170          |\n",
      "|    explained_variance | -3.01         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 27199         |\n",
      "|    policy_loss        | 0.829         |\n",
      "|    reward             | -0.0015551533 |\n",
      "|    std                | 85.1          |\n",
      "|    value_loss         | 5.4e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 27300       |\n",
      "|    time_elapsed       | 1343        |\n",
      "|    total_timesteps    | 136500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -170        |\n",
      "|    explained_variance | -0.0746     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27299       |\n",
      "|    policy_loss        | 2.7         |\n",
      "|    reward             | 0.016462263 |\n",
      "|    std                | 87          |\n",
      "|    value_loss         | 0.000393    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 1348        |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -171        |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | 4           |\n",
      "|    reward             | 0.034790635 |\n",
      "|    std                | 89.2        |\n",
      "|    value_loss         | 0.000561    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 27500       |\n",
      "|    time_elapsed       | 1353        |\n",
      "|    total_timesteps    | 137500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -172        |\n",
      "|    explained_variance | 0.739       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27499       |\n",
      "|    policy_loss        | 5.44        |\n",
      "|    reward             | -0.13758992 |\n",
      "|    std                | 91.9        |\n",
      "|    value_loss         | 0.00199     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 27600      |\n",
      "|    time_elapsed       | 1357       |\n",
      "|    total_timesteps    | 138000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -173       |\n",
      "|    explained_variance | 0.845      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27599      |\n",
      "|    policy_loss        | -0.922     |\n",
      "|    reward             | 0.07742145 |\n",
      "|    std                | 94.3       |\n",
      "|    value_loss         | 0.000154   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 27700       |\n",
      "|    time_elapsed       | 1362        |\n",
      "|    total_timesteps    | 138500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -173        |\n",
      "|    explained_variance | 0.746       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27699       |\n",
      "|    policy_loss        | -9.1        |\n",
      "|    reward             | -0.13187455 |\n",
      "|    std                | 96.4        |\n",
      "|    value_loss         | 0.00438     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 27800        |\n",
      "|    time_elapsed       | 1367         |\n",
      "|    total_timesteps    | 139000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -174         |\n",
      "|    explained_variance | -0.892       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 27799        |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | 0.0070966156 |\n",
      "|    std                | 98           |\n",
      "|    value_loss         | 0.00016      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 27900      |\n",
      "|    time_elapsed       | 1372       |\n",
      "|    total_timesteps    | 139500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -175       |\n",
      "|    explained_variance | 0.62       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27899      |\n",
      "|    policy_loss        | 0.607      |\n",
      "|    reward             | 0.00877368 |\n",
      "|    std                | 100        |\n",
      "|    value_loss         | 0.000225   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 28000       |\n",
      "|    time_elapsed       | 1376        |\n",
      "|    total_timesteps    | 140000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -175        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27999       |\n",
      "|    policy_loss        | 0.783       |\n",
      "|    reward             | 0.007348037 |\n",
      "|    std                | 103         |\n",
      "|    value_loss         | 5.13e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 28100        |\n",
      "|    time_elapsed       | 1381         |\n",
      "|    total_timesteps    | 140500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -176         |\n",
      "|    explained_variance | 0.612        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28099        |\n",
      "|    policy_loss        | -3.04        |\n",
      "|    reward             | -0.027556166 |\n",
      "|    std                | 107          |\n",
      "|    value_loss         | 0.00081      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 28200      |\n",
      "|    time_elapsed       | 1386       |\n",
      "|    total_timesteps    | 141000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -177       |\n",
      "|    explained_variance | 0.762      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28199      |\n",
      "|    policy_loss        | -2.62      |\n",
      "|    reward             | 0.06374523 |\n",
      "|    std                | 110        |\n",
      "|    value_loss         | 0.000326   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 28300      |\n",
      "|    time_elapsed       | 1390       |\n",
      "|    total_timesteps    | 141500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -178       |\n",
      "|    explained_variance | -0.971     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28299      |\n",
      "|    policy_loss        | 54.5       |\n",
      "|    reward             | -0.1287493 |\n",
      "|    std                | 112        |\n",
      "|    value_loss         | 0.0978     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17812315.48\n",
      "total_reward: 7812315.48\n",
      "total_cost: 557804.62\n",
      "total_trades: 82520\n",
      "Sharpe: 0.447\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 28400        |\n",
      "|    time_elapsed       | 1395         |\n",
      "|    total_timesteps    | 142000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -178         |\n",
      "|    explained_variance | 0.685        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28399        |\n",
      "|    policy_loss        | -0.774       |\n",
      "|    reward             | 0.0060217693 |\n",
      "|    std                | 114          |\n",
      "|    value_loss         | 2.73e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 28500        |\n",
      "|    time_elapsed       | 1400         |\n",
      "|    total_timesteps    | 142500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -179         |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28499        |\n",
      "|    policy_loss        | 3.77         |\n",
      "|    reward             | -0.023561563 |\n",
      "|    std                | 117          |\n",
      "|    value_loss         | 0.000474     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 28600         |\n",
      "|    time_elapsed       | 1404          |\n",
      "|    total_timesteps    | 143000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -180          |\n",
      "|    explained_variance | 0.0876        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 28599         |\n",
      "|    policy_loss        | 0.0809        |\n",
      "|    reward             | -0.0076514506 |\n",
      "|    std                | 120           |\n",
      "|    value_loss         | 0.000135      |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 28700    |\n",
      "|    time_elapsed       | 1409     |\n",
      "|    total_timesteps    | 143500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -181     |\n",
      "|    explained_variance | -3.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28699    |\n",
      "|    policy_loss        | -4.98    |\n",
      "|    reward             | 0.14066  |\n",
      "|    std                | 124      |\n",
      "|    value_loss         | 0.00101  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 28800      |\n",
      "|    time_elapsed       | 1414       |\n",
      "|    total_timesteps    | 144000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -182       |\n",
      "|    explained_variance | -0.207     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28799      |\n",
      "|    policy_loss        | -4.16      |\n",
      "|    reward             | 0.05813225 |\n",
      "|    std                | 128        |\n",
      "|    value_loss         | 0.00155    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 28900     |\n",
      "|    time_elapsed       | 1418      |\n",
      "|    total_timesteps    | 144500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -182      |\n",
      "|    explained_variance | 0.525     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28899     |\n",
      "|    policy_loss        | 13.8      |\n",
      "|    reward             | 0.1041855 |\n",
      "|    std                | 131       |\n",
      "|    value_loss         | 0.00714   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 1423        |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -183        |\n",
      "|    explained_variance | 0.572       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | -1.54       |\n",
      "|    reward             | 0.013373677 |\n",
      "|    std                | 133         |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 29100        |\n",
      "|    time_elapsed       | 1428         |\n",
      "|    total_timesteps    | 145500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -184         |\n",
      "|    explained_variance | 0.157        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29099        |\n",
      "|    policy_loss        | 5.45         |\n",
      "|    reward             | -0.032603245 |\n",
      "|    std                | 136          |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 29200        |\n",
      "|    time_elapsed       | 1432         |\n",
      "|    total_timesteps    | 146000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -184         |\n",
      "|    explained_variance | 0.631        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29199        |\n",
      "|    policy_loss        | -2.75        |\n",
      "|    reward             | -0.029345443 |\n",
      "|    std                | 141          |\n",
      "|    value_loss         | 0.000354     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 29300      |\n",
      "|    time_elapsed       | 1437       |\n",
      "|    total_timesteps    | 146500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -185       |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29299      |\n",
      "|    policy_loss        | -1.7       |\n",
      "|    reward             | 0.07145754 |\n",
      "|    std                | 146        |\n",
      "|    value_loss         | 0.000117   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 29400      |\n",
      "|    time_elapsed       | 1442       |\n",
      "|    total_timesteps    | 147000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -186       |\n",
      "|    explained_variance | 0.513      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29399      |\n",
      "|    policy_loss        | -7.35      |\n",
      "|    reward             | 0.13975887 |\n",
      "|    std                | 150        |\n",
      "|    value_loss         | 0.00607    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 29500       |\n",
      "|    time_elapsed       | 1446        |\n",
      "|    total_timesteps    | 147500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -187        |\n",
      "|    explained_variance | 0.652       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29499       |\n",
      "|    policy_loss        | -12.2       |\n",
      "|    reward             | -0.16361152 |\n",
      "|    std                | 153         |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 29600        |\n",
      "|    time_elapsed       | 1451         |\n",
      "|    total_timesteps    | 148000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -187         |\n",
      "|    explained_variance | -0.351       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29599        |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | 0.0015963389 |\n",
      "|    std                | 156          |\n",
      "|    value_loss         | 6.26e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 29700         |\n",
      "|    time_elapsed       | 1456          |\n",
      "|    total_timesteps    | 148500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -188          |\n",
      "|    explained_variance | 0.245         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 29699         |\n",
      "|    policy_loss        | 0.655         |\n",
      "|    reward             | 0.00019125479 |\n",
      "|    std                | 161           |\n",
      "|    value_loss         | 0.000386      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 101           |\n",
      "|    iterations         | 29800         |\n",
      "|    time_elapsed       | 1460          |\n",
      "|    total_timesteps    | 149000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -189          |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 29799         |\n",
      "|    policy_loss        | -0.537        |\n",
      "|    reward             | -0.0025434983 |\n",
      "|    std                | 166           |\n",
      "|    value_loss         | 0.000135      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 29900       |\n",
      "|    time_elapsed       | 1465        |\n",
      "|    total_timesteps    | 149500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -190        |\n",
      "|    explained_variance | 0.435       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29899       |\n",
      "|    policy_loss        | 4.49        |\n",
      "|    reward             | -0.07779341 |\n",
      "|    std                | 172         |\n",
      "|    value_loss         | 0.000865    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 30000        |\n",
      "|    time_elapsed       | 1470         |\n",
      "|    total_timesteps    | 150000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -191         |\n",
      "|    explained_variance | 0.751        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29999        |\n",
      "|    policy_loss        | -0.0002      |\n",
      "|    reward             | -0.049740892 |\n",
      "|    std                | 177          |\n",
      "|    value_loss         | 0.000398     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 30100         |\n",
      "|    time_elapsed       | 1475          |\n",
      "|    total_timesteps    | 150500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -192          |\n",
      "|    explained_variance | -0.807        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 30099         |\n",
      "|    policy_loss        | -2.57         |\n",
      "|    reward             | -0.0017658552 |\n",
      "|    std                | 180           |\n",
      "|    value_loss         | 0.000206      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 30200       |\n",
      "|    time_elapsed       | 1479        |\n",
      "|    total_timesteps    | 151000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -192        |\n",
      "|    explained_variance | -0.0731     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30199       |\n",
      "|    policy_loss        | 3.19        |\n",
      "|    reward             | 0.010054005 |\n",
      "|    std                | 184         |\n",
      "|    value_loss         | 0.00047     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 30300        |\n",
      "|    time_elapsed       | 1484         |\n",
      "|    total_timesteps    | 151500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -193         |\n",
      "|    explained_variance | 0.09         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 30299        |\n",
      "|    policy_loss        | 2.58         |\n",
      "|    reward             | -0.004307953 |\n",
      "|    std                | 190          |\n",
      "|    value_loss         | 0.000254     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 30400        |\n",
      "|    time_elapsed       | 1489         |\n",
      "|    total_timesteps    | 152000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -194         |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 30399        |\n",
      "|    policy_loss        | 0.562        |\n",
      "|    reward             | -0.021254234 |\n",
      "|    std                | 197          |\n",
      "|    value_loss         | 6.54e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 30500         |\n",
      "|    time_elapsed       | 1493          |\n",
      "|    total_timesteps    | 152500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -195          |\n",
      "|    explained_variance | 0.944         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 30499         |\n",
      "|    policy_loss        | -5.22         |\n",
      "|    reward             | -0.0065993876 |\n",
      "|    std                | 204           |\n",
      "|    value_loss         | 0.000742      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 30600      |\n",
      "|    time_elapsed       | 1498       |\n",
      "|    total_timesteps    | 153000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -196       |\n",
      "|    explained_variance | 0.644      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30599      |\n",
      "|    policy_loss        | -17.6      |\n",
      "|    reward             | 0.06847673 |\n",
      "|    std                | 208        |\n",
      "|    value_loss         | 0.00943    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 30700        |\n",
      "|    time_elapsed       | 1503         |\n",
      "|    total_timesteps    | 153500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -196         |\n",
      "|    explained_variance | -2.19        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 30699        |\n",
      "|    policy_loss        | 1.49         |\n",
      "|    reward             | 0.0043665245 |\n",
      "|    std                | 211          |\n",
      "|    value_loss         | 7.52e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 1508        |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -197        |\n",
      "|    explained_variance | 0.601       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | 2.61        |\n",
      "|    reward             | 0.013251519 |\n",
      "|    std                | 216         |\n",
      "|    value_loss         | 0.000724    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 30900       |\n",
      "|    time_elapsed       | 1512        |\n",
      "|    total_timesteps    | 154500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -198        |\n",
      "|    explained_variance | 0.189       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30899       |\n",
      "|    policy_loss        | 4.29        |\n",
      "|    reward             | 0.018162057 |\n",
      "|    std                | 223         |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 31000       |\n",
      "|    time_elapsed       | 1517        |\n",
      "|    total_timesteps    | 155000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -199        |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30999       |\n",
      "|    policy_loss        | -1.15       |\n",
      "|    reward             | -0.22720304 |\n",
      "|    std                | 230         |\n",
      "|    value_loss         | 8.93e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 31100        |\n",
      "|    time_elapsed       | 1522         |\n",
      "|    total_timesteps    | 155500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -199         |\n",
      "|    explained_variance | -2.68        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31099        |\n",
      "|    policy_loss        | -3.2         |\n",
      "|    reward             | -0.097811095 |\n",
      "|    std                | 237          |\n",
      "|    value_loss         | 0.000597     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 31200       |\n",
      "|    time_elapsed       | 1526        |\n",
      "|    total_timesteps    | 156000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -200        |\n",
      "|    explained_variance | 0.8         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31199       |\n",
      "|    policy_loss        | -31.4       |\n",
      "|    reward             | -0.34576678 |\n",
      "|    std                | 242         |\n",
      "|    value_loss         | 0.0324      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 31300         |\n",
      "|    time_elapsed       | 1531          |\n",
      "|    total_timesteps    | 156500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -201          |\n",
      "|    explained_variance | 0.536         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 31299         |\n",
      "|    policy_loss        | -0.601        |\n",
      "|    reward             | -0.0022705994 |\n",
      "|    std                | 247           |\n",
      "|    value_loss         | 2.12e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 31400       |\n",
      "|    time_elapsed       | 1536        |\n",
      "|    total_timesteps    | 157000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -201        |\n",
      "|    explained_variance | -11.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31399       |\n",
      "|    policy_loss        | -1.87       |\n",
      "|    reward             | 0.029152809 |\n",
      "|    std                | 253         |\n",
      "|    value_loss         | 0.000214    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 1541        |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -202        |\n",
      "|    explained_variance | 0.788       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | 0.912       |\n",
      "|    reward             | -0.03241547 |\n",
      "|    std                | 262         |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 31600        |\n",
      "|    time_elapsed       | 1545         |\n",
      "|    total_timesteps    | 158000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -203         |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31599        |\n",
      "|    policy_loss        | -0.265       |\n",
      "|    reward             | -0.059119973 |\n",
      "|    std                | 271          |\n",
      "|    value_loss         | 9.69e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 31700      |\n",
      "|    time_elapsed       | 1550       |\n",
      "|    total_timesteps    | 158500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -204       |\n",
      "|    explained_variance | 0.679      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31699      |\n",
      "|    policy_loss        | 2.93       |\n",
      "|    reward             | 0.05105188 |\n",
      "|    std                | 281        |\n",
      "|    value_loss         | 0.000506   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 31800      |\n",
      "|    time_elapsed       | 1555       |\n",
      "|    total_timesteps    | 159000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -205       |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31799      |\n",
      "|    policy_loss        | 2.97       |\n",
      "|    reward             | 0.08879367 |\n",
      "|    std                | 288        |\n",
      "|    value_loss         | 0.000386   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 31900      |\n",
      "|    time_elapsed       | 1559       |\n",
      "|    total_timesteps    | 159500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -206       |\n",
      "|    explained_variance | 0.807      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31899      |\n",
      "|    policy_loss        | 3.83       |\n",
      "|    reward             | 0.00175445 |\n",
      "|    std                | 294        |\n",
      "|    value_loss         | 0.000359   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 32000         |\n",
      "|    time_elapsed       | 1564          |\n",
      "|    total_timesteps    | 160000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -207          |\n",
      "|    explained_variance | 0.879         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 31999         |\n",
      "|    policy_loss        | -3.2          |\n",
      "|    reward             | -0.0039030088 |\n",
      "|    std                | 302           |\n",
      "|    value_loss         | 0.000258      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 32100        |\n",
      "|    time_elapsed       | 1569         |\n",
      "|    total_timesteps    | 160500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -208         |\n",
      "|    explained_variance | 0.557        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32099        |\n",
      "|    policy_loss        | 1.84         |\n",
      "|    reward             | -0.018970972 |\n",
      "|    std                | 314          |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 32200       |\n",
      "|    time_elapsed       | 1573        |\n",
      "|    total_timesteps    | 161000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -209        |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32199       |\n",
      "|    policy_loss        | -2.5        |\n",
      "|    reward             | 0.104903735 |\n",
      "|    std                | 325         |\n",
      "|    value_loss         | 0.000165    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 32300      |\n",
      "|    time_elapsed       | 1578       |\n",
      "|    total_timesteps    | 161500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -210       |\n",
      "|    explained_variance | 0.344      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32299      |\n",
      "|    policy_loss        | 14.1       |\n",
      "|    reward             | -0.1544272 |\n",
      "|    std                | 336        |\n",
      "|    value_loss         | 0.00489    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 32400       |\n",
      "|    time_elapsed       | 1583        |\n",
      "|    total_timesteps    | 162000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -210        |\n",
      "|    explained_variance | 0.679       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32399       |\n",
      "|    policy_loss        | -63.9       |\n",
      "|    reward             | -0.06761476 |\n",
      "|    std                | 342         |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 32500        |\n",
      "|    time_elapsed       | 1588         |\n",
      "|    total_timesteps    | 162500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -211         |\n",
      "|    explained_variance | 0.264        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32499        |\n",
      "|    policy_loss        | -0.369       |\n",
      "|    reward             | -0.009019371 |\n",
      "|    std                | 350          |\n",
      "|    value_loss         | 2.07e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 32600       |\n",
      "|    time_elapsed       | 1592        |\n",
      "|    total_timesteps    | 163000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -212        |\n",
      "|    explained_variance | 0.548       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32599       |\n",
      "|    policy_loss        | -3.1        |\n",
      "|    reward             | 0.022019267 |\n",
      "|    std                | 360         |\n",
      "|    value_loss         | 0.000268    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 32700      |\n",
      "|    time_elapsed       | 1597       |\n",
      "|    total_timesteps    | 163500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -213       |\n",
      "|    explained_variance | 0.294      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32699      |\n",
      "|    policy_loss        | 0.586      |\n",
      "|    reward             | 0.03354513 |\n",
      "|    std                | 373        |\n",
      "|    value_loss         | 7.28e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 32800       |\n",
      "|    time_elapsed       | 1602        |\n",
      "|    total_timesteps    | 164000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -214        |\n",
      "|    explained_variance | 0.696       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32799       |\n",
      "|    policy_loss        | 1.97        |\n",
      "|    reward             | 0.004406088 |\n",
      "|    std                | 386         |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 32900     |\n",
      "|    time_elapsed       | 1606      |\n",
      "|    total_timesteps    | 164500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -214      |\n",
      "|    explained_variance | 0.324     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32899     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 0.2024174 |\n",
      "|    std                | 396       |\n",
      "|    value_loss         | 0.0227    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 33000        |\n",
      "|    time_elapsed       | 1611         |\n",
      "|    total_timesteps    | 165000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -215         |\n",
      "|    explained_variance | 0.13         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32999        |\n",
      "|    policy_loss        | 3.31         |\n",
      "|    reward             | -0.009455731 |\n",
      "|    std                | 403          |\n",
      "|    value_loss         | 0.000281     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 33100        |\n",
      "|    time_elapsed       | 1615         |\n",
      "|    total_timesteps    | 165500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -216         |\n",
      "|    explained_variance | -0.235       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33099        |\n",
      "|    policy_loss        | -9.98        |\n",
      "|    reward             | 0.0038928636 |\n",
      "|    std                | 413          |\n",
      "|    value_loss         | 0.00225      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 33200        |\n",
      "|    time_elapsed       | 1620         |\n",
      "|    total_timesteps    | 166000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -217         |\n",
      "|    explained_variance | 0.665        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33199        |\n",
      "|    policy_loss        | 0.416        |\n",
      "|    reward             | -0.019344611 |\n",
      "|    std                | 426          |\n",
      "|    value_loss         | 0.000102     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 33300         |\n",
      "|    time_elapsed       | 1625          |\n",
      "|    total_timesteps    | 166500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -218          |\n",
      "|    explained_variance | 0.83          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33299         |\n",
      "|    policy_loss        | -7.96         |\n",
      "|    reward             | -0.0103644235 |\n",
      "|    std                | 442           |\n",
      "|    value_loss         | 0.00146       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 33400       |\n",
      "|    time_elapsed       | 1630        |\n",
      "|    total_timesteps    | 167000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -219        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33399       |\n",
      "|    policy_loss        | 2.78        |\n",
      "|    reward             | 0.008631155 |\n",
      "|    std                | 457         |\n",
      "|    value_loss         | 0.000468    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 33500       |\n",
      "|    time_elapsed       | 1634        |\n",
      "|    total_timesteps    | 167500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -219        |\n",
      "|    explained_variance | 0.0438      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33499       |\n",
      "|    policy_loss        | -19.5       |\n",
      "|    reward             | -0.01572005 |\n",
      "|    std                | 467         |\n",
      "|    value_loss         | 0.00928     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 33600        |\n",
      "|    time_elapsed       | 1639         |\n",
      "|    total_timesteps    | 168000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -220         |\n",
      "|    explained_variance | -0.291       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33599        |\n",
      "|    policy_loss        | 0.644        |\n",
      "|    reward             | 0.0004075591 |\n",
      "|    std                | 476          |\n",
      "|    value_loss         | 2.48e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 33700         |\n",
      "|    time_elapsed       | 1644          |\n",
      "|    total_timesteps    | 168500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -220          |\n",
      "|    explained_variance | 0.198         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33699         |\n",
      "|    policy_loss        | -1.97         |\n",
      "|    reward             | 0.00094137195 |\n",
      "|    std                | 488           |\n",
      "|    value_loss         | 0.000268      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 33800       |\n",
      "|    time_elapsed       | 1648        |\n",
      "|    total_timesteps    | 169000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -221        |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33799       |\n",
      "|    policy_loss        | -9.84       |\n",
      "|    reward             | 0.019995688 |\n",
      "|    std                | 504         |\n",
      "|    value_loss         | 0.00203     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 1653         |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -222         |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | -3.74        |\n",
      "|    reward             | -0.018210731 |\n",
      "|    std                | 522          |\n",
      "|    value_loss         | 0.000368     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 1658         |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -223         |\n",
      "|    explained_variance | -0.0335      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33999        |\n",
      "|    policy_loss        | 5.81         |\n",
      "|    reward             | 0.0055747153 |\n",
      "|    std                | 541          |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 34100      |\n",
      "|    time_elapsed       | 1663       |\n",
      "|    total_timesteps    | 170500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -224       |\n",
      "|    explained_variance | 0.545      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34099      |\n",
      "|    policy_loss        | -21.4      |\n",
      "|    reward             | 0.07456668 |\n",
      "|    std                | 553        |\n",
      "|    value_loss         | 0.0104     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17336362.16\n",
      "total_reward: 7336362.16\n",
      "total_cost: 559228.93\n",
      "total_trades: 82543\n",
      "Sharpe: 0.480\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 34200       |\n",
      "|    time_elapsed       | 1667        |\n",
      "|    total_timesteps    | 171000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -225        |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34199       |\n",
      "|    policy_loss        | -0.694      |\n",
      "|    reward             | 0.006206114 |\n",
      "|    std                | 563         |\n",
      "|    value_loss         | 2.07e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 34300      |\n",
      "|    time_elapsed       | 1672       |\n",
      "|    total_timesteps    | 171500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -225       |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34299      |\n",
      "|    policy_loss        | 1.9        |\n",
      "|    reward             | 0.03544145 |\n",
      "|    std                | 578        |\n",
      "|    value_loss         | 9.01e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 34400        |\n",
      "|    time_elapsed       | 1677         |\n",
      "|    total_timesteps    | 172000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -226         |\n",
      "|    explained_variance | 0.677        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34399        |\n",
      "|    policy_loss        | -7.45        |\n",
      "|    reward             | -0.014855921 |\n",
      "|    std                | 596          |\n",
      "|    value_loss         | 0.00169      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 34500      |\n",
      "|    time_elapsed       | 1682       |\n",
      "|    total_timesteps    | 172500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -227       |\n",
      "|    explained_variance | -0.556     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34499      |\n",
      "|    policy_loss        | -5.89      |\n",
      "|    reward             | 0.06363692 |\n",
      "|    std                | 616        |\n",
      "|    value_loss         | 0.00129    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 34600        |\n",
      "|    time_elapsed       | 1686         |\n",
      "|    total_timesteps    | 173000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -228         |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34599        |\n",
      "|    policy_loss        | -5.01        |\n",
      "|    reward             | -0.080445014 |\n",
      "|    std                | 634          |\n",
      "|    value_loss         | 0.00348      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 34700      |\n",
      "|    time_elapsed       | 1691       |\n",
      "|    total_timesteps    | 173500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -229       |\n",
      "|    explained_variance | 0.392      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34699      |\n",
      "|    policy_loss        | -30.4      |\n",
      "|    reward             | -0.9957477 |\n",
      "|    std                | 647        |\n",
      "|    value_loss         | 0.167      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 1696        |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -229        |\n",
      "|    explained_variance | 0.665       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34799       |\n",
      "|    policy_loss        | -4.79       |\n",
      "|    reward             | 0.009361879 |\n",
      "|    std                | 659         |\n",
      "|    value_loss         | 0.000475    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 34900         |\n",
      "|    time_elapsed       | 1700          |\n",
      "|    total_timesteps    | 174500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -230          |\n",
      "|    explained_variance | 0.915         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 34899         |\n",
      "|    policy_loss        | -1.4          |\n",
      "|    reward             | -0.0018776968 |\n",
      "|    std                | 679           |\n",
      "|    value_loss         | 4.94e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 35000      |\n",
      "|    time_elapsed       | 1705       |\n",
      "|    total_timesteps    | 175000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -231       |\n",
      "|    explained_variance | 0.144      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34999      |\n",
      "|    policy_loss        | -2.54      |\n",
      "|    reward             | 0.02362456 |\n",
      "|    std                | 701        |\n",
      "|    value_loss         | 0.000286   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 102            |\n",
      "|    iterations         | 35100          |\n",
      "|    time_elapsed       | 1710           |\n",
      "|    total_timesteps    | 175500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -232           |\n",
      "|    explained_variance | 0.762          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 35099          |\n",
      "|    policy_loss        | 3.15           |\n",
      "|    reward             | -0.00021190787 |\n",
      "|    std                | 724            |\n",
      "|    value_loss         | 0.000359       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 35200       |\n",
      "|    time_elapsed       | 1715        |\n",
      "|    total_timesteps    | 176000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -233        |\n",
      "|    explained_variance | 0.101       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35199       |\n",
      "|    policy_loss        | 6.95        |\n",
      "|    reward             | 0.050918844 |\n",
      "|    std                | 745         |\n",
      "|    value_loss         | 0.00201     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 35300        |\n",
      "|    time_elapsed       | 1719         |\n",
      "|    total_timesteps    | 176500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -233         |\n",
      "|    explained_variance | -0.718       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35299        |\n",
      "|    policy_loss        | -2.64        |\n",
      "|    reward             | 0.0051848358 |\n",
      "|    std                | 756          |\n",
      "|    value_loss         | 0.00016      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 35400        |\n",
      "|    time_elapsed       | 1724         |\n",
      "|    total_timesteps    | 177000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -234         |\n",
      "|    explained_variance | -4.94        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35399        |\n",
      "|    policy_loss        | -4.29        |\n",
      "|    reward             | 0.0037115985 |\n",
      "|    std                | 773          |\n",
      "|    value_loss         | 0.000463     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 35500      |\n",
      "|    time_elapsed       | 1729       |\n",
      "|    total_timesteps    | 177500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -235       |\n",
      "|    explained_variance | -5.52      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35499      |\n",
      "|    policy_loss        | 6.62       |\n",
      "|    reward             | 0.03199383 |\n",
      "|    std                | 798        |\n",
      "|    value_loss         | 0.00107    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 35600        |\n",
      "|    time_elapsed       | 1733         |\n",
      "|    total_timesteps    | 178000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -236         |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35599        |\n",
      "|    policy_loss        | 1.94         |\n",
      "|    reward             | -0.051457614 |\n",
      "|    std                | 825          |\n",
      "|    value_loss         | 0.00018      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 35700        |\n",
      "|    time_elapsed       | 1738         |\n",
      "|    total_timesteps    | 178500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -237         |\n",
      "|    explained_variance | 0.53         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35699        |\n",
      "|    policy_loss        | -2.18        |\n",
      "|    reward             | -0.008792625 |\n",
      "|    std                | 855          |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 35800      |\n",
      "|    time_elapsed       | 1743       |\n",
      "|    total_timesteps    | 179000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -238       |\n",
      "|    explained_variance | 0.779      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35799      |\n",
      "|    policy_loss        | -21.1      |\n",
      "|    reward             | 0.04468733 |\n",
      "|    std                | 883        |\n",
      "|    value_loss         | 0.0105     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 35900     |\n",
      "|    time_elapsed       | 1747      |\n",
      "|    total_timesteps    | 179500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -238      |\n",
      "|    explained_variance | -0.425    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35899     |\n",
      "|    policy_loss        | -1.21     |\n",
      "|    reward             | 0.0089522 |\n",
      "|    std                | 903       |\n",
      "|    value_loss         | 0.000142  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 36000        |\n",
      "|    time_elapsed       | 1752         |\n",
      "|    total_timesteps    | 180000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -239         |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35999        |\n",
      "|    policy_loss        | 2.04         |\n",
      "|    reward             | -0.028069781 |\n",
      "|    std                | 929          |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 36100       |\n",
      "|    time_elapsed       | 1757        |\n",
      "|    total_timesteps    | 180500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -240        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36099       |\n",
      "|    policy_loss        | -1.59       |\n",
      "|    reward             | 0.010542617 |\n",
      "|    std                | 963         |\n",
      "|    value_loss         | 6.94e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 36200       |\n",
      "|    time_elapsed       | 1761        |\n",
      "|    total_timesteps    | 181000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -241        |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -5.22       |\n",
      "|    reward             | 0.066074245 |\n",
      "|    std                | 998         |\n",
      "|    value_loss         | 0.000669    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 1766        |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -242        |\n",
      "|    explained_variance | -0.297      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | 26.2        |\n",
      "|    reward             | -0.00687199 |\n",
      "|    std                | 1.03e+03    |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 36400        |\n",
      "|    time_elapsed       | 1771         |\n",
      "|    total_timesteps    | 182000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -243         |\n",
      "|    explained_variance | 0.14         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36399        |\n",
      "|    policy_loss        | 8.19         |\n",
      "|    reward             | -0.065454006 |\n",
      "|    std                | 1.05e+03     |\n",
      "|    value_loss         | 0.00421      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 36500        |\n",
      "|    time_elapsed       | 1775         |\n",
      "|    total_timesteps    | 182500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -243         |\n",
      "|    explained_variance | -3.03        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36499        |\n",
      "|    policy_loss        | -0.0394      |\n",
      "|    reward             | 0.0022938666 |\n",
      "|    std                | 1.06e+03     |\n",
      "|    value_loss         | 8.37e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 36600       |\n",
      "|    time_elapsed       | 1780        |\n",
      "|    total_timesteps    | 183000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -244        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36599       |\n",
      "|    policy_loss        | -2.68       |\n",
      "|    reward             | 0.030386105 |\n",
      "|    std                | 1.09e+03    |\n",
      "|    value_loss         | 0.000166    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 1785        |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -245        |\n",
      "|    explained_variance | 0.705       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | -1.26       |\n",
      "|    reward             | 0.038588196 |\n",
      "|    std                | 1.12e+03    |\n",
      "|    value_loss         | 4.2e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 36800        |\n",
      "|    time_elapsed       | 1790         |\n",
      "|    total_timesteps    | 184000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -245         |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36799        |\n",
      "|    policy_loss        | -0.992       |\n",
      "|    reward             | -0.022122908 |\n",
      "|    std                | 1.16e+03     |\n",
      "|    value_loss         | 0.000272     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 36900        |\n",
      "|    time_elapsed       | 1794         |\n",
      "|    total_timesteps    | 184500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -246         |\n",
      "|    explained_variance | 0.465        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36899        |\n",
      "|    policy_loss        | -10.4        |\n",
      "|    reward             | 9.316925e-06 |\n",
      "|    std                | 1.19e+03     |\n",
      "|    value_loss         | 0.00204      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 37000        |\n",
      "|    time_elapsed       | 1799         |\n",
      "|    total_timesteps    | 185000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -247         |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36999        |\n",
      "|    policy_loss        | -5.28        |\n",
      "|    reward             | 0.0032213093 |\n",
      "|    std                | 1.22e+03     |\n",
      "|    value_loss         | 0.000493     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 37100       |\n",
      "|    time_elapsed       | 1804        |\n",
      "|    total_timesteps    | 185500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -248        |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37099       |\n",
      "|    policy_loss        | -5.28       |\n",
      "|    reward             | 0.015397961 |\n",
      "|    std                | 1.25e+03    |\n",
      "|    value_loss         | 0.000493    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 37200        |\n",
      "|    time_elapsed       | 1808         |\n",
      "|    total_timesteps    | 186000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -248         |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37199        |\n",
      "|    policy_loss        | -6.19        |\n",
      "|    reward             | -0.011819107 |\n",
      "|    std                | 1.28e+03     |\n",
      "|    value_loss         | 0.000741     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 1813        |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -249        |\n",
      "|    explained_variance | -7.49       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | -19.6       |\n",
      "|    reward             | 0.006067395 |\n",
      "|    std                | 1.32e+03    |\n",
      "|    value_loss         | 0.00694     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 1818        |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -250        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | 0.358       |\n",
      "|    reward             | 0.017221265 |\n",
      "|    std                | 1.36e+03    |\n",
      "|    value_loss         | 1.78e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 37500       |\n",
      "|    time_elapsed       | 1823        |\n",
      "|    total_timesteps    | 187500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -251        |\n",
      "|    explained_variance | 0.681       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37499       |\n",
      "|    policy_loss        | -36.5       |\n",
      "|    reward             | -0.10528726 |\n",
      "|    std                | 1.4e+03     |\n",
      "|    value_loss         | 0.0261      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 37600        |\n",
      "|    time_elapsed       | 1828         |\n",
      "|    total_timesteps    | 188000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -252         |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37599        |\n",
      "|    policy_loss        | -59.7        |\n",
      "|    reward             | 0.0012362214 |\n",
      "|    std                | 1.43e+03     |\n",
      "|    value_loss         | 0.0673       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 37700         |\n",
      "|    time_elapsed       | 1832          |\n",
      "|    total_timesteps    | 188500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -252          |\n",
      "|    explained_variance | 0.613         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 37699         |\n",
      "|    policy_loss        | -2.04         |\n",
      "|    reward             | -0.0058314614 |\n",
      "|    std                | 1.46e+03      |\n",
      "|    value_loss         | 9.42e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 37800       |\n",
      "|    time_elapsed       | 1837        |\n",
      "|    total_timesteps    | 189000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -253        |\n",
      "|    explained_variance | 0.547       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37799       |\n",
      "|    policy_loss        | -2.25       |\n",
      "|    reward             | 0.030414324 |\n",
      "|    std                | 1.5e+03     |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 37900         |\n",
      "|    time_elapsed       | 1842          |\n",
      "|    total_timesteps    | 189500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -254          |\n",
      "|    explained_variance | 0.83          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 37899         |\n",
      "|    policy_loss        | 5.22          |\n",
      "|    reward             | -0.0051318896 |\n",
      "|    std                | 1.55e+03      |\n",
      "|    value_loss         | 0.000582      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 38000         |\n",
      "|    time_elapsed       | 1846          |\n",
      "|    total_timesteps    | 190000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -255          |\n",
      "|    explained_variance | 0.819         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 37999         |\n",
      "|    policy_loss        | -6.75         |\n",
      "|    reward             | -0.0010854362 |\n",
      "|    std                | 1.61e+03      |\n",
      "|    value_loss         | 0.00102       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 38100       |\n",
      "|    time_elapsed       | 1851        |\n",
      "|    total_timesteps    | 190500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -256        |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38099       |\n",
      "|    policy_loss        | -5.22       |\n",
      "|    reward             | 0.016739888 |\n",
      "|    std                | 1.66e+03    |\n",
      "|    value_loss         | 0.000976    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 38200       |\n",
      "|    time_elapsed       | 1856        |\n",
      "|    total_timesteps    | 191000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -256        |\n",
      "|    explained_variance | -0.356      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38199       |\n",
      "|    policy_loss        | 2.69        |\n",
      "|    reward             | 0.011632167 |\n",
      "|    std                | 1.69e+03    |\n",
      "|    value_loss         | 0.000188    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 102           |\n",
      "|    iterations         | 38300         |\n",
      "|    time_elapsed       | 1861          |\n",
      "|    total_timesteps    | 191500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -257          |\n",
      "|    explained_variance | 0.778         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 38299         |\n",
      "|    policy_loss        | 3.7           |\n",
      "|    reward             | -0.0011676701 |\n",
      "|    std                | 1.73e+03      |\n",
      "|    value_loss         | 0.000251      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 38400        |\n",
      "|    time_elapsed       | 1865         |\n",
      "|    total_timesteps    | 192000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -258         |\n",
      "|    explained_variance | -4.01        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38399        |\n",
      "|    policy_loss        | 1.87         |\n",
      "|    reward             | -0.010732279 |\n",
      "|    std                | 1.79e+03     |\n",
      "|    value_loss         | 0.000432     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 38500        |\n",
      "|    time_elapsed       | 1870         |\n",
      "|    total_timesteps    | 192500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -259         |\n",
      "|    explained_variance | 0.773        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38499        |\n",
      "|    policy_loss        | 0.89         |\n",
      "|    reward             | -0.037709642 |\n",
      "|    std                | 1.85e+03     |\n",
      "|    value_loss         | 0.000868     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 38600        |\n",
      "|    time_elapsed       | 1875         |\n",
      "|    total_timesteps    | 193000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -260         |\n",
      "|    explained_variance | 0.641        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38599        |\n",
      "|    policy_loss        | -9.68        |\n",
      "|    reward             | -0.028237423 |\n",
      "|    std                | 1.92e+03     |\n",
      "|    value_loss         | 0.00178      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 38700        |\n",
      "|    time_elapsed       | 1880         |\n",
      "|    total_timesteps    | 193500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -261         |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38699        |\n",
      "|    policy_loss        | -8.34        |\n",
      "|    reward             | 0.0042716297 |\n",
      "|    std                | 1.97e+03     |\n",
      "|    value_loss         | 0.00108      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 38800       |\n",
      "|    time_elapsed       | 1884        |\n",
      "|    total_timesteps    | 194000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -261        |\n",
      "|    explained_variance | 0.173       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38799       |\n",
      "|    policy_loss        | -0.957      |\n",
      "|    reward             | 0.004849553 |\n",
      "|    std                | 2e+03       |\n",
      "|    value_loss         | 2.07e-05    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 38900     |\n",
      "|    time_elapsed       | 1889      |\n",
      "|    total_timesteps    | 194500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -262      |\n",
      "|    explained_variance | 0.8       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38899     |\n",
      "|    policy_loss        | 0.242     |\n",
      "|    reward             | 0.0411818 |\n",
      "|    std                | 2.06e+03  |\n",
      "|    value_loss         | 0.0003    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 39000       |\n",
      "|    time_elapsed       | 1894        |\n",
      "|    total_timesteps    | 195000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -263        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | 0.282       |\n",
      "|    reward             | 0.005009239 |\n",
      "|    std                | 2.13e+03    |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 39100       |\n",
      "|    time_elapsed       | 1898        |\n",
      "|    total_timesteps    | 195500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -264        |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39099       |\n",
      "|    policy_loss        | -3.57       |\n",
      "|    reward             | -0.14181721 |\n",
      "|    std                | 2.21e+03    |\n",
      "|    value_loss         | 0.000286    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 39200        |\n",
      "|    time_elapsed       | 1903         |\n",
      "|    total_timesteps    | 196000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -265         |\n",
      "|    explained_variance | 0.476        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39199        |\n",
      "|    policy_loss        | 2.54         |\n",
      "|    reward             | -0.012092943 |\n",
      "|    std                | 2.28e+03     |\n",
      "|    value_loss         | 0.00015      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 39300       |\n",
      "|    time_elapsed       | 1908        |\n",
      "|    total_timesteps    | 196500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -266        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39299       |\n",
      "|    policy_loss        | -0.641      |\n",
      "|    reward             | -0.13629614 |\n",
      "|    std                | 2.34e+03    |\n",
      "|    value_loss         | 0.000377    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 102          |\n",
      "|    iterations         | 39400        |\n",
      "|    time_elapsed       | 1912         |\n",
      "|    total_timesteps    | 197000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -266         |\n",
      "|    explained_variance | 0.00556      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39399        |\n",
      "|    policy_loss        | -2.17        |\n",
      "|    reward             | -0.010749619 |\n",
      "|    std                | 2.38e+03     |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 39500       |\n",
      "|    time_elapsed       | 1917        |\n",
      "|    total_timesteps    | 197500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -267        |\n",
      "|    explained_variance | -3.26       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39499       |\n",
      "|    policy_loss        | -2.02       |\n",
      "|    reward             | 0.021257477 |\n",
      "|    std                | 2.44e+03    |\n",
      "|    value_loss         | 0.000195    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 39600        |\n",
      "|    time_elapsed       | 1922         |\n",
      "|    total_timesteps    | 198000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -268         |\n",
      "|    explained_variance | -4.55        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39599        |\n",
      "|    policy_loss        | -10.6        |\n",
      "|    reward             | -0.074593216 |\n",
      "|    std                | 2.53e+03     |\n",
      "|    value_loss         | 0.00264      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 39700       |\n",
      "|    time_elapsed       | 1926        |\n",
      "|    total_timesteps    | 198500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -269        |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39699       |\n",
      "|    policy_loss        | -4.28       |\n",
      "|    reward             | -0.09760282 |\n",
      "|    std                | 2.61e+03    |\n",
      "|    value_loss         | 0.000585    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 39800       |\n",
      "|    time_elapsed       | 1931        |\n",
      "|    total_timesteps    | 199000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -270        |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39799       |\n",
      "|    policy_loss        | -5.45       |\n",
      "|    reward             | -0.05409821 |\n",
      "|    std                | 2.69e+03    |\n",
      "|    value_loss         | 0.000708    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 39900        |\n",
      "|    time_elapsed       | 1936         |\n",
      "|    total_timesteps    | 199500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -271         |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39899        |\n",
      "|    policy_loss        | 1.62         |\n",
      "|    reward             | 0.0110012945 |\n",
      "|    std                | 2.75e+03     |\n",
      "|    value_loss         | 0.000794     |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19192464.81\n",
      "total_reward: 9192464.81\n",
      "total_cost: 562492.14\n",
      "total_trades: 82750\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 40000      |\n",
      "|    time_elapsed       | 1941       |\n",
      "|    total_timesteps    | 200000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -271       |\n",
      "|    explained_variance | 0.799      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39999      |\n",
      "|    policy_loss        | -2.07      |\n",
      "|    reward             | 0.02044578 |\n",
      "|    std                | 2.81e+03   |\n",
      "|    value_loss         | 0.000155   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 40100        |\n",
      "|    time_elapsed       | 1945         |\n",
      "|    total_timesteps    | 200500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -272         |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40099        |\n",
      "|    policy_loss        | -0.501       |\n",
      "|    reward             | -0.011152313 |\n",
      "|    std                | 2.89e+03     |\n",
      "|    value_loss         | 0.000144     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 40200         |\n",
      "|    time_elapsed       | 1950          |\n",
      "|    total_timesteps    | 201000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -273          |\n",
      "|    explained_variance | 0.744         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 40199         |\n",
      "|    policy_loss        | -1.16         |\n",
      "|    reward             | -0.0016038475 |\n",
      "|    std                | 2.98e+03      |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 40300        |\n",
      "|    time_elapsed       | 1955         |\n",
      "|    total_timesteps    | 201500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -274         |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40299        |\n",
      "|    policy_loss        | 2.7          |\n",
      "|    reward             | -0.120446324 |\n",
      "|    std                | 3.08e+03     |\n",
      "|    value_loss         | 0.000279     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 40400        |\n",
      "|    time_elapsed       | 1959         |\n",
      "|    total_timesteps    | 202000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -275         |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40399        |\n",
      "|    policy_loss        | 5.05         |\n",
      "|    reward             | -0.080358714 |\n",
      "|    std                | 3.17e+03     |\n",
      "|    value_loss         | 0.000358     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 40500        |\n",
      "|    time_elapsed       | 1964         |\n",
      "|    total_timesteps    | 202500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -275         |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40499        |\n",
      "|    policy_loss        | -4.2         |\n",
      "|    reward             | -0.067310356 |\n",
      "|    std                | 3.22e+03     |\n",
      "|    value_loss         | 0.0106       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 40600        |\n",
      "|    time_elapsed       | 1969         |\n",
      "|    total_timesteps    | 203000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -276         |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40599        |\n",
      "|    policy_loss        | -1.66        |\n",
      "|    reward             | 0.0010886546 |\n",
      "|    std                | 3.29e+03     |\n",
      "|    value_loss         | 4.36e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 40700       |\n",
      "|    time_elapsed       | 1974        |\n",
      "|    total_timesteps    | 203500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -277        |\n",
      "|    explained_variance | 0.522       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40699       |\n",
      "|    policy_loss        | -0.901      |\n",
      "|    reward             | 0.010721069 |\n",
      "|    std                | 3.39e+03    |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 40800        |\n",
      "|    time_elapsed       | 1978         |\n",
      "|    total_timesteps    | 204000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -278         |\n",
      "|    explained_variance | -1.19        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40799        |\n",
      "|    policy_loss        | -7.65        |\n",
      "|    reward             | -0.018657055 |\n",
      "|    std                | 3.51e+03     |\n",
      "|    value_loss         | 0.000912     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 40900       |\n",
      "|    time_elapsed       | 1983        |\n",
      "|    total_timesteps    | 204500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -279        |\n",
      "|    explained_variance | 0.372       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40899       |\n",
      "|    policy_loss        | -5.06       |\n",
      "|    reward             | -0.03375289 |\n",
      "|    std                | 3.62e+03    |\n",
      "|    value_loss         | 0.000509    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 41000        |\n",
      "|    time_elapsed       | 1988         |\n",
      "|    total_timesteps    | 205000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -279         |\n",
      "|    explained_variance | 0.387        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40999        |\n",
      "|    policy_loss        | -33.5        |\n",
      "|    reward             | 0.0068453834 |\n",
      "|    std                | 3.73e+03     |\n",
      "|    value_loss         | 0.0283       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 41100         |\n",
      "|    time_elapsed       | 1993          |\n",
      "|    total_timesteps    | 205500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -280          |\n",
      "|    explained_variance | -0.0232       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 41099         |\n",
      "|    policy_loss        | -3.48         |\n",
      "|    reward             | -0.0033218977 |\n",
      "|    std                | 3.8e+03       |\n",
      "|    value_loss         | 0.000266      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 41200         |\n",
      "|    time_elapsed       | 1997          |\n",
      "|    total_timesteps    | 206000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -281          |\n",
      "|    explained_variance | 0.954         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 41199         |\n",
      "|    policy_loss        | -2.16         |\n",
      "|    reward             | -0.0046187686 |\n",
      "|    std                | 3.9e+03       |\n",
      "|    value_loss         | 6.23e-05      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 41300     |\n",
      "|    time_elapsed       | 2002      |\n",
      "|    total_timesteps    | 206500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -282      |\n",
      "|    explained_variance | 0.703     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41299     |\n",
      "|    policy_loss        | 6.57      |\n",
      "|    reward             | 0.0497439 |\n",
      "|    std                | 4.03e+03  |\n",
      "|    value_loss         | 0.00084   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 41400       |\n",
      "|    time_elapsed       | 2007        |\n",
      "|    total_timesteps    | 207000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -283        |\n",
      "|    explained_variance | 0.709       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41399       |\n",
      "|    policy_loss        | -1.38       |\n",
      "|    reward             | 0.093202606 |\n",
      "|    std                | 4.17e+03    |\n",
      "|    value_loss         | 0.000437    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 41500        |\n",
      "|    time_elapsed       | 2011         |\n",
      "|    total_timesteps    | 207500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -284         |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 41499        |\n",
      "|    policy_loss        | -1.87        |\n",
      "|    reward             | 0.0024752286 |\n",
      "|    std                | 4.31e+03     |\n",
      "|    value_loss         | 8.36e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 41600       |\n",
      "|    time_elapsed       | 2016        |\n",
      "|    total_timesteps    | 208000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -284        |\n",
      "|    explained_variance | -0.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41599       |\n",
      "|    policy_loss        | -7.3        |\n",
      "|    reward             | 0.026124606 |\n",
      "|    std                | 4.42e+03    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 41700        |\n",
      "|    time_elapsed       | 2021         |\n",
      "|    total_timesteps    | 208500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -285         |\n",
      "|    explained_variance | 0.492        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 41699        |\n",
      "|    policy_loss        | -2.46        |\n",
      "|    reward             | -0.010616653 |\n",
      "|    std                | 4.49e+03     |\n",
      "|    value_loss         | 8.57e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 41800       |\n",
      "|    time_elapsed       | 2026        |\n",
      "|    total_timesteps    | 209000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -285        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41799       |\n",
      "|    policy_loss        | 3.89        |\n",
      "|    reward             | 0.037638437 |\n",
      "|    std                | 4.6e+03     |\n",
      "|    value_loss         | 0.00028     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 41900        |\n",
      "|    time_elapsed       | 2030         |\n",
      "|    total_timesteps    | 209500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -286         |\n",
      "|    explained_variance | 0.63         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 41899        |\n",
      "|    policy_loss        | 9.23         |\n",
      "|    reward             | -0.041425776 |\n",
      "|    std                | 4.75e+03     |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 42000       |\n",
      "|    time_elapsed       | 2035        |\n",
      "|    total_timesteps    | 210000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -287        |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41999       |\n",
      "|    policy_loss        | -0.944      |\n",
      "|    reward             | 0.012717204 |\n",
      "|    std                | 4.92e+03    |\n",
      "|    value_loss         | 0.000447    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 42100       |\n",
      "|    time_elapsed       | 2040        |\n",
      "|    total_timesteps    | 210500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -288        |\n",
      "|    explained_variance | 0.668       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42099       |\n",
      "|    policy_loss        | -5.8        |\n",
      "|    reward             | 0.016011726 |\n",
      "|    std                | 5.06e+03    |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 42200       |\n",
      "|    time_elapsed       | 2045        |\n",
      "|    total_timesteps    | 211000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -289        |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42199       |\n",
      "|    policy_loss        | -34.2       |\n",
      "|    reward             | -0.18256661 |\n",
      "|    std                | 5.17e+03    |\n",
      "|    value_loss         | 0.0142      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 42300         |\n",
      "|    time_elapsed       | 2049          |\n",
      "|    total_timesteps    | 211500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -289          |\n",
      "|    explained_variance | -4.65         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 42299         |\n",
      "|    policy_loss        | -9.92         |\n",
      "|    reward             | -0.0031526964 |\n",
      "|    std                | 5.25e+03      |\n",
      "|    value_loss         | 0.00122       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 42400        |\n",
      "|    time_elapsed       | 2054         |\n",
      "|    total_timesteps    | 212000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -290         |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 42399        |\n",
      "|    policy_loss        | 1.61         |\n",
      "|    reward             | -0.015197973 |\n",
      "|    std                | 5.39e+03     |\n",
      "|    value_loss         | 5.29e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 42500       |\n",
      "|    time_elapsed       | 2059        |\n",
      "|    total_timesteps    | 212500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -291        |\n",
      "|    explained_variance | 0.347       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42499       |\n",
      "|    policy_loss        | -10.7       |\n",
      "|    reward             | 0.028143793 |\n",
      "|    std                | 5.57e+03    |\n",
      "|    value_loss         | 0.00165     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 42600       |\n",
      "|    time_elapsed       | 2063        |\n",
      "|    total_timesteps    | 213000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -292        |\n",
      "|    explained_variance | -0.146      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42599       |\n",
      "|    policy_loss        | 14.5        |\n",
      "|    reward             | 0.009927697 |\n",
      "|    std                | 5.75e+03    |\n",
      "|    value_loss         | 0.0031      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 42700      |\n",
      "|    time_elapsed       | 2068       |\n",
      "|    total_timesteps    | 213500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -293       |\n",
      "|    explained_variance | 0.744      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42699      |\n",
      "|    policy_loss        | -64.9      |\n",
      "|    reward             | 0.16544458 |\n",
      "|    std                | 5.92e+03   |\n",
      "|    value_loss         | 0.0548     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 42800     |\n",
      "|    time_elapsed       | 2073      |\n",
      "|    total_timesteps    | 214000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -294      |\n",
      "|    explained_variance | 0.485     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42799     |\n",
      "|    policy_loss        | -111      |\n",
      "|    reward             | -0.252993 |\n",
      "|    std                | 6.08e+03  |\n",
      "|    value_loss         | 0.183     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 42900         |\n",
      "|    time_elapsed       | 2078          |\n",
      "|    total_timesteps    | 214500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -294          |\n",
      "|    explained_variance | 0.497         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 42899         |\n",
      "|    policy_loss        | -12.8         |\n",
      "|    reward             | -0.0007810046 |\n",
      "|    std                | 6.23e+03      |\n",
      "|    value_loss         | 0.00203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 43000        |\n",
      "|    time_elapsed       | 2083         |\n",
      "|    total_timesteps    | 215000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -295         |\n",
      "|    explained_variance | -19.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 42999        |\n",
      "|    policy_loss        | -1.07        |\n",
      "|    reward             | -0.025474083 |\n",
      "|    std                | 6.4e+03      |\n",
      "|    value_loss         | 7.86e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 43100      |\n",
      "|    time_elapsed       | 2088       |\n",
      "|    total_timesteps    | 215500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -296       |\n",
      "|    explained_variance | 0.864      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43099      |\n",
      "|    policy_loss        | 1.74       |\n",
      "|    reward             | 0.02059613 |\n",
      "|    std                | 6.6e+03    |\n",
      "|    value_loss         | 0.000154   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 43200       |\n",
      "|    time_elapsed       | 2092        |\n",
      "|    total_timesteps    | 216000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -297        |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43199       |\n",
      "|    policy_loss        | 1.75        |\n",
      "|    reward             | -0.03653717 |\n",
      "|    std                | 6.83e+03    |\n",
      "|    value_loss         | 7.73e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 2097        |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -298        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | 1.22        |\n",
      "|    reward             | -0.07924822 |\n",
      "|    std                | 7.05e+03    |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 103            |\n",
      "|    iterations         | 43400          |\n",
      "|    time_elapsed       | 2102           |\n",
      "|    total_timesteps    | 217000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -298           |\n",
      "|    explained_variance | -2.68          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 43399          |\n",
      "|    policy_loss        | -4.63          |\n",
      "|    reward             | -0.00015620732 |\n",
      "|    std                | 7.21e+03       |\n",
      "|    value_loss         | 0.000303       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 43500        |\n",
      "|    time_elapsed       | 2106         |\n",
      "|    total_timesteps    | 217500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -299         |\n",
      "|    explained_variance | -2.4         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43499        |\n",
      "|    policy_loss        | 3.69         |\n",
      "|    reward             | 0.0032880604 |\n",
      "|    std                | 7.39e+03     |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 43600         |\n",
      "|    time_elapsed       | 2111          |\n",
      "|    total_timesteps    | 218000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -300          |\n",
      "|    explained_variance | 0.269         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 43599         |\n",
      "|    policy_loss        | 5.08          |\n",
      "|    reward             | -0.0029435628 |\n",
      "|    std                | 7.63e+03      |\n",
      "|    value_loss         | 0.000354      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 43700        |\n",
      "|    time_elapsed       | 2116         |\n",
      "|    total_timesteps    | 218500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -301         |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43699        |\n",
      "|    policy_loss        | 0.0306       |\n",
      "|    reward             | 0.0024609533 |\n",
      "|    std                | 7.92e+03     |\n",
      "|    value_loss         | 5.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 43800        |\n",
      "|    time_elapsed       | 2121         |\n",
      "|    total_timesteps    | 219000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -302         |\n",
      "|    explained_variance | 0.72         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43799        |\n",
      "|    policy_loss        | -5.08        |\n",
      "|    reward             | -0.023131903 |\n",
      "|    std                | 8.2e+03      |\n",
      "|    value_loss         | 0.00034      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 43900       |\n",
      "|    time_elapsed       | 2125        |\n",
      "|    total_timesteps    | 219500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -303        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43899       |\n",
      "|    policy_loss        | 60.6        |\n",
      "|    reward             | 0.067432076 |\n",
      "|    std                | 8.39e+03    |\n",
      "|    value_loss         | 0.0411      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 44000        |\n",
      "|    time_elapsed       | 2130         |\n",
      "|    total_timesteps    | 220000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -303         |\n",
      "|    explained_variance | -0.124       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | -8.34        |\n",
      "|    reward             | 0.0014130194 |\n",
      "|    std                | 8.49e+03     |\n",
      "|    value_loss         | 0.000813     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 44100       |\n",
      "|    time_elapsed       | 2135        |\n",
      "|    total_timesteps    | 220500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -304        |\n",
      "|    explained_variance | 0.578       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44099       |\n",
      "|    policy_loss        | 1.51        |\n",
      "|    reward             | 0.021922002 |\n",
      "|    std                | 8.68e+03    |\n",
      "|    value_loss         | 0.000116    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 44200       |\n",
      "|    time_elapsed       | 2140        |\n",
      "|    total_timesteps    | 221000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -305        |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44199       |\n",
      "|    policy_loss        | -0.705      |\n",
      "|    reward             | 0.014816937 |\n",
      "|    std                | 8.94e+03    |\n",
      "|    value_loss         | 0.000314    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 44300       |\n",
      "|    time_elapsed       | 2144        |\n",
      "|    total_timesteps    | 221500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -306        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44299       |\n",
      "|    policy_loss        | 0.818       |\n",
      "|    reward             | -0.14760305 |\n",
      "|    std                | 9.23e+03    |\n",
      "|    value_loss         | 5.36e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 44400       |\n",
      "|    time_elapsed       | 2149        |\n",
      "|    total_timesteps    | 222000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -307        |\n",
      "|    explained_variance | 0.61        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44399       |\n",
      "|    policy_loss        | -2.04       |\n",
      "|    reward             | 0.010872784 |\n",
      "|    std                | 9.51e+03    |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 44500       |\n",
      "|    time_elapsed       | 2154        |\n",
      "|    total_timesteps    | 222500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -307        |\n",
      "|    explained_variance | 0.469       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44499       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.034065813 |\n",
      "|    std                | 9.75e+03    |\n",
      "|    value_loss         | 0.00386     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 44600        |\n",
      "|    time_elapsed       | 2159         |\n",
      "|    total_timesteps    | 223000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -308         |\n",
      "|    explained_variance | -2.03        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 44599        |\n",
      "|    policy_loss        | -2.78        |\n",
      "|    reward             | 0.0032850024 |\n",
      "|    std                | 9.92e+03     |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 44700      |\n",
      "|    time_elapsed       | 2163       |\n",
      "|    total_timesteps    | 223500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -309       |\n",
      "|    explained_variance | 0.878      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44699      |\n",
      "|    policy_loss        | -6.16      |\n",
      "|    reward             | 0.01401249 |\n",
      "|    std                | 1.02e+04   |\n",
      "|    value_loss         | 0.000458   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 44800        |\n",
      "|    time_elapsed       | 2168         |\n",
      "|    total_timesteps    | 224000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -309         |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 44799        |\n",
      "|    policy_loss        | -1.73        |\n",
      "|    reward             | -0.005320194 |\n",
      "|    std                | 1.05e+04     |\n",
      "|    value_loss         | 5.78e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 44900       |\n",
      "|    time_elapsed       | 2173        |\n",
      "|    total_timesteps    | 224500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -311        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44899       |\n",
      "|    policy_loss        | 7.92        |\n",
      "|    reward             | -0.03788201 |\n",
      "|    std                | 1.09e+04    |\n",
      "|    value_loss         | 0.000885    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 45000        |\n",
      "|    time_elapsed       | 2178         |\n",
      "|    total_timesteps    | 225000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -311         |\n",
      "|    explained_variance | 0.614        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 44999        |\n",
      "|    policy_loss        | -14.4        |\n",
      "|    reward             | -0.027608937 |\n",
      "|    std                | 1.13e+04     |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 45100       |\n",
      "|    time_elapsed       | 2182        |\n",
      "|    total_timesteps    | 225500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -312        |\n",
      "|    explained_variance | 0.491       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 45099       |\n",
      "|    policy_loss        | 11.4        |\n",
      "|    reward             | -0.07680087 |\n",
      "|    std                | 1.15e+04    |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 45200        |\n",
      "|    time_elapsed       | 2187         |\n",
      "|    total_timesteps    | 226000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -313         |\n",
      "|    explained_variance | 0.748        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 45199        |\n",
      "|    policy_loss        | -2.65        |\n",
      "|    reward             | -0.006371082 |\n",
      "|    std                | 1.17e+04     |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 45300         |\n",
      "|    time_elapsed       | 2192          |\n",
      "|    total_timesteps    | 226500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -313          |\n",
      "|    explained_variance | -1.43         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45299         |\n",
      "|    policy_loss        | -3.05         |\n",
      "|    reward             | -0.0005804215 |\n",
      "|    std                | 1.21e+04      |\n",
      "|    value_loss         | 0.000227      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 45400      |\n",
      "|    time_elapsed       | 2196       |\n",
      "|    total_timesteps    | 227000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -314       |\n",
      "|    explained_variance | 0.815      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45399      |\n",
      "|    policy_loss        | 4.09       |\n",
      "|    reward             | 0.02063266 |\n",
      "|    std                | 1.25e+04   |\n",
      "|    value_loss         | 0.00027    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 45500        |\n",
      "|    time_elapsed       | 2201         |\n",
      "|    total_timesteps    | 227500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -315         |\n",
      "|    explained_variance | -5.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 45499        |\n",
      "|    policy_loss        | 7.05         |\n",
      "|    reward             | -0.042743802 |\n",
      "|    std                | 1.28e+04     |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 45600        |\n",
      "|    time_elapsed       | 2206         |\n",
      "|    total_timesteps    | 228000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -316         |\n",
      "|    explained_variance | 0.56         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 45599        |\n",
      "|    policy_loss        | -4.79        |\n",
      "|    reward             | -0.058313258 |\n",
      "|    std                | 1.31e+04     |\n",
      "|    value_loss         | 0.00195      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 45700      |\n",
      "|    time_elapsed       | 2211       |\n",
      "|    total_timesteps    | 228500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -316       |\n",
      "|    explained_variance | 0.535      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45699      |\n",
      "|    policy_loss        | 108        |\n",
      "|    reward             | 0.09183979 |\n",
      "|    std                | 1.34e+04   |\n",
      "|    value_loss         | 0.136      |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 80\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17999256.26\n",
      "total_reward: 7999256.26\n",
      "total_cost: 561948.15\n",
      "total_trades: 82645\n",
      "Sharpe: 0.457\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 45800       |\n",
      "|    time_elapsed       | 2216        |\n",
      "|    total_timesteps    | 229000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -317        |\n",
      "|    explained_variance | 0.0498      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 45799       |\n",
      "|    policy_loss        | -3.26       |\n",
      "|    reward             | 0.022996334 |\n",
      "|    std                | 1.36e+04    |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 45900         |\n",
      "|    time_elapsed       | 2220          |\n",
      "|    total_timesteps    | 229500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -318          |\n",
      "|    explained_variance | 0.939         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45899         |\n",
      "|    policy_loss        | 1.98          |\n",
      "|    reward             | -0.0037784972 |\n",
      "|    std                | 1.4e+04       |\n",
      "|    value_loss         | 4.88e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 46000       |\n",
      "|    time_elapsed       | 2225        |\n",
      "|    total_timesteps    | 230000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -319        |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 45999       |\n",
      "|    policy_loss        | -6.73       |\n",
      "|    reward             | -0.05175686 |\n",
      "|    std                | 1.44e+04    |\n",
      "|    value_loss         | 0.000764    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 46100       |\n",
      "|    time_elapsed       | 2230        |\n",
      "|    total_timesteps    | 230500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -319        |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46099       |\n",
      "|    policy_loss        | 9.61        |\n",
      "|    reward             | 0.020284846 |\n",
      "|    std                | 1.49e+04    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 46200      |\n",
      "|    time_elapsed       | 2235       |\n",
      "|    total_timesteps    | 231000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -320       |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46199      |\n",
      "|    policy_loss        | 4.07       |\n",
      "|    reward             | 0.06636319 |\n",
      "|    std                | 1.53e+04   |\n",
      "|    value_loss         | 0.000531   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 46300       |\n",
      "|    time_elapsed       | 2239        |\n",
      "|    total_timesteps    | 231500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -321        |\n",
      "|    explained_variance | -0.225      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46299       |\n",
      "|    policy_loss        | 3.56        |\n",
      "|    reward             | 0.008650178 |\n",
      "|    std                | 1.55e+04    |\n",
      "|    value_loss         | 0.000264    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 46400       |\n",
      "|    time_elapsed       | 2244        |\n",
      "|    total_timesteps    | 232000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -321        |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46399       |\n",
      "|    policy_loss        | -3.85       |\n",
      "|    reward             | 0.015448546 |\n",
      "|    std                | 1.59e+04    |\n",
      "|    value_loss         | 0.000215    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 46500        |\n",
      "|    time_elapsed       | 2249         |\n",
      "|    total_timesteps    | 232500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -322         |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 46499        |\n",
      "|    policy_loss        | 9.49         |\n",
      "|    reward             | -0.026940843 |\n",
      "|    std                | 1.64e+04     |\n",
      "|    value_loss         | 0.000934     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 46600       |\n",
      "|    time_elapsed       | 2254        |\n",
      "|    total_timesteps    | 233000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -323        |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46599       |\n",
      "|    policy_loss        | -14         |\n",
      "|    reward             | -0.03329608 |\n",
      "|    std                | 1.69e+04    |\n",
      "|    value_loss         | 0.00216     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 46700      |\n",
      "|    time_elapsed       | 2258       |\n",
      "|    total_timesteps    | 233500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -324       |\n",
      "|    explained_variance | 0.638      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46699      |\n",
      "|    policy_loss        | -6.48      |\n",
      "|    reward             | 0.02798755 |\n",
      "|    std                | 1.74e+04   |\n",
      "|    value_loss         | 0.0014     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 46800       |\n",
      "|    time_elapsed       | 2263        |\n",
      "|    total_timesteps    | 234000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -325        |\n",
      "|    explained_variance | 0.774       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46799       |\n",
      "|    policy_loss        | -12.4       |\n",
      "|    reward             | -0.12104514 |\n",
      "|    std                | 1.78e+04    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 46900        |\n",
      "|    time_elapsed       | 2268         |\n",
      "|    total_timesteps    | 234500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -325         |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 46899        |\n",
      "|    policy_loss        | -0.125       |\n",
      "|    reward             | -0.013355202 |\n",
      "|    std                | 1.81e+04     |\n",
      "|    value_loss         | 1.74e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 47000      |\n",
      "|    time_elapsed       | 2273       |\n",
      "|    total_timesteps    | 235000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -326       |\n",
      "|    explained_variance | 0.191      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46999      |\n",
      "|    policy_loss        | 19.9       |\n",
      "|    reward             | -0.0284066 |\n",
      "|    std                | 1.85e+04   |\n",
      "|    value_loss         | 0.0041     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 47100       |\n",
      "|    time_elapsed       | 2278        |\n",
      "|    total_timesteps    | 235500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -327        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47099       |\n",
      "|    policy_loss        | 3.56        |\n",
      "|    reward             | 0.021008888 |\n",
      "|    std                | 1.91e+04    |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 47200       |\n",
      "|    time_elapsed       | 2282        |\n",
      "|    total_timesteps    | 236000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -328        |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47199       |\n",
      "|    policy_loss        | -5.68       |\n",
      "|    reward             | -0.03891007 |\n",
      "|    std                | 1.97e+04    |\n",
      "|    value_loss         | 0.000599    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 47300       |\n",
      "|    time_elapsed       | 2287        |\n",
      "|    total_timesteps    | 236500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -328        |\n",
      "|    explained_variance | 0.705       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47299       |\n",
      "|    policy_loss        | -3.74       |\n",
      "|    reward             | 0.026116215 |\n",
      "|    std                | 2.02e+04    |\n",
      "|    value_loss         | 0.000327    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 47400      |\n",
      "|    time_elapsed       | 2292       |\n",
      "|    total_timesteps    | 237000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -329       |\n",
      "|    explained_variance | -6.25      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47399      |\n",
      "|    policy_loss        | 164        |\n",
      "|    reward             | 0.29637584 |\n",
      "|    std                | 2.06e+04   |\n",
      "|    value_loss         | 0.287      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 47500        |\n",
      "|    time_elapsed       | 2297         |\n",
      "|    total_timesteps    | 237500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -330         |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 47499        |\n",
      "|    policy_loss        | -4.37        |\n",
      "|    reward             | -0.033192154 |\n",
      "|    std                | 2.1e+04      |\n",
      "|    value_loss         | 0.00018      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 47600        |\n",
      "|    time_elapsed       | 2301         |\n",
      "|    total_timesteps    | 238000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -330         |\n",
      "|    explained_variance | 0.448        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 47599        |\n",
      "|    policy_loss        | -16.6        |\n",
      "|    reward             | -0.011848499 |\n",
      "|    std                | 2.15e+04     |\n",
      "|    value_loss         | 0.00305      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 47700        |\n",
      "|    time_elapsed       | 2306         |\n",
      "|    total_timesteps    | 238500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -331         |\n",
      "|    explained_variance | 0.547        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 47699        |\n",
      "|    policy_loss        | 11.7         |\n",
      "|    reward             | -0.011618182 |\n",
      "|    std                | 2.21e+04     |\n",
      "|    value_loss         | 0.00153      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 47800       |\n",
      "|    time_elapsed       | 2311        |\n",
      "|    total_timesteps    | 239000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -332        |\n",
      "|    explained_variance | 0.813       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47799       |\n",
      "|    policy_loss        | 26.9        |\n",
      "|    reward             | 0.013436205 |\n",
      "|    std                | 2.28e+04    |\n",
      "|    value_loss         | 0.008       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 47900        |\n",
      "|    time_elapsed       | 2316         |\n",
      "|    total_timesteps    | 239500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -333         |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 47899        |\n",
      "|    policy_loss        | 0.49         |\n",
      "|    reward             | 0.0049067084 |\n",
      "|    std                | 2.35e+04     |\n",
      "|    value_loss         | 0.000547     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 48000      |\n",
      "|    time_elapsed       | 2320       |\n",
      "|    total_timesteps    | 240000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -333       |\n",
      "|    explained_variance | 0.592      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47999      |\n",
      "|    policy_loss        | 9.72       |\n",
      "|    reward             | -0.0565016 |\n",
      "|    std                | 2.4e+04    |\n",
      "|    value_loss         | 0.00275    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 48100       |\n",
      "|    time_elapsed       | 2325        |\n",
      "|    total_timesteps    | 240500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -334        |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | -8.4        |\n",
      "|    reward             | 0.017865863 |\n",
      "|    std                | 2.44e+04    |\n",
      "|    value_loss         | 0.000743    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 48200       |\n",
      "|    time_elapsed       | 2330        |\n",
      "|    total_timesteps    | 241000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -335        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48199       |\n",
      "|    policy_loss        | -4.44       |\n",
      "|    reward             | 0.008466337 |\n",
      "|    std                | 2.51e+04    |\n",
      "|    value_loss         | 0.000198    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 48300        |\n",
      "|    time_elapsed       | 2335         |\n",
      "|    total_timesteps    | 241500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -335         |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 48299        |\n",
      "|    policy_loss        | -0.523       |\n",
      "|    reward             | -0.009579263 |\n",
      "|    std                | 2.58e+04     |\n",
      "|    value_loss         | 1.53e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 48400      |\n",
      "|    time_elapsed       | 2340       |\n",
      "|    total_timesteps    | 242000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -336       |\n",
      "|    explained_variance | 0.682      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48399      |\n",
      "|    policy_loss        | 6.63       |\n",
      "|    reward             | 0.08362479 |\n",
      "|    std                | 2.66e+04   |\n",
      "|    value_loss         | 0.0012     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 2345        |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -337        |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48499       |\n",
      "|    policy_loss        | -7.01       |\n",
      "|    reward             | -0.10687311 |\n",
      "|    std                | 2.72e+04    |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 48600       |\n",
      "|    time_elapsed       | 2349        |\n",
      "|    total_timesteps    | 243000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -338        |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48599       |\n",
      "|    policy_loss        | 121         |\n",
      "|    reward             | 0.117548674 |\n",
      "|    std                | 2.77e+04    |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 2354         |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -338         |\n",
      "|    explained_variance | 0.378        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | 8.83         |\n",
      "|    reward             | 0.0011163877 |\n",
      "|    std                | 2.83e+04     |\n",
      "|    value_loss         | 0.000943     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 48800       |\n",
      "|    time_elapsed       | 2359        |\n",
      "|    total_timesteps    | 244000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -339        |\n",
      "|    explained_variance | 0.693       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48799       |\n",
      "|    policy_loss        | 3.95        |\n",
      "|    reward             | 0.016016237 |\n",
      "|    std                | 2.91e+04    |\n",
      "|    value_loss         | 0.000282    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 48900        |\n",
      "|    time_elapsed       | 2363         |\n",
      "|    total_timesteps    | 244500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -340         |\n",
      "|    explained_variance | -5.04        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 48899        |\n",
      "|    policy_loss        | 5.4          |\n",
      "|    reward             | -0.021966422 |\n",
      "|    std                | 3e+04        |\n",
      "|    value_loss         | 0.000381     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 2368        |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -341        |\n",
      "|    explained_variance | 0.167       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | -21.6       |\n",
      "|    reward             | 0.031106291 |\n",
      "|    std                | 3.1e+04     |\n",
      "|    value_loss         | 0.00548     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 49100       |\n",
      "|    time_elapsed       | 2373        |\n",
      "|    total_timesteps    | 245500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -342        |\n",
      "|    explained_variance | 0.371       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49099       |\n",
      "|    policy_loss        | -94.2       |\n",
      "|    reward             | -0.27568945 |\n",
      "|    std                | 3.19e+04    |\n",
      "|    value_loss         | 0.0901      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 49200         |\n",
      "|    time_elapsed       | 2378          |\n",
      "|    total_timesteps    | 246000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -342          |\n",
      "|    explained_variance | 0.873         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 49199         |\n",
      "|    policy_loss        | 2.65          |\n",
      "|    reward             | -0.0061414186 |\n",
      "|    std                | 3.24e+04      |\n",
      "|    value_loss         | 6.57e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 49300        |\n",
      "|    time_elapsed       | 2382         |\n",
      "|    total_timesteps    | 246500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -343         |\n",
      "|    explained_variance | -0.0155      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49299        |\n",
      "|    policy_loss        | 1.72         |\n",
      "|    reward             | -0.014943598 |\n",
      "|    std                | 3.31e+04     |\n",
      "|    value_loss         | 8.63e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 49400      |\n",
      "|    time_elapsed       | 2387       |\n",
      "|    total_timesteps    | 247000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -344       |\n",
      "|    explained_variance | 0.612      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49399      |\n",
      "|    policy_loss        | -1.55      |\n",
      "|    reward             | 0.01105749 |\n",
      "|    std                | 3.41e+04   |\n",
      "|    value_loss         | 0.000126   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 49500        |\n",
      "|    time_elapsed       | 2392         |\n",
      "|    total_timesteps    | 247500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -344         |\n",
      "|    explained_variance | 0.548        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49499        |\n",
      "|    policy_loss        | 0.253        |\n",
      "|    reward             | -0.018504415 |\n",
      "|    std                | 3.52e+04     |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 49600        |\n",
      "|    time_elapsed       | 2397         |\n",
      "|    total_timesteps    | 248000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -345         |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | 10.1         |\n",
      "|    reward             | -0.025645135 |\n",
      "|    std                | 3.63e+04     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 49700      |\n",
      "|    time_elapsed       | 2401       |\n",
      "|    total_timesteps    | 248500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -346       |\n",
      "|    explained_variance | 0.539      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49699      |\n",
      "|    policy_loss        | -22.5      |\n",
      "|    reward             | 0.06365862 |\n",
      "|    std                | 3.73e+04   |\n",
      "|    value_loss         | 0.00555    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 49800        |\n",
      "|    time_elapsed       | 2406         |\n",
      "|    total_timesteps    | 249000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -347         |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49799        |\n",
      "|    policy_loss        | -1.71        |\n",
      "|    reward             | -0.010400424 |\n",
      "|    std                | 3.8e+04      |\n",
      "|    value_loss         | 2.53e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 49900       |\n",
      "|    time_elapsed       | 2411        |\n",
      "|    total_timesteps    | 249500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -347        |\n",
      "|    explained_variance | 0.652       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49899       |\n",
      "|    policy_loss        | -2.51       |\n",
      "|    reward             | 0.023073895 |\n",
      "|    std                | 3.9e+04     |\n",
      "|    value_loss         | 0.000256    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 50000       |\n",
      "|    time_elapsed       | 2416        |\n",
      "|    total_timesteps    | 250000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -348        |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49999       |\n",
      "|    policy_loss        | -2.07       |\n",
      "|    reward             | 0.031082435 |\n",
      "|    std                | 4.03e+04    |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 50100       |\n",
      "|    time_elapsed       | 2421        |\n",
      "|    total_timesteps    | 250500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -349        |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50099       |\n",
      "|    policy_loss        | 1.71        |\n",
      "|    reward             | 0.070788175 |\n",
      "|    std                | 4.15e+04    |\n",
      "|    value_loss         | 0.00106     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 50200      |\n",
      "|    time_elapsed       | 2426       |\n",
      "|    total_timesteps    | 251000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -350       |\n",
      "|    explained_variance | 0.473      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50199      |\n",
      "|    policy_loss        | -28.5      |\n",
      "|    reward             | 0.04529714 |\n",
      "|    std                | 4.27e+04   |\n",
      "|    value_loss         | 0.00694    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 50300        |\n",
      "|    time_elapsed       | 2430         |\n",
      "|    total_timesteps    | 251500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -351         |\n",
      "|    explained_variance | -1.57        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 50299        |\n",
      "|    policy_loss        | 7.48         |\n",
      "|    reward             | -0.089872085 |\n",
      "|    std                | 4.36e+04     |\n",
      "|    value_loss         | 0.00157      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 50400         |\n",
      "|    time_elapsed       | 2435          |\n",
      "|    total_timesteps    | 252000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -351          |\n",
      "|    explained_variance | 0.0944        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 50399         |\n",
      "|    policy_loss        | 1.48          |\n",
      "|    reward             | 0.00021259864 |\n",
      "|    std                | 4.43e+04      |\n",
      "|    value_loss         | 5.23e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 50500        |\n",
      "|    time_elapsed       | 2440         |\n",
      "|    total_timesteps    | 252500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -352         |\n",
      "|    explained_variance | 0.793        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 50499        |\n",
      "|    policy_loss        | -4.72        |\n",
      "|    reward             | -0.011951139 |\n",
      "|    std                | 4.55e+04     |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 50600       |\n",
      "|    time_elapsed       | 2445        |\n",
      "|    total_timesteps    | 253000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -353        |\n",
      "|    explained_variance | -3.23       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50599       |\n",
      "|    policy_loss        | 8.84        |\n",
      "|    reward             | 0.029979095 |\n",
      "|    std                | 4.7e+04     |\n",
      "|    value_loss         | 0.000789    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 50700      |\n",
      "|    time_elapsed       | 2449       |\n",
      "|    total_timesteps    | 253500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -354       |\n",
      "|    explained_variance | 0.815      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50699      |\n",
      "|    policy_loss        | -14.5      |\n",
      "|    reward             | 0.08126596 |\n",
      "|    std                | 4.85e+04   |\n",
      "|    value_loss         | 0.00235    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 50800        |\n",
      "|    time_elapsed       | 2454         |\n",
      "|    total_timesteps    | 254000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -355         |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 50799        |\n",
      "|    policy_loss        | -11          |\n",
      "|    reward             | -0.043217678 |\n",
      "|    std                | 5e+04        |\n",
      "|    value_loss         | 0.00383      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 50900      |\n",
      "|    time_elapsed       | 2459       |\n",
      "|    total_timesteps    | 254500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -355       |\n",
      "|    explained_variance | 0.673      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50899      |\n",
      "|    policy_loss        | -213       |\n",
      "|    reward             | -0.4078647 |\n",
      "|    std                | 5.11e+04   |\n",
      "|    value_loss         | 0.378      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 51000       |\n",
      "|    time_elapsed       | 2464        |\n",
      "|    total_timesteps    | 255000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -356        |\n",
      "|    explained_variance | 0.356       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50999       |\n",
      "|    policy_loss        | 3.56        |\n",
      "|    reward             | 0.013985115 |\n",
      "|    std                | 5.21e+04    |\n",
      "|    value_loss         | 0.000143    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 51100        |\n",
      "|    time_elapsed       | 2469         |\n",
      "|    total_timesteps    | 255500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -357         |\n",
      "|    explained_variance | -12.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51099        |\n",
      "|    policy_loss        | 1.7          |\n",
      "|    reward             | -0.008722486 |\n",
      "|    std                | 5.36e+04     |\n",
      "|    value_loss         | 3.58e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 51200       |\n",
      "|    time_elapsed       | 2473        |\n",
      "|    total_timesteps    | 256000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -358        |\n",
      "|    explained_variance | 0.101       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51199       |\n",
      "|    policy_loss        | -8.75       |\n",
      "|    reward             | 0.023826512 |\n",
      "|    std                | 5.56e+04    |\n",
      "|    value_loss         | 0.000921    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 51300        |\n",
      "|    time_elapsed       | 2478         |\n",
      "|    total_timesteps    | 256500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -359         |\n",
      "|    explained_variance | 0.745        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51299        |\n",
      "|    policy_loss        | 5.92         |\n",
      "|    reward             | -0.008205039 |\n",
      "|    std                | 5.75e+04     |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 51400       |\n",
      "|    time_elapsed       | 2483        |\n",
      "|    total_timesteps    | 257000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -360        |\n",
      "|    explained_variance | 0.391       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51399       |\n",
      "|    policy_loss        | 19.9        |\n",
      "|    reward             | -0.04339449 |\n",
      "|    std                | 5.93e+04    |\n",
      "|    value_loss         | 0.00575     |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18210834.88\n",
      "total_reward: 8210834.88\n",
      "total_cost: 561344.97\n",
      "total_trades: 82422\n",
      "Sharpe: 0.563\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 2488        |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -360        |\n",
      "|    explained_variance | -3.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | -3.71       |\n",
      "|    reward             | 0.002290077 |\n",
      "|    std                | 6.04e+04    |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 51600       |\n",
      "|    time_elapsed       | 2492        |\n",
      "|    total_timesteps    | 258000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -361        |\n",
      "|    explained_variance | 0.655       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51599       |\n",
      "|    policy_loss        | -7.63       |\n",
      "|    reward             | 0.020222005 |\n",
      "|    std                | 6.16e+04    |\n",
      "|    value_loss         | 0.000523    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 51700        |\n",
      "|    time_elapsed       | 2497         |\n",
      "|    total_timesteps    | 258500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -362         |\n",
      "|    explained_variance | 0.398        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51699        |\n",
      "|    policy_loss        | 13.2         |\n",
      "|    reward             | -0.003293868 |\n",
      "|    std                | 6.34e+04     |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 51800      |\n",
      "|    time_elapsed       | 2502       |\n",
      "|    total_timesteps    | 259000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -362       |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51799      |\n",
      "|    policy_loss        | 13.6       |\n",
      "|    reward             | 0.08643499 |\n",
      "|    std                | 6.54e+04   |\n",
      "|    value_loss         | 0.00146    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 51900        |\n",
      "|    time_elapsed       | 2507         |\n",
      "|    total_timesteps    | 259500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -363         |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51899        |\n",
      "|    policy_loss        | 6.64         |\n",
      "|    reward             | -0.033447366 |\n",
      "|    std                | 6.74e+04     |\n",
      "|    value_loss         | 0.000581     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 52000       |\n",
      "|    time_elapsed       | 2512        |\n",
      "|    total_timesteps    | 260000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -364        |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51999       |\n",
      "|    policy_loss        | -23.8       |\n",
      "|    reward             | 0.021750571 |\n",
      "|    std                | 6.9e+04     |\n",
      "|    value_loss         | 0.00573     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 52100         |\n",
      "|    time_elapsed       | 2516          |\n",
      "|    total_timesteps    | 260500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -364          |\n",
      "|    explained_variance | -0.681        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 52099         |\n",
      "|    policy_loss        | -9.29         |\n",
      "|    reward             | -0.0070624594 |\n",
      "|    std                | 7.02e+04      |\n",
      "|    value_loss         | 0.000655      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 52200        |\n",
      "|    time_elapsed       | 2521         |\n",
      "|    total_timesteps    | 261000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -365         |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 52199        |\n",
      "|    policy_loss        | -0.66        |\n",
      "|    reward             | -0.008692864 |\n",
      "|    std                | 7.17e+04     |\n",
      "|    value_loss         | 9.64e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 2526        |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -366        |\n",
      "|    explained_variance | 0.776       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52299       |\n",
      "|    policy_loss        | -24.7       |\n",
      "|    reward             | 0.019643575 |\n",
      "|    std                | 7.37e+04    |\n",
      "|    value_loss         | 0.00582     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 52400        |\n",
      "|    time_elapsed       | 2531         |\n",
      "|    total_timesteps    | 262000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -367         |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 52399        |\n",
      "|    policy_loss        | 22.2         |\n",
      "|    reward             | -0.026642442 |\n",
      "|    std                | 7.59e+04     |\n",
      "|    value_loss         | 0.00383      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 52500       |\n",
      "|    time_elapsed       | 2536        |\n",
      "|    total_timesteps    | 262500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -368        |\n",
      "|    explained_variance | 0.2         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52499       |\n",
      "|    policy_loss        | 0.795       |\n",
      "|    reward             | -0.03404616 |\n",
      "|    std                | 7.8e+04     |\n",
      "|    value_loss         | 0.000411    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 103            |\n",
      "|    iterations         | 52600          |\n",
      "|    time_elapsed       | 2540           |\n",
      "|    total_timesteps    | 263000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -368           |\n",
      "|    explained_variance | 0.989          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 52599          |\n",
      "|    policy_loss        | 28.2           |\n",
      "|    reward             | -0.00093693315 |\n",
      "|    std                | 7.97e+04       |\n",
      "|    value_loss         | 0.00668        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 52700       |\n",
      "|    time_elapsed       | 2545        |\n",
      "|    total_timesteps    | 263500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -369        |\n",
      "|    explained_variance | -2.41       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52699       |\n",
      "|    policy_loss        | 2.18        |\n",
      "|    reward             | 0.009001478 |\n",
      "|    std                | 8.09e+04    |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 52800       |\n",
      "|    time_elapsed       | 2550        |\n",
      "|    total_timesteps    | 264000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -369        |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52799       |\n",
      "|    policy_loss        | 2.58        |\n",
      "|    reward             | 0.016093593 |\n",
      "|    std                | 8.29e+04    |\n",
      "|    value_loss         | 0.000196    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 52900        |\n",
      "|    time_elapsed       | 2555         |\n",
      "|    total_timesteps    | 264500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -370         |\n",
      "|    explained_variance | 0.0299       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 52899        |\n",
      "|    policy_loss        | -2.63        |\n",
      "|    reward             | -0.022878915 |\n",
      "|    std                | 8.53e+04     |\n",
      "|    value_loss         | 0.000516     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 2559        |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -371        |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | 19.4        |\n",
      "|    reward             | 0.008712022 |\n",
      "|    std                | 8.79e+04    |\n",
      "|    value_loss         | 0.00368     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 53100       |\n",
      "|    time_elapsed       | 2564        |\n",
      "|    total_timesteps    | 265500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -372        |\n",
      "|    explained_variance | -4.94       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53099       |\n",
      "|    policy_loss        | 44.7        |\n",
      "|    reward             | 0.048322245 |\n",
      "|    std                | 9.03e+04    |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 53200      |\n",
      "|    time_elapsed       | 2569       |\n",
      "|    total_timesteps    | 266000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -372       |\n",
      "|    explained_variance | 0.654      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53199      |\n",
      "|    policy_loss        | 23.5       |\n",
      "|    reward             | 0.14939332 |\n",
      "|    std                | 9.2e+04    |\n",
      "|    value_loss         | 0.00532    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 53300         |\n",
      "|    time_elapsed       | 2574          |\n",
      "|    total_timesteps    | 266500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -373          |\n",
      "|    explained_variance | 0.722         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 53299         |\n",
      "|    policy_loss        | -4.49         |\n",
      "|    reward             | 0.00066139456 |\n",
      "|    std                | 9.32e+04      |\n",
      "|    value_loss         | 0.000613      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 53400        |\n",
      "|    time_elapsed       | 2578         |\n",
      "|    total_timesteps    | 267000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -373         |\n",
      "|    explained_variance | -0.806       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 53399        |\n",
      "|    policy_loss        | 1.24         |\n",
      "|    reward             | -0.028849356 |\n",
      "|    std                | 9.55e+04     |\n",
      "|    value_loss         | 0.000208     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 53500     |\n",
      "|    time_elapsed       | 2583      |\n",
      "|    total_timesteps    | 267500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -374      |\n",
      "|    explained_variance | 0.574     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53499     |\n",
      "|    policy_loss        | -2.31     |\n",
      "|    reward             | 0.0383719 |\n",
      "|    std                | 9.84e+04  |\n",
      "|    value_loss         | 0.000276  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 53600       |\n",
      "|    time_elapsed       | 2588        |\n",
      "|    total_timesteps    | 268000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -375        |\n",
      "|    explained_variance | -1.79       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53599       |\n",
      "|    policy_loss        | 5.12        |\n",
      "|    reward             | 0.044260513 |\n",
      "|    std                | 1.01e+05    |\n",
      "|    value_loss         | 0.000879    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 53700       |\n",
      "|    time_elapsed       | 2593        |\n",
      "|    total_timesteps    | 268500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -376        |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53699       |\n",
      "|    policy_loss        | -6.97       |\n",
      "|    reward             | 0.118078224 |\n",
      "|    std                | 1.04e+05    |\n",
      "|    value_loss         | 0.00111     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 53800      |\n",
      "|    time_elapsed       | 2598       |\n",
      "|    total_timesteps    | 269000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -376       |\n",
      "|    explained_variance | 0.863      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53799      |\n",
      "|    policy_loss        | 12.8       |\n",
      "|    reward             | 0.24043322 |\n",
      "|    std                | 1.06e+05   |\n",
      "|    value_loss         | 0.00934    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 53900       |\n",
      "|    time_elapsed       | 2603        |\n",
      "|    total_timesteps    | 269500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -377        |\n",
      "|    explained_variance | 0.109       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53899       |\n",
      "|    policy_loss        | 4.66        |\n",
      "|    reward             | 0.011089376 |\n",
      "|    std                | 1.08e+05    |\n",
      "|    value_loss         | 0.000293    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 54000        |\n",
      "|    time_elapsed       | 2607         |\n",
      "|    total_timesteps    | 270000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -378         |\n",
      "|    explained_variance | 0.729        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 53999        |\n",
      "|    policy_loss        | 3.18         |\n",
      "|    reward             | -0.026560482 |\n",
      "|    std                | 1.11e+05     |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 54100      |\n",
      "|    time_elapsed       | 2612       |\n",
      "|    total_timesteps    | 270500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -379       |\n",
      "|    explained_variance | 0.735      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54099      |\n",
      "|    policy_loss        | 8.55       |\n",
      "|    reward             | 0.10923549 |\n",
      "|    std                | 1.15e+05   |\n",
      "|    value_loss         | 0.000773   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 54200       |\n",
      "|    time_elapsed       | 2617        |\n",
      "|    total_timesteps    | 271000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -380        |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54199       |\n",
      "|    policy_loss        | -23.6       |\n",
      "|    reward             | -0.01953992 |\n",
      "|    std                | 1.18e+05    |\n",
      "|    value_loss         | 0.00417     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 54300       |\n",
      "|    time_elapsed       | 2622        |\n",
      "|    total_timesteps    | 271500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -380        |\n",
      "|    explained_variance | -1.61       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54299       |\n",
      "|    policy_loss        | -47.6       |\n",
      "|    reward             | 0.039261274 |\n",
      "|    std                | 1.21e+05    |\n",
      "|    value_loss         | 0.0189      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 54400       |\n",
      "|    time_elapsed       | 2626        |\n",
      "|    total_timesteps    | 272000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -381        |\n",
      "|    explained_variance | -2.93       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54399       |\n",
      "|    policy_loss        | -2.2        |\n",
      "|    reward             | -0.00958909 |\n",
      "|    std                | 1.23e+05    |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 2631         |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -381         |\n",
      "|    explained_variance | 0.703        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | -14.5        |\n",
      "|    reward             | -0.004263328 |\n",
      "|    std                | 1.25e+05     |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 54600         |\n",
      "|    time_elapsed       | 2636          |\n",
      "|    total_timesteps    | 273000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -382          |\n",
      "|    explained_variance | 0.484         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 54599         |\n",
      "|    policy_loss        | -2.37         |\n",
      "|    reward             | -0.0039651967 |\n",
      "|    std                | 1.29e+05      |\n",
      "|    value_loss         | 0.000306      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 54700        |\n",
      "|    time_elapsed       | 2641         |\n",
      "|    total_timesteps    | 273500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -383         |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 54699        |\n",
      "|    policy_loss        | 1.96         |\n",
      "|    reward             | -0.056867365 |\n",
      "|    std                | 1.33e+05     |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 54800        |\n",
      "|    time_elapsed       | 2646         |\n",
      "|    total_timesteps    | 274000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -384         |\n",
      "|    explained_variance | 0.253        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 54799        |\n",
      "|    policy_loss        | 16.1         |\n",
      "|    reward             | -0.020000266 |\n",
      "|    std                | 1.37e+05     |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 54900       |\n",
      "|    time_elapsed       | 2650        |\n",
      "|    total_timesteps    | 274500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -385        |\n",
      "|    explained_variance | 0.661       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54899       |\n",
      "|    policy_loss        | -3.38       |\n",
      "|    reward             | 0.011583145 |\n",
      "|    std                | 1.4e+05     |\n",
      "|    value_loss         | 0.000332    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 55000         |\n",
      "|    time_elapsed       | 2655          |\n",
      "|    total_timesteps    | 275000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -385          |\n",
      "|    explained_variance | 0.165         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 54999         |\n",
      "|    policy_loss        | 6.69          |\n",
      "|    reward             | -0.0015239677 |\n",
      "|    std                | 1.43e+05      |\n",
      "|    value_loss         | 0.000335      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 55100       |\n",
      "|    time_elapsed       | 2660        |\n",
      "|    total_timesteps    | 275500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -386        |\n",
      "|    explained_variance | 0.214       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55099       |\n",
      "|    policy_loss        | -14.3       |\n",
      "|    reward             | 0.060653966 |\n",
      "|    std                | 1.46e+05    |\n",
      "|    value_loss         | 0.00237     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 55200       |\n",
      "|    time_elapsed       | 2665        |\n",
      "|    total_timesteps    | 276000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -387        |\n",
      "|    explained_variance | 0.65        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55199       |\n",
      "|    policy_loss        | 5.35        |\n",
      "|    reward             | 0.000878435 |\n",
      "|    std                | 1.51e+05    |\n",
      "|    value_loss         | 0.000253    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 55300      |\n",
      "|    time_elapsed       | 2669       |\n",
      "|    total_timesteps    | 276500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -388       |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55299      |\n",
      "|    policy_loss        | -0.286     |\n",
      "|    reward             | 0.02609968 |\n",
      "|    std                | 1.56e+05   |\n",
      "|    value_loss         | 4.91e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 55400        |\n",
      "|    time_elapsed       | 2674         |\n",
      "|    total_timesteps    | 277000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -389         |\n",
      "|    explained_variance | -2.43        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 55399        |\n",
      "|    policy_loss        | -21.8        |\n",
      "|    reward             | -0.018938351 |\n",
      "|    std                | 1.61e+05     |\n",
      "|    value_loss         | 0.00545      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 55500      |\n",
      "|    time_elapsed       | 2679       |\n",
      "|    total_timesteps    | 277500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -389       |\n",
      "|    explained_variance | 0.475      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55499      |\n",
      "|    policy_loss        | 16.9       |\n",
      "|    reward             | 0.15266141 |\n",
      "|    std                | 1.65e+05   |\n",
      "|    value_loss         | 0.00415    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 55600       |\n",
      "|    time_elapsed       | 2684        |\n",
      "|    total_timesteps    | 278000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -390        |\n",
      "|    explained_variance | 0.289       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55599       |\n",
      "|    policy_loss        | -6.49       |\n",
      "|    reward             | 0.009784657 |\n",
      "|    std                | 1.68e+05    |\n",
      "|    value_loss         | 0.000622    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 55700        |\n",
      "|    time_elapsed       | 2688         |\n",
      "|    total_timesteps    | 278500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -391         |\n",
      "|    explained_variance | 0.349        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 55699        |\n",
      "|    policy_loss        | 5.87         |\n",
      "|    reward             | -0.005965372 |\n",
      "|    std                | 1.72e+05     |\n",
      "|    value_loss         | 0.000322     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 55800        |\n",
      "|    time_elapsed       | 2693         |\n",
      "|    total_timesteps    | 279000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -392         |\n",
      "|    explained_variance | 0.461        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 55799        |\n",
      "|    policy_loss        | 10.6         |\n",
      "|    reward             | -0.030834677 |\n",
      "|    std                | 1.78e+05     |\n",
      "|    value_loss         | 0.000881     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 55900       |\n",
      "|    time_elapsed       | 2698        |\n",
      "|    total_timesteps    | 279500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -393        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55899       |\n",
      "|    policy_loss        | -17.4       |\n",
      "|    reward             | 0.030756667 |\n",
      "|    std                | 1.85e+05    |\n",
      "|    value_loss         | 0.00323     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 56000       |\n",
      "|    time_elapsed       | 2703        |\n",
      "|    total_timesteps    | 280000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -393        |\n",
      "|    explained_variance | -0.896      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55999       |\n",
      "|    policy_loss        | 14.3        |\n",
      "|    reward             | 0.082045175 |\n",
      "|    std                | 1.9e+05     |\n",
      "|    value_loss         | 0.00225     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 56100       |\n",
      "|    time_elapsed       | 2707        |\n",
      "|    total_timesteps    | 280500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -394        |\n",
      "|    explained_variance | 0.36        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56099       |\n",
      "|    policy_loss        | -3.48       |\n",
      "|    reward             | 0.106140114 |\n",
      "|    std                | 1.95e+05    |\n",
      "|    value_loss         | 0.000928    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 56200      |\n",
      "|    time_elapsed       | 2712       |\n",
      "|    total_timesteps    | 281000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -395       |\n",
      "|    explained_variance | -0.512     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56199      |\n",
      "|    policy_loss        | -11.6      |\n",
      "|    reward             | 0.03232295 |\n",
      "|    std                | 1.99e+05   |\n",
      "|    value_loss         | 0.000926   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 56300       |\n",
      "|    time_elapsed       | 2717        |\n",
      "|    total_timesteps    | 281500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -396        |\n",
      "|    explained_variance | -1.7        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56299       |\n",
      "|    policy_loss        | -13.9       |\n",
      "|    reward             | -0.01036482 |\n",
      "|    std                | 2.05e+05    |\n",
      "|    value_loss         | 0.00155     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 56400        |\n",
      "|    time_elapsed       | 2722         |\n",
      "|    total_timesteps    | 282000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -397         |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 56399        |\n",
      "|    policy_loss        | 0.289        |\n",
      "|    reward             | -0.006073265 |\n",
      "|    std                | 2.12e+05     |\n",
      "|    value_loss         | 2.75e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 56500        |\n",
      "|    time_elapsed       | 2726         |\n",
      "|    total_timesteps    | 282500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -397         |\n",
      "|    explained_variance | 0.994        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 56499        |\n",
      "|    policy_loss        | -4.9         |\n",
      "|    reward             | -0.006940723 |\n",
      "|    std                | 2.19e+05     |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 56600         |\n",
      "|    time_elapsed       | 2731          |\n",
      "|    total_timesteps    | 283000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -398          |\n",
      "|    explained_variance | 0.96          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 56599         |\n",
      "|    policy_loss        | 5.27          |\n",
      "|    reward             | -0.0150457425 |\n",
      "|    std                | 2.24e+05      |\n",
      "|    value_loss         | 0.000492      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 56700      |\n",
      "|    time_elapsed       | 2736       |\n",
      "|    total_timesteps    | 283500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -399       |\n",
      "|    explained_variance | 0.75       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56699      |\n",
      "|    policy_loss        | -126       |\n",
      "|    reward             | -1.1077884 |\n",
      "|    std                | 2.28e+05   |\n",
      "|    value_loss         | 0.104      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 56800        |\n",
      "|    time_elapsed       | 2741         |\n",
      "|    total_timesteps    | 284000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -399         |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 56799        |\n",
      "|    policy_loss        | -4.17        |\n",
      "|    reward             | -0.004717346 |\n",
      "|    std                | 2.33e+05     |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 56900        |\n",
      "|    time_elapsed       | 2745         |\n",
      "|    total_timesteps    | 284500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -400         |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 56899        |\n",
      "|    policy_loss        | 8.75         |\n",
      "|    reward             | -0.012051179 |\n",
      "|    std                | 2.4e+05      |\n",
      "|    value_loss         | 0.00069      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 57000       |\n",
      "|    time_elapsed       | 2750        |\n",
      "|    total_timesteps    | 285000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -401        |\n",
      "|    explained_variance | -0.146      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56999       |\n",
      "|    policy_loss        | 20.5        |\n",
      "|    reward             | 0.022001645 |\n",
      "|    std                | 2.47e+05    |\n",
      "|    value_loss         | 0.00289     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 2755        |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -402        |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | 5.47        |\n",
      "|    reward             | 0.028590737 |\n",
      "|    std                | 2.55e+05    |\n",
      "|    value_loss         | 0.000701    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 57200     |\n",
      "|    time_elapsed       | 2760      |\n",
      "|    total_timesteps    | 286000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -403      |\n",
      "|    explained_variance | 0.724     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57199     |\n",
      "|    policy_loss        | -64.6     |\n",
      "|    reward             | 0.0569823 |\n",
      "|    std                | 2.61e+05  |\n",
      "|    value_loss         | 0.0341    |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17369825.82\n",
      "total_reward: 7369825.82\n",
      "total_cost: 560563.33\n",
      "total_trades: 82552\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 57300     |\n",
      "|    time_elapsed       | 2764      |\n",
      "|    total_timesteps    | 286500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -403      |\n",
      "|    explained_variance | 0.0164    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57299     |\n",
      "|    policy_loss        | 2.34      |\n",
      "|    reward             | 0.0158691 |\n",
      "|    std                | 2.65e+05  |\n",
      "|    value_loss         | 4.34e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 57400       |\n",
      "|    time_elapsed       | 2769        |\n",
      "|    total_timesteps    | 287000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -404        |\n",
      "|    explained_variance | -1.02       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57399       |\n",
      "|    policy_loss        | -14.8       |\n",
      "|    reward             | -0.02204652 |\n",
      "|    std                | 2.7e+05     |\n",
      "|    value_loss         | 0.00137     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 57500       |\n",
      "|    time_elapsed       | 2774        |\n",
      "|    total_timesteps    | 287500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -404        |\n",
      "|    explained_variance | -3.82       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57499       |\n",
      "|    policy_loss        | -7.62       |\n",
      "|    reward             | 0.012803903 |\n",
      "|    std                | 2.77e+05    |\n",
      "|    value_loss         | 0.000438    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 2779        |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -405        |\n",
      "|    explained_variance | -17.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57599       |\n",
      "|    policy_loss        | -13.1       |\n",
      "|    reward             | 0.014265464 |\n",
      "|    std                | 2.86e+05    |\n",
      "|    value_loss         | 0.00325     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 57700      |\n",
      "|    time_elapsed       | 2783       |\n",
      "|    total_timesteps    | 288500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -406       |\n",
      "|    explained_variance | 0.858      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57699      |\n",
      "|    policy_loss        | 25.6       |\n",
      "|    reward             | 0.00473787 |\n",
      "|    std                | 2.95e+05   |\n",
      "|    value_loss         | 0.0043     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 57800        |\n",
      "|    time_elapsed       | 2788         |\n",
      "|    total_timesteps    | 289000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -407         |\n",
      "|    explained_variance | -0.0458      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 57799        |\n",
      "|    policy_loss        | 40.9         |\n",
      "|    reward             | -0.063117616 |\n",
      "|    std                | 3.02e+05     |\n",
      "|    value_loss         | 0.0171       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 57900        |\n",
      "|    time_elapsed       | 2793         |\n",
      "|    total_timesteps    | 289500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -407         |\n",
      "|    explained_variance | -1.09        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 57899        |\n",
      "|    policy_loss        | 4.47         |\n",
      "|    reward             | 0.0068355133 |\n",
      "|    std                | 3.06e+05     |\n",
      "|    value_loss         | 0.000243     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 58000      |\n",
      "|    time_elapsed       | 2798       |\n",
      "|    total_timesteps    | 290000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -408       |\n",
      "|    explained_variance | 0.783      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57999      |\n",
      "|    policy_loss        | 1.61       |\n",
      "|    reward             | 0.01799471 |\n",
      "|    std                | 3.13e+05   |\n",
      "|    value_loss         | 0.000254   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 58100        |\n",
      "|    time_elapsed       | 2803         |\n",
      "|    total_timesteps    | 290500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -409         |\n",
      "|    explained_variance | 0.42         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 58099        |\n",
      "|    policy_loss        | -9.79        |\n",
      "|    reward             | 0.0075603607 |\n",
      "|    std                | 3.23e+05     |\n",
      "|    value_loss         | 0.000912     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 58200      |\n",
      "|    time_elapsed       | 2807       |\n",
      "|    total_timesteps    | 291000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -410       |\n",
      "|    explained_variance | 0.868      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58199      |\n",
      "|    policy_loss        | -22.1      |\n",
      "|    reward             | 0.11349486 |\n",
      "|    std                | 3.34e+05   |\n",
      "|    value_loss         | 0.00317    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 58300       |\n",
      "|    time_elapsed       | 2812        |\n",
      "|    total_timesteps    | 291500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -411        |\n",
      "|    explained_variance | -0.429      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58299       |\n",
      "|    policy_loss        | 6.35        |\n",
      "|    reward             | 0.019119155 |\n",
      "|    std                | 3.45e+05    |\n",
      "|    value_loss         | 0.000683    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 58400       |\n",
      "|    time_elapsed       | 2817        |\n",
      "|    total_timesteps    | 292000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -411        |\n",
      "|    explained_variance | 0.131       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58399       |\n",
      "|    policy_loss        | -3.32       |\n",
      "|    reward             | 0.076924615 |\n",
      "|    std                | 3.51e+05    |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 58500         |\n",
      "|    time_elapsed       | 2822          |\n",
      "|    total_timesteps    | 292500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -412          |\n",
      "|    explained_variance | 0.81          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 58499         |\n",
      "|    policy_loss        | 0.23          |\n",
      "|    reward             | -0.0073704254 |\n",
      "|    std                | 3.57e+05      |\n",
      "|    value_loss         | 3.88e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 58600        |\n",
      "|    time_elapsed       | 2826         |\n",
      "|    total_timesteps    | 293000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -412         |\n",
      "|    explained_variance | 0.637        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 58599        |\n",
      "|    policy_loss        | -3.72        |\n",
      "|    reward             | -0.005520255 |\n",
      "|    std                | 3.67e+05     |\n",
      "|    value_loss         | 0.000286     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 58700       |\n",
      "|    time_elapsed       | 2831        |\n",
      "|    total_timesteps    | 293500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -413        |\n",
      "|    explained_variance | 0.728       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58699       |\n",
      "|    policy_loss        | 5.97        |\n",
      "|    reward             | -0.01793283 |\n",
      "|    std                | 3.78e+05    |\n",
      "|    value_loss         | 0.00055     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 58800       |\n",
      "|    time_elapsed       | 2836        |\n",
      "|    total_timesteps    | 294000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -414        |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58799       |\n",
      "|    policy_loss        | -5.19       |\n",
      "|    reward             | 0.052338745 |\n",
      "|    std                | 3.9e+05     |\n",
      "|    value_loss         | 0.000629    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 58900      |\n",
      "|    time_elapsed       | 2841       |\n",
      "|    total_timesteps    | 294500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -415       |\n",
      "|    explained_variance | 0.861      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58899      |\n",
      "|    policy_loss        | 35         |\n",
      "|    reward             | 0.22465923 |\n",
      "|    std                | 4e+05      |\n",
      "|    value_loss         | 0.00852    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 59000       |\n",
      "|    time_elapsed       | 2846        |\n",
      "|    total_timesteps    | 295000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -415        |\n",
      "|    explained_variance | 0.514       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58999       |\n",
      "|    policy_loss        | -60.5       |\n",
      "|    reward             | -0.25855902 |\n",
      "|    std                | 4.06e+05    |\n",
      "|    value_loss         | 0.0219      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 59100       |\n",
      "|    time_elapsed       | 2850        |\n",
      "|    total_timesteps    | 295500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -416        |\n",
      "|    explained_variance | 0.472       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59099       |\n",
      "|    policy_loss        | 5.11        |\n",
      "|    reward             | 0.005819757 |\n",
      "|    std                | 4.13e+05    |\n",
      "|    value_loss         | 0.000182    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 59200       |\n",
      "|    time_elapsed       | 2855        |\n",
      "|    total_timesteps    | 296000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -417        |\n",
      "|    explained_variance | 0.382       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | -0.818      |\n",
      "|    reward             | 0.007236406 |\n",
      "|    std                | 4.24e+05    |\n",
      "|    value_loss         | 6.86e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 59300         |\n",
      "|    time_elapsed       | 2860          |\n",
      "|    total_timesteps    | 296500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -418          |\n",
      "|    explained_variance | 0.751         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 59299         |\n",
      "|    policy_loss        | 2.35          |\n",
      "|    reward             | -0.0071725114 |\n",
      "|    std                | 4.37e+05      |\n",
      "|    value_loss         | 0.00031       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 2864        |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -418        |\n",
      "|    explained_variance | 0.765       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59399       |\n",
      "|    policy_loss        | 6.09        |\n",
      "|    reward             | -0.02336054 |\n",
      "|    std                | 4.51e+05    |\n",
      "|    value_loss         | 0.000292    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 59500       |\n",
      "|    time_elapsed       | 2869        |\n",
      "|    total_timesteps    | 297500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -419        |\n",
      "|    explained_variance | 0.299       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59499       |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | 0.018441673 |\n",
      "|    std                | 4.63e+05    |\n",
      "|    value_loss         | 0.00545     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 59600       |\n",
      "|    time_elapsed       | 2874        |\n",
      "|    total_timesteps    | 298000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -420        |\n",
      "|    explained_variance | -13.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59599       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | 0.003021778 |\n",
      "|    std                | 4.72e+05    |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 59700        |\n",
      "|    time_elapsed       | 2879         |\n",
      "|    total_timesteps    | 298500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -420         |\n",
      "|    explained_variance | -0.995       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 59699        |\n",
      "|    policy_loss        | 7.21         |\n",
      "|    reward             | 0.0005851936 |\n",
      "|    std                | 4.83e+05     |\n",
      "|    value_loss         | 0.000414     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 59800         |\n",
      "|    time_elapsed       | 2883          |\n",
      "|    total_timesteps    | 299000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -421          |\n",
      "|    explained_variance | -5.45         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 59799         |\n",
      "|    policy_loss        | -6.91         |\n",
      "|    reward             | -0.0011080813 |\n",
      "|    std                | 4.98e+05      |\n",
      "|    value_loss         | 0.000345      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 59900        |\n",
      "|    time_elapsed       | 2888         |\n",
      "|    total_timesteps    | 299500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -422         |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 59899        |\n",
      "|    policy_loss        | 7.96         |\n",
      "|    reward             | 0.0020748691 |\n",
      "|    std                | 5.16e+05     |\n",
      "|    value_loss         | 0.000552     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 60000        |\n",
      "|    time_elapsed       | 2893         |\n",
      "|    total_timesteps    | 300000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -423         |\n",
      "|    explained_variance | 0.69         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 59999        |\n",
      "|    policy_loss        | -13.7        |\n",
      "|    reward             | -0.031452704 |\n",
      "|    std                | 5.33e+05     |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 60100       |\n",
      "|    time_elapsed       | 2898        |\n",
      "|    total_timesteps    | 300500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -424        |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60099       |\n",
      "|    policy_loss        | 49.3        |\n",
      "|    reward             | 0.033528887 |\n",
      "|    std                | 5.48e+05    |\n",
      "|    value_loss         | 0.0198      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 60200        |\n",
      "|    time_elapsed       | 2903         |\n",
      "|    total_timesteps    | 301000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -425         |\n",
      "|    explained_variance | -1.01        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 60199        |\n",
      "|    policy_loss        | -5.35        |\n",
      "|    reward             | 0.0031086274 |\n",
      "|    std                | 5.58e+05     |\n",
      "|    value_loss         | 0.000201     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 60300       |\n",
      "|    time_elapsed       | 2908        |\n",
      "|    total_timesteps    | 301500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -425        |\n",
      "|    explained_variance | -0.923      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60299       |\n",
      "|    policy_loss        | 8.75        |\n",
      "|    reward             | 0.013855374 |\n",
      "|    std                | 5.71e+05    |\n",
      "|    value_loss         | 0.000504    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 60400      |\n",
      "|    time_elapsed       | 2913       |\n",
      "|    total_timesteps    | 302000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -426       |\n",
      "|    explained_variance | 0.837      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60399      |\n",
      "|    policy_loss        | -19.3      |\n",
      "|    reward             | 0.04541202 |\n",
      "|    std                | 5.89e+05   |\n",
      "|    value_loss         | 0.00216    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 60500        |\n",
      "|    time_elapsed       | 2918         |\n",
      "|    total_timesteps    | 302500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -427         |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 60499        |\n",
      "|    policy_loss        | -6.44        |\n",
      "|    reward             | -0.005769452 |\n",
      "|    std                | 6.08e+05     |\n",
      "|    value_loss         | 0.000311     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 60600       |\n",
      "|    time_elapsed       | 2922        |\n",
      "|    total_timesteps    | 303000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -428        |\n",
      "|    explained_variance | 0.0786      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60599       |\n",
      "|    policy_loss        | -26.6       |\n",
      "|    reward             | 0.010705312 |\n",
      "|    std                | 6.26e+05    |\n",
      "|    value_loss         | 0.00535     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 60700      |\n",
      "|    time_elapsed       | 2927       |\n",
      "|    total_timesteps    | 303500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -429       |\n",
      "|    explained_variance | 0.874      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60699      |\n",
      "|    policy_loss        | 8.13       |\n",
      "|    reward             | 0.05102293 |\n",
      "|    std                | 6.4e+05    |\n",
      "|    value_loss         | 0.00382    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 60800        |\n",
      "|    time_elapsed       | 2932         |\n",
      "|    total_timesteps    | 304000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -429         |\n",
      "|    explained_variance | 0.543        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 60799        |\n",
      "|    policy_loss        | -1.81        |\n",
      "|    reward             | -0.010140054 |\n",
      "|    std                | 6.52e+05     |\n",
      "|    value_loss         | 4.93e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 60900         |\n",
      "|    time_elapsed       | 2937          |\n",
      "|    total_timesteps    | 304500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -430          |\n",
      "|    explained_variance | -0.0526       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 60899         |\n",
      "|    policy_loss        | 4.02          |\n",
      "|    reward             | -0.0075019915 |\n",
      "|    std                | 6.67e+05      |\n",
      "|    value_loss         | 0.00114       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 61000        |\n",
      "|    time_elapsed       | 2942         |\n",
      "|    total_timesteps    | 305000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -431         |\n",
      "|    explained_variance | 0.852        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 60999        |\n",
      "|    policy_loss        | 5.29         |\n",
      "|    reward             | 0.0063869935 |\n",
      "|    std                | 6.88e+05     |\n",
      "|    value_loss         | 0.000182     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 61100        |\n",
      "|    time_elapsed       | 2946         |\n",
      "|    total_timesteps    | 305500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -432         |\n",
      "|    explained_variance | 0.425        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 61099        |\n",
      "|    policy_loss        | 8.79         |\n",
      "|    reward             | -0.013281551 |\n",
      "|    std                | 7.13e+05     |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 61200       |\n",
      "|    time_elapsed       | 2951        |\n",
      "|    total_timesteps    | 306000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -433        |\n",
      "|    explained_variance | -1.83       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61199       |\n",
      "|    policy_loss        | -15.4       |\n",
      "|    reward             | 0.073605545 |\n",
      "|    std                | 7.34e+05    |\n",
      "|    value_loss         | 0.0016      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 61300       |\n",
      "|    time_elapsed       | 2956        |\n",
      "|    total_timesteps    | 306500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -433        |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61299       |\n",
      "|    policy_loss        | 0.988       |\n",
      "|    reward             | 0.040878795 |\n",
      "|    std                | 7.51e+05    |\n",
      "|    value_loss         | 0.000373    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 61400        |\n",
      "|    time_elapsed       | 2961         |\n",
      "|    total_timesteps    | 307000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -434         |\n",
      "|    explained_variance | 0.668        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 61399        |\n",
      "|    policy_loss        | -19.1        |\n",
      "|    reward             | -0.018157436 |\n",
      "|    std                | 7.65e+05     |\n",
      "|    value_loss         | 0.00201      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 61500         |\n",
      "|    time_elapsed       | 2965          |\n",
      "|    total_timesteps    | 307500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -435          |\n",
      "|    explained_variance | 0.79          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 61499         |\n",
      "|    policy_loss        | -0.694        |\n",
      "|    reward             | -0.0014173953 |\n",
      "|    std                | 7.86e+05      |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 61600       |\n",
      "|    time_elapsed       | 2970        |\n",
      "|    total_timesteps    | 308000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -435        |\n",
      "|    explained_variance | 0.444       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61599       |\n",
      "|    policy_loss        | 17.1        |\n",
      "|    reward             | 0.008556439 |\n",
      "|    std                | 8.13e+05    |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 61700       |\n",
      "|    time_elapsed       | 2975        |\n",
      "|    total_timesteps    | 308500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -436        |\n",
      "|    explained_variance | -0.714      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61699       |\n",
      "|    policy_loss        | -19.1       |\n",
      "|    reward             | -0.05351011 |\n",
      "|    std                | 8.39e+05    |\n",
      "|    value_loss         | 0.00228     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 61800       |\n",
      "|    time_elapsed       | 2980        |\n",
      "|    total_timesteps    | 309000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -437        |\n",
      "|    explained_variance | 0.4         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61799       |\n",
      "|    policy_loss        | 46          |\n",
      "|    reward             | -0.08643672 |\n",
      "|    std                | 8.66e+05    |\n",
      "|    value_loss         | 0.0117      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 61900       |\n",
      "|    time_elapsed       | 2985        |\n",
      "|    total_timesteps    | 309500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -438        |\n",
      "|    explained_variance | 0.751       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61899       |\n",
      "|    policy_loss        | 61.8        |\n",
      "|    reward             | -0.26168227 |\n",
      "|    std                | 8.84e+05    |\n",
      "|    value_loss         | 0.0653      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 62000         |\n",
      "|    time_elapsed       | 2989          |\n",
      "|    total_timesteps    | 310000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -439          |\n",
      "|    explained_variance | -0.0484       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 61999         |\n",
      "|    policy_loss        | 5.27          |\n",
      "|    reward             | -0.0042250142 |\n",
      "|    std                | 9.02e+05      |\n",
      "|    value_loss         | 0.000246      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 62100        |\n",
      "|    time_elapsed       | 2994         |\n",
      "|    total_timesteps    | 310500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -439         |\n",
      "|    explained_variance | 0.653        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 62099        |\n",
      "|    policy_loss        | 3.98         |\n",
      "|    reward             | -0.012025116 |\n",
      "|    std                | 9.29e+05     |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 62200        |\n",
      "|    time_elapsed       | 2999         |\n",
      "|    total_timesteps    | 311000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -440         |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 62199        |\n",
      "|    policy_loss        | 1.35         |\n",
      "|    reward             | -0.018061044 |\n",
      "|    std                | 9.61e+05     |\n",
      "|    value_loss         | 9.41e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 62300       |\n",
      "|    time_elapsed       | 3004        |\n",
      "|    total_timesteps    | 311500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -441        |\n",
      "|    explained_variance | 0.719       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62299       |\n",
      "|    policy_loss        | 23.3        |\n",
      "|    reward             | -0.09106843 |\n",
      "|    std                | 9.92e+05    |\n",
      "|    value_loss         | 0.003       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 62400        |\n",
      "|    time_elapsed       | 3009         |\n",
      "|    total_timesteps    | 312000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -442         |\n",
      "|    explained_variance | -6.96        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 62399        |\n",
      "|    policy_loss        | -79.5        |\n",
      "|    reward             | -0.009701004 |\n",
      "|    std                | 1.02e+06     |\n",
      "|    value_loss         | 0.0431       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 3013        |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -442        |\n",
      "|    explained_variance | -0.64       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62499       |\n",
      "|    policy_loss        | 13.6        |\n",
      "|    reward             | 0.002585072 |\n",
      "|    std                | 1.03e+06    |\n",
      "|    value_loss         | 0.00103     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 62600       |\n",
      "|    time_elapsed       | 3018        |\n",
      "|    total_timesteps    | 313000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -443        |\n",
      "|    explained_variance | 0.758       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62599       |\n",
      "|    policy_loss        | 10.2        |\n",
      "|    reward             | 0.013156375 |\n",
      "|    std                | 1.06e+06    |\n",
      "|    value_loss         | 0.000559    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 62700        |\n",
      "|    time_elapsed       | 3023         |\n",
      "|    total_timesteps    | 313500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -444         |\n",
      "|    explained_variance | 0.653        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 62699        |\n",
      "|    policy_loss        | -2.96        |\n",
      "|    reward             | -0.005468194 |\n",
      "|    std                | 1.09e+06     |\n",
      "|    value_loss         | 9.16e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 62800      |\n",
      "|    time_elapsed       | 3028       |\n",
      "|    total_timesteps    | 314000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -445       |\n",
      "|    explained_variance | 0.853      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62799      |\n",
      "|    policy_loss        | -2.85      |\n",
      "|    reward             | 0.00443727 |\n",
      "|    std                | 1.13e+06   |\n",
      "|    value_loss         | 7.85e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 62900        |\n",
      "|    time_elapsed       | 3032         |\n",
      "|    total_timesteps    | 314500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -446         |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 62899        |\n",
      "|    policy_loss        | -4.91        |\n",
      "|    reward             | -0.022847986 |\n",
      "|    std                | 1.16e+06     |\n",
      "|    value_loss         | 0.000249     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 63000       |\n",
      "|    time_elapsed       | 3037        |\n",
      "|    total_timesteps    | 315000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -447        |\n",
      "|    explained_variance | 0.821       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62999       |\n",
      "|    policy_loss        | -36         |\n",
      "|    reward             | 0.051397905 |\n",
      "|    std                | 1.2e+06     |\n",
      "|    value_loss         | 0.00778     |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17461889.19\n",
      "total_reward: 7461889.19\n",
      "total_cost: 559680.17\n",
      "total_trades: 82356\n",
      "Sharpe: 0.571\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 63100        |\n",
      "|    time_elapsed       | 3042         |\n",
      "|    total_timesteps    | 315500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -447         |\n",
      "|    explained_variance | 0.701        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63099        |\n",
      "|    policy_loss        | -0.624       |\n",
      "|    reward             | 0.0016455747 |\n",
      "|    std                | 1.22e+06     |\n",
      "|    value_loss         | 2.67e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 63200        |\n",
      "|    time_elapsed       | 3047         |\n",
      "|    total_timesteps    | 316000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -448         |\n",
      "|    explained_variance | 0.745        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63199        |\n",
      "|    policy_loss        | -1.19        |\n",
      "|    reward             | -0.024219994 |\n",
      "|    std                | 1.25e+06     |\n",
      "|    value_loss         | 0.000693     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 63300        |\n",
      "|    time_elapsed       | 3051         |\n",
      "|    total_timesteps    | 316500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -449         |\n",
      "|    explained_variance | -0.33        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63299        |\n",
      "|    policy_loss        | 3.08         |\n",
      "|    reward             | -0.007582029 |\n",
      "|    std                | 1.29e+06     |\n",
      "|    value_loss         | 0.000376     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 63400      |\n",
      "|    time_elapsed       | 3056       |\n",
      "|    total_timesteps    | 317000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -450       |\n",
      "|    explained_variance | -1.51      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63399      |\n",
      "|    policy_loss        | 6.57       |\n",
      "|    reward             | 0.00399989 |\n",
      "|    std                | 1.34e+06   |\n",
      "|    value_loss         | 0.000376   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 63500       |\n",
      "|    time_elapsed       | 3061        |\n",
      "|    total_timesteps    | 317500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -451        |\n",
      "|    explained_variance | 0.527       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63499       |\n",
      "|    policy_loss        | 32          |\n",
      "|    reward             | 0.019954754 |\n",
      "|    std                | 1.38e+06    |\n",
      "|    value_loss         | 0.00831     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 63600        |\n",
      "|    time_elapsed       | 3065         |\n",
      "|    total_timesteps    | 318000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -452         |\n",
      "|    explained_variance | 0.218        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63599        |\n",
      "|    policy_loss        | -1.59        |\n",
      "|    reward             | -0.034762084 |\n",
      "|    std                | 1.42e+06     |\n",
      "|    value_loss         | 0.00151      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 63700        |\n",
      "|    time_elapsed       | 3070         |\n",
      "|    total_timesteps    | 318500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -452         |\n",
      "|    explained_variance | 0.486        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63699        |\n",
      "|    policy_loss        | -14.7        |\n",
      "|    reward             | -0.009668382 |\n",
      "|    std                | 1.44e+06     |\n",
      "|    value_loss         | 0.00114      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 63800        |\n",
      "|    time_elapsed       | 3075         |\n",
      "|    total_timesteps    | 319000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -453         |\n",
      "|    explained_variance | -4.18        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63799        |\n",
      "|    policy_loss        | -3.87        |\n",
      "|    reward             | -0.016574962 |\n",
      "|    std                | 1.49e+06     |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 63900       |\n",
      "|    time_elapsed       | 3080        |\n",
      "|    total_timesteps    | 319500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -454        |\n",
      "|    explained_variance | -1.49       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63899       |\n",
      "|    policy_loss        | 2.81        |\n",
      "|    reward             | 0.003979711 |\n",
      "|    std                | 1.54e+06    |\n",
      "|    value_loss         | 0.000247    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 64000      |\n",
      "|    time_elapsed       | 3084       |\n",
      "|    total_timesteps    | 320000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -455       |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63999      |\n",
      "|    policy_loss        | -46.7      |\n",
      "|    reward             | 0.08010178 |\n",
      "|    std                | 1.61e+06   |\n",
      "|    value_loss         | 0.011      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 64100      |\n",
      "|    time_elapsed       | 3089       |\n",
      "|    total_timesteps    | 320500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -456       |\n",
      "|    explained_variance | 0.596      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64099      |\n",
      "|    policy_loss        | -20.1      |\n",
      "|    reward             | 0.06213836 |\n",
      "|    std                | 1.66e+06   |\n",
      "|    value_loss         | 0.00206    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 64200       |\n",
      "|    time_elapsed       | 3094        |\n",
      "|    total_timesteps    | 321000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -457        |\n",
      "|    explained_variance | 0.625       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64199       |\n",
      "|    policy_loss        | -2.9        |\n",
      "|    reward             | 0.064954236 |\n",
      "|    std                | 1.7e+06     |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 64300         |\n",
      "|    time_elapsed       | 3099          |\n",
      "|    total_timesteps    | 321500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -457          |\n",
      "|    explained_variance | -0.251        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 64299         |\n",
      "|    policy_loss        | -8.43         |\n",
      "|    reward             | -0.0084695695 |\n",
      "|    std                | 1.73e+06      |\n",
      "|    value_loss         | 0.000843      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 64400        |\n",
      "|    time_elapsed       | 3104         |\n",
      "|    total_timesteps    | 322000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -458         |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 64399        |\n",
      "|    policy_loss        | 8.56         |\n",
      "|    reward             | 0.0071007977 |\n",
      "|    std                | 1.78e+06     |\n",
      "|    value_loss         | 0.000652     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 64500       |\n",
      "|    time_elapsed       | 3108        |\n",
      "|    total_timesteps    | 322500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -459        |\n",
      "|    explained_variance | 0.571       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64499       |\n",
      "|    policy_loss        | -6.42       |\n",
      "|    reward             | -0.05527842 |\n",
      "|    std                | 1.83e+06    |\n",
      "|    value_loss         | 0.000977    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 64600        |\n",
      "|    time_elapsed       | 3113         |\n",
      "|    total_timesteps    | 323000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -460         |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 64599        |\n",
      "|    policy_loss        | 10.6         |\n",
      "|    reward             | -0.033119243 |\n",
      "|    std                | 1.88e+06     |\n",
      "|    value_loss         | 0.00072      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 64700        |\n",
      "|    time_elapsed       | 3118         |\n",
      "|    total_timesteps    | 323500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -461         |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 64699        |\n",
      "|    policy_loss        | 13.7         |\n",
      "|    reward             | -0.098957516 |\n",
      "|    std                | 1.93e+06     |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 64800       |\n",
      "|    time_elapsed       | 3123        |\n",
      "|    total_timesteps    | 324000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -461        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64799       |\n",
      "|    policy_loss        | 11.1        |\n",
      "|    reward             | -0.31409383 |\n",
      "|    std                | 1.96e+06    |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 64900        |\n",
      "|    time_elapsed       | 3128         |\n",
      "|    total_timesteps    | 324500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -462         |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 64899        |\n",
      "|    policy_loss        | 1.04         |\n",
      "|    reward             | 0.0019510916 |\n",
      "|    std                | 1.99e+06     |\n",
      "|    value_loss         | 7.82e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 65000       |\n",
      "|    time_elapsed       | 3133        |\n",
      "|    total_timesteps    | 325000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -462        |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64999       |\n",
      "|    policy_loss        | 6.9         |\n",
      "|    reward             | 0.009844129 |\n",
      "|    std                | 2.04e+06    |\n",
      "|    value_loss         | 0.000351    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 65100       |\n",
      "|    time_elapsed       | 3138        |\n",
      "|    total_timesteps    | 325500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -463        |\n",
      "|    explained_variance | -10.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65099       |\n",
      "|    policy_loss        | -10.6       |\n",
      "|    reward             | 0.021301525 |\n",
      "|    std                | 2.1e+06     |\n",
      "|    value_loss         | 0.000623    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 65200       |\n",
      "|    time_elapsed       | 3143        |\n",
      "|    total_timesteps    | 326000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -464        |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65199       |\n",
      "|    policy_loss        | 31          |\n",
      "|    reward             | 0.042482868 |\n",
      "|    std                | 2.16e+06    |\n",
      "|    value_loss         | 0.00596     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 65300        |\n",
      "|    time_elapsed       | 3148         |\n",
      "|    total_timesteps    | 326500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -465         |\n",
      "|    explained_variance | 0.429        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65299        |\n",
      "|    policy_loss        | -47.2        |\n",
      "|    reward             | 0.0010807597 |\n",
      "|    std                | 2.21e+06     |\n",
      "|    value_loss         | 0.0154       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 65400       |\n",
      "|    time_elapsed       | 3153        |\n",
      "|    total_timesteps    | 327000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -465        |\n",
      "|    explained_variance | 0.44        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65399       |\n",
      "|    policy_loss        | 3.25        |\n",
      "|    reward             | 0.003366681 |\n",
      "|    std                | 2.25e+06    |\n",
      "|    value_loss         | 7.3e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 65500        |\n",
      "|    time_elapsed       | 3158         |\n",
      "|    total_timesteps    | 327500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -466         |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65499        |\n",
      "|    policy_loss        | -0.084       |\n",
      "|    reward             | 0.0054665604 |\n",
      "|    std                | 2.3e+06      |\n",
      "|    value_loss         | 1.88e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 65600        |\n",
      "|    time_elapsed       | 3162         |\n",
      "|    total_timesteps    | 328000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -466         |\n",
      "|    explained_variance | 0.423        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65599        |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | 0.0050988267 |\n",
      "|    std                | 2.37e+06     |\n",
      "|    value_loss         | 7.08e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 65700      |\n",
      "|    time_elapsed       | 3167       |\n",
      "|    total_timesteps    | 328500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -467       |\n",
      "|    explained_variance | 0.781      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65699      |\n",
      "|    policy_loss        | -8.74      |\n",
      "|    reward             | -0.0710177 |\n",
      "|    std                | 2.44e+06   |\n",
      "|    value_loss         | 0.000726   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 65800      |\n",
      "|    time_elapsed       | 3172       |\n",
      "|    total_timesteps    | 329000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -468       |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65799      |\n",
      "|    policy_loss        | 12.2       |\n",
      "|    reward             | 0.12621282 |\n",
      "|    std                | 2.52e+06   |\n",
      "|    value_loss         | 0.000752   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 65900        |\n",
      "|    time_elapsed       | 3177         |\n",
      "|    total_timesteps    | 329500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -469         |\n",
      "|    explained_variance | 0.735        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65899        |\n",
      "|    policy_loss        | -137         |\n",
      "|    reward             | -0.021931836 |\n",
      "|    std                | 2.56e+06     |\n",
      "|    value_loss         | 0.0891       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 66000        |\n",
      "|    time_elapsed       | 3181         |\n",
      "|    total_timesteps    | 330000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -469         |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65999        |\n",
      "|    policy_loss        | 7.22         |\n",
      "|    reward             | 0.0027199027 |\n",
      "|    std                | 2.6e+06      |\n",
      "|    value_loss         | 0.000302     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 66100      |\n",
      "|    time_elapsed       | 3186       |\n",
      "|    total_timesteps    | 330500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -470       |\n",
      "|    explained_variance | 0.858      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66099      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.07116287 |\n",
      "|    std                | 2.66e+06   |\n",
      "|    value_loss         | 0.00161    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 66200        |\n",
      "|    time_elapsed       | 3191         |\n",
      "|    total_timesteps    | 331000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -471         |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 66199        |\n",
      "|    policy_loss        | 12.8         |\n",
      "|    reward             | -0.038879428 |\n",
      "|    std                | 2.73e+06     |\n",
      "|    value_loss         | 0.000775     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 3196        |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -472        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | 9.62        |\n",
      "|    reward             | 0.005069702 |\n",
      "|    std                | 2.82e+06    |\n",
      "|    value_loss         | 0.000614    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 66400        |\n",
      "|    time_elapsed       | 3201         |\n",
      "|    total_timesteps    | 332000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -472         |\n",
      "|    explained_variance | -0.196       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 66399        |\n",
      "|    policy_loss        | -7.34        |\n",
      "|    reward             | -0.012887183 |\n",
      "|    std                | 2.9e+06      |\n",
      "|    value_loss         | 0.000452     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 66500         |\n",
      "|    time_elapsed       | 3205          |\n",
      "|    total_timesteps    | 332500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -473          |\n",
      "|    explained_variance | -0.186        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 66499         |\n",
      "|    policy_loss        | 8.86          |\n",
      "|    reward             | -0.0045598424 |\n",
      "|    std                | 2.96e+06      |\n",
      "|    value_loss         | 0.00205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 66600        |\n",
      "|    time_elapsed       | 3210         |\n",
      "|    total_timesteps    | 333000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -473         |\n",
      "|    explained_variance | -0.223       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 66599        |\n",
      "|    policy_loss        | 2.6          |\n",
      "|    reward             | 0.0063688317 |\n",
      "|    std                | 3.01e+06     |\n",
      "|    value_loss         | 4.36e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 66700        |\n",
      "|    time_elapsed       | 3215         |\n",
      "|    total_timesteps    | 333500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -474         |\n",
      "|    explained_variance | 0.803        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 66699        |\n",
      "|    policy_loss        | -8.82        |\n",
      "|    reward             | -0.001982973 |\n",
      "|    std                | 3.09e+06     |\n",
      "|    value_loss         | 0.000518     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 66800        |\n",
      "|    time_elapsed       | 3220         |\n",
      "|    total_timesteps    | 334000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -475         |\n",
      "|    explained_variance | 0.632        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 66799        |\n",
      "|    policy_loss        | 8.34         |\n",
      "|    reward             | 0.0013736194 |\n",
      "|    std                | 3.19e+06     |\n",
      "|    value_loss         | 0.000574     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 3224        |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -476        |\n",
      "|    explained_variance | 0.8         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | 24.1        |\n",
      "|    reward             | 0.025126897 |\n",
      "|    std                | 3.29e+06    |\n",
      "|    value_loss         | 0.00283     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 67000       |\n",
      "|    time_elapsed       | 3229        |\n",
      "|    total_timesteps    | 335000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -477        |\n",
      "|    explained_variance | 0.0887      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66999       |\n",
      "|    policy_loss        | 2.61        |\n",
      "|    reward             | -0.17579615 |\n",
      "|    std                | 3.39e+06    |\n",
      "|    value_loss         | 0.00402     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 67100      |\n",
      "|    time_elapsed       | 3234       |\n",
      "|    total_timesteps    | 335500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -477       |\n",
      "|    explained_variance | 0.54       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67099      |\n",
      "|    policy_loss        | -3.07      |\n",
      "|    reward             | -0.0899315 |\n",
      "|    std                | 3.45e+06   |\n",
      "|    value_loss         | 0.00203    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 67200        |\n",
      "|    time_elapsed       | 3239         |\n",
      "|    total_timesteps    | 336000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -478         |\n",
      "|    explained_variance | 0.612        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 67199        |\n",
      "|    policy_loss        | -12.5        |\n",
      "|    reward             | -0.011070659 |\n",
      "|    std                | 3.51e+06     |\n",
      "|    value_loss         | 0.000959     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 67300       |\n",
      "|    time_elapsed       | 3244        |\n",
      "|    total_timesteps    | 336500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -479        |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67299       |\n",
      "|    policy_loss        | -12.1       |\n",
      "|    reward             | 0.005570598 |\n",
      "|    std                | 3.61e+06    |\n",
      "|    value_loss         | 0.000687    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 67400       |\n",
      "|    time_elapsed       | 3248        |\n",
      "|    total_timesteps    | 337000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -480        |\n",
      "|    explained_variance | 0.612       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67399       |\n",
      "|    policy_loss        | -15         |\n",
      "|    reward             | 0.042336855 |\n",
      "|    std                | 3.74e+06    |\n",
      "|    value_loss         | 0.0021      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 67500        |\n",
      "|    time_elapsed       | 3253         |\n",
      "|    total_timesteps    | 337500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -481         |\n",
      "|    explained_variance | -0.558       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 67499        |\n",
      "|    policy_loss        | -16.2        |\n",
      "|    reward             | -0.019424533 |\n",
      "|    std                | 3.86e+06     |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 67600       |\n",
      "|    time_elapsed       | 3258        |\n",
      "|    total_timesteps    | 338000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -481        |\n",
      "|    explained_variance | 0.651       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67599       |\n",
      "|    policy_loss        | 33          |\n",
      "|    reward             | 0.009057442 |\n",
      "|    std                | 3.96e+06    |\n",
      "|    value_loss         | 0.00661     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 67700      |\n",
      "|    time_elapsed       | 3263       |\n",
      "|    total_timesteps    | 338500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -482       |\n",
      "|    explained_variance | -26.6      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67699      |\n",
      "|    policy_loss        | -8.48      |\n",
      "|    reward             | -0.0026263 |\n",
      "|    std                | 4.02e+06   |\n",
      "|    value_loss         | 0.000467   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 67800        |\n",
      "|    time_elapsed       | 3268         |\n",
      "|    total_timesteps    | 339000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -482         |\n",
      "|    explained_variance | -1.97        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 67799        |\n",
      "|    policy_loss        | -12.1        |\n",
      "|    reward             | -0.008330011 |\n",
      "|    std                | 4.1e+06      |\n",
      "|    value_loss         | 0.000914     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 67900       |\n",
      "|    time_elapsed       | 3272        |\n",
      "|    total_timesteps    | 339500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -483        |\n",
      "|    explained_variance | 0.304       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67899       |\n",
      "|    policy_loss        | 5.82        |\n",
      "|    reward             | 0.021122016 |\n",
      "|    std                | 4.21e+06    |\n",
      "|    value_loss         | 0.000293    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 68000      |\n",
      "|    time_elapsed       | 3277       |\n",
      "|    total_timesteps    | 340000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -484       |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67999      |\n",
      "|    policy_loss        | -1.64      |\n",
      "|    reward             | -0.0863226 |\n",
      "|    std                | 4.34e+06   |\n",
      "|    value_loss         | 0.000572   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 68100       |\n",
      "|    time_elapsed       | 3282        |\n",
      "|    total_timesteps    | 340500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -485        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68099       |\n",
      "|    policy_loss        | -20.3       |\n",
      "|    reward             | -0.01699604 |\n",
      "|    std                | 4.46e+06    |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 68200       |\n",
      "|    time_elapsed       | 3287        |\n",
      "|    total_timesteps    | 341000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -486        |\n",
      "|    explained_variance | 0.642       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68199       |\n",
      "|    policy_loss        | 67.7        |\n",
      "|    reward             | 0.101442024 |\n",
      "|    std                | 4.57e+06    |\n",
      "|    value_loss         | 0.0528      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 68300        |\n",
      "|    time_elapsed       | 3292         |\n",
      "|    total_timesteps    | 341500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -486         |\n",
      "|    explained_variance | -0.821       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 68299        |\n",
      "|    policy_loss        | -16.8        |\n",
      "|    reward             | 0.0052689794 |\n",
      "|    std                | 4.65e+06     |\n",
      "|    value_loss         | 0.00146      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 68400      |\n",
      "|    time_elapsed       | 3296       |\n",
      "|    total_timesteps    | 342000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -487       |\n",
      "|    explained_variance | 0.577      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68399      |\n",
      "|    policy_loss        | -16.8      |\n",
      "|    reward             | 0.02548295 |\n",
      "|    std                | 4.75e+06   |\n",
      "|    value_loss         | 0.00126    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 68500       |\n",
      "|    time_elapsed       | 3301        |\n",
      "|    total_timesteps    | 342500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -487        |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68499       |\n",
      "|    policy_loss        | 3.85        |\n",
      "|    reward             | 0.036605153 |\n",
      "|    std                | 4.88e+06    |\n",
      "|    value_loss         | 0.000189    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 68600        |\n",
      "|    time_elapsed       | 3306         |\n",
      "|    total_timesteps    | 343000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -488         |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 68599        |\n",
      "|    policy_loss        | 1.56         |\n",
      "|    reward             | -0.028972853 |\n",
      "|    std                | 5.04e+06     |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 68700      |\n",
      "|    time_elapsed       | 3311       |\n",
      "|    total_timesteps    | 343500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -489       |\n",
      "|    explained_variance | 0.607      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68699      |\n",
      "|    policy_loss        | 13         |\n",
      "|    reward             | 0.05663102 |\n",
      "|    std                | 5.16e+06   |\n",
      "|    value_loss         | 0.00142    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 68800        |\n",
      "|    time_elapsed       | 3315         |\n",
      "|    total_timesteps    | 344000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -490         |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 68799        |\n",
      "|    policy_loss        | 4.83         |\n",
      "|    reward             | -0.006246044 |\n",
      "|    std                | 5.25e+06     |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19472736.76\n",
      "total_reward: 9472736.76\n",
      "total_cost: 561588.16\n",
      "total_trades: 82501\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 68900       |\n",
      "|    time_elapsed       | 3320        |\n",
      "|    total_timesteps    | 344500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -490        |\n",
      "|    explained_variance | -4.02       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68899       |\n",
      "|    policy_loss        | 3.43        |\n",
      "|    reward             | 0.008257769 |\n",
      "|    std                | 5.34e+06    |\n",
      "|    value_loss         | 0.000186    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 3325         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -491         |\n",
      "|    explained_variance | 0.0805       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | 5.64         |\n",
      "|    reward             | 0.0038894748 |\n",
      "|    std                | 5.47e+06     |\n",
      "|    value_loss         | 0.000672     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 69100        |\n",
      "|    time_elapsed       | 3330         |\n",
      "|    total_timesteps    | 345500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -492         |\n",
      "|    explained_variance | 0.779        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69099        |\n",
      "|    policy_loss        | 1.87         |\n",
      "|    reward             | -0.009802281 |\n",
      "|    std                | 5.63e+06     |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 69200       |\n",
      "|    time_elapsed       | 3334        |\n",
      "|    total_timesteps    | 346000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -493        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69199       |\n",
      "|    policy_loss        | 25.7        |\n",
      "|    reward             | 0.013174658 |\n",
      "|    std                | 5.83e+06    |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 69300        |\n",
      "|    time_elapsed       | 3339         |\n",
      "|    total_timesteps    | 346500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -493         |\n",
      "|    explained_variance | 0.642        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69299        |\n",
      "|    policy_loss        | 14.8         |\n",
      "|    reward             | -0.027425608 |\n",
      "|    std                | 6.01e+06     |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 69400      |\n",
      "|    time_elapsed       | 3344       |\n",
      "|    total_timesteps    | 347000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -494       |\n",
      "|    explained_variance | 0.0354     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69399      |\n",
      "|    policy_loss        | 10.2       |\n",
      "|    reward             | 0.07583289 |\n",
      "|    std                | 6.14e+06   |\n",
      "|    value_loss         | 0.00509    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 69500        |\n",
      "|    time_elapsed       | 3349         |\n",
      "|    total_timesteps    | 347500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -495         |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69499        |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | -0.005694515 |\n",
      "|    std                | 6.25e+06     |\n",
      "|    value_loss         | 4.27e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 3354         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -495         |\n",
      "|    explained_variance | -3.6         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | -3.07        |\n",
      "|    reward             | -0.024090711 |\n",
      "|    std                | 6.41e+06     |\n",
      "|    value_loss         | 0.000303     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 69700        |\n",
      "|    time_elapsed       | 3358         |\n",
      "|    total_timesteps    | 348500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -496         |\n",
      "|    explained_variance | -0.0782      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69699        |\n",
      "|    policy_loss        | 4.61         |\n",
      "|    reward             | 0.0059519964 |\n",
      "|    std                | 6.62e+06     |\n",
      "|    value_loss         | 0.000383     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 69800       |\n",
      "|    time_elapsed       | 3363        |\n",
      "|    total_timesteps    | 349000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -497        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | 6.37        |\n",
      "|    reward             | 0.009301364 |\n",
      "|    std                | 6.83e+06    |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 69900       |\n",
      "|    time_elapsed       | 3368        |\n",
      "|    total_timesteps    | 349500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -498        |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69899       |\n",
      "|    policy_loss        | -4.73       |\n",
      "|    reward             | -0.06664649 |\n",
      "|    std                | 7.03e+06    |\n",
      "|    value_loss         | 0.00044     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70000       |\n",
      "|    time_elapsed       | 3373        |\n",
      "|    total_timesteps    | 350000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -499        |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69999       |\n",
      "|    policy_loss        | 121         |\n",
      "|    reward             | 0.033001997 |\n",
      "|    std                | 7.17e+06    |\n",
      "|    value_loss         | 0.0646      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70100       |\n",
      "|    time_elapsed       | 3377        |\n",
      "|    total_timesteps    | 350500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -499        |\n",
      "|    explained_variance | -0.103      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70099       |\n",
      "|    policy_loss        | 7.91        |\n",
      "|    reward             | 0.008633859 |\n",
      "|    std                | 7.32e+06    |\n",
      "|    value_loss         | 0.000318    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70200       |\n",
      "|    time_elapsed       | 3382        |\n",
      "|    total_timesteps    | 351000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -500        |\n",
      "|    explained_variance | 0.791       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70199       |\n",
      "|    policy_loss        | -1.43       |\n",
      "|    reward             | 0.023631388 |\n",
      "|    std                | 7.51e+06    |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 70300        |\n",
      "|    time_elapsed       | 3387         |\n",
      "|    total_timesteps    | 351500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -501         |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 70299        |\n",
      "|    policy_loss        | -17          |\n",
      "|    reward             | -0.006554431 |\n",
      "|    std                | 7.74e+06     |\n",
      "|    value_loss         | 0.00139      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70400       |\n",
      "|    time_elapsed       | 3391        |\n",
      "|    total_timesteps    | 352000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -502        |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70399       |\n",
      "|    policy_loss        | 1.64        |\n",
      "|    reward             | 0.045945138 |\n",
      "|    std                | 7.97e+06    |\n",
      "|    value_loss         | 7.58e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70500       |\n",
      "|    time_elapsed       | 3396        |\n",
      "|    total_timesteps    | 352500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -502        |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70499       |\n",
      "|    policy_loss        | 6.28        |\n",
      "|    reward             | 0.093644604 |\n",
      "|    std                | 8.16e+06    |\n",
      "|    value_loss         | 0.000874    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70600       |\n",
      "|    time_elapsed       | 3401        |\n",
      "|    total_timesteps    | 353000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -503        |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70599       |\n",
      "|    policy_loss        | 6.22        |\n",
      "|    reward             | 0.024654377 |\n",
      "|    std                | 8.29e+06    |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70700       |\n",
      "|    time_elapsed       | 3406        |\n",
      "|    total_timesteps    | 353500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -503        |\n",
      "|    explained_variance | 0.265       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70699       |\n",
      "|    policy_loss        | 3.38        |\n",
      "|    reward             | -0.04071181 |\n",
      "|    std                | 8.48e+06    |\n",
      "|    value_loss         | 0.000209    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70800       |\n",
      "|    time_elapsed       | 3411        |\n",
      "|    total_timesteps    | 354000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -504        |\n",
      "|    explained_variance | -0.238      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | 25.7        |\n",
      "|    reward             | 0.009612198 |\n",
      "|    std                | 8.73e+06    |\n",
      "|    value_loss         | 0.00331     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 70900       |\n",
      "|    time_elapsed       | 3415        |\n",
      "|    total_timesteps    | 354500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -505        |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70899       |\n",
      "|    policy_loss        | 14.3        |\n",
      "|    reward             | 0.060370944 |\n",
      "|    std                | 9.02e+06    |\n",
      "|    value_loss         | 0.00089     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 71000       |\n",
      "|    time_elapsed       | 3420        |\n",
      "|    total_timesteps    | 355000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -506        |\n",
      "|    explained_variance | 0.807       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70999       |\n",
      "|    policy_loss        | -7.62       |\n",
      "|    reward             | -0.05186732 |\n",
      "|    std                | 9.29e+06    |\n",
      "|    value_loss         | 0.00046     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 3425        |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -507        |\n",
      "|    explained_variance | 0.33        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71099       |\n",
      "|    policy_loss        | 73.9        |\n",
      "|    reward             | -0.01272708 |\n",
      "|    std                | 9.51e+06    |\n",
      "|    value_loss         | 0.0333      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 71200        |\n",
      "|    time_elapsed       | 3430         |\n",
      "|    total_timesteps    | 356000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -507         |\n",
      "|    explained_variance | -1.84        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71199        |\n",
      "|    policy_loss        | -1.84        |\n",
      "|    reward             | 0.0019759315 |\n",
      "|    std                | 9.67e+06     |\n",
      "|    value_loss         | 9.34e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 71300        |\n",
      "|    time_elapsed       | 3435         |\n",
      "|    total_timesteps    | 356500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -508         |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71299        |\n",
      "|    policy_loss        | -49          |\n",
      "|    reward             | -0.009829852 |\n",
      "|    std                | 9.89e+06     |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 71400       |\n",
      "|    time_elapsed       | 3439        |\n",
      "|    total_timesteps    | 357000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -509        |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71399       |\n",
      "|    policy_loss        | 11.6        |\n",
      "|    reward             | -0.03779706 |\n",
      "|    std                | 1.02e+07    |\n",
      "|    value_loss         | 0.000575    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 71500       |\n",
      "|    time_elapsed       | 3444        |\n",
      "|    total_timesteps    | 357500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -510        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71499       |\n",
      "|    policy_loss        | -3.71       |\n",
      "|    reward             | 0.068039626 |\n",
      "|    std                | 1.05e+07    |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 71600        |\n",
      "|    time_elapsed       | 3449         |\n",
      "|    total_timesteps    | 358000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -510         |\n",
      "|    explained_variance | 0.591        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71599        |\n",
      "|    policy_loss        | 4.58         |\n",
      "|    reward             | 0.0028042078 |\n",
      "|    std                | 1.08e+07     |\n",
      "|    value_loss         | 0.000471     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 71700       |\n",
      "|    time_elapsed       | 3454        |\n",
      "|    total_timesteps    | 358500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -511        |\n",
      "|    explained_variance | 0.546       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71699       |\n",
      "|    policy_loss        | -52.4       |\n",
      "|    reward             | -0.17155024 |\n",
      "|    std                | 1.1e+07     |\n",
      "|    value_loss         | 0.0107      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 71800       |\n",
      "|    time_elapsed       | 3458        |\n",
      "|    total_timesteps    | 359000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -512        |\n",
      "|    explained_variance | 0.623       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71799       |\n",
      "|    policy_loss        | -1.79       |\n",
      "|    reward             | 0.011747476 |\n",
      "|    std                | 1.12e+07    |\n",
      "|    value_loss         | 2.41e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 71900        |\n",
      "|    time_elapsed       | 3463         |\n",
      "|    total_timesteps    | 359500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -512         |\n",
      "|    explained_variance | 0.8          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71899        |\n",
      "|    policy_loss        | 14.6         |\n",
      "|    reward             | 0.0095165055 |\n",
      "|    std                | 1.15e+07     |\n",
      "|    value_loss         | 0.000854     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 72000        |\n",
      "|    time_elapsed       | 3468         |\n",
      "|    total_timesteps    | 360000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -513         |\n",
      "|    explained_variance | -0.116       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71999        |\n",
      "|    policy_loss        | -11.2        |\n",
      "|    reward             | -0.024788165 |\n",
      "|    std                | 1.19e+07     |\n",
      "|    value_loss         | 0.000554     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 72100       |\n",
      "|    time_elapsed       | 3473        |\n",
      "|    total_timesteps    | 360500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -514        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72099       |\n",
      "|    policy_loss        | -12.9       |\n",
      "|    reward             | 0.056278747 |\n",
      "|    std                | 1.23e+07    |\n",
      "|    value_loss         | 0.00119     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 72200       |\n",
      "|    time_elapsed       | 3478        |\n",
      "|    total_timesteps    | 361000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -515        |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72199       |\n",
      "|    policy_loss        | 6.6         |\n",
      "|    reward             | 0.065078184 |\n",
      "|    std                | 1.27e+07    |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 72300      |\n",
      "|    time_elapsed       | 3482       |\n",
      "|    total_timesteps    | 361500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -516       |\n",
      "|    explained_variance | -1.33      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72299      |\n",
      "|    policy_loss        | -49.1      |\n",
      "|    reward             | 0.19925767 |\n",
      "|    std                | 1.3e+07    |\n",
      "|    value_loss         | 0.0131     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 72400        |\n",
      "|    time_elapsed       | 3487         |\n",
      "|    total_timesteps    | 362000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -516         |\n",
      "|    explained_variance | -0.286       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 72399        |\n",
      "|    policy_loss        | -4.42        |\n",
      "|    reward             | -0.011461097 |\n",
      "|    std                | 1.32e+07     |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 72500       |\n",
      "|    time_elapsed       | 3492        |\n",
      "|    total_timesteps    | 362500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -517        |\n",
      "|    explained_variance | 0.726       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72499       |\n",
      "|    policy_loss        | 0.64        |\n",
      "|    reward             | 0.030058414 |\n",
      "|    std                | 1.36e+07    |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 72600       |\n",
      "|    time_elapsed       | 3497        |\n",
      "|    total_timesteps    | 363000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -518        |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72599       |\n",
      "|    policy_loss        | -20         |\n",
      "|    reward             | 0.026488163 |\n",
      "|    std                | 1.4e+07     |\n",
      "|    value_loss         | 0.0017      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 3501         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -519         |\n",
      "|    explained_variance | 0.193        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | -13.5        |\n",
      "|    reward             | -0.016573487 |\n",
      "|    std                | 1.44e+07     |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 72800        |\n",
      "|    time_elapsed       | 3506         |\n",
      "|    total_timesteps    | 364000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -520         |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 72799        |\n",
      "|    policy_loss        | 8.03         |\n",
      "|    reward             | 0.0137399975 |\n",
      "|    std                | 1.48e+07     |\n",
      "|    value_loss         | 0.000947     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 72900     |\n",
      "|    time_elapsed       | 3511      |\n",
      "|    total_timesteps    | 364500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -520      |\n",
      "|    explained_variance | 0.626     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72899     |\n",
      "|    policy_loss        | 56.3      |\n",
      "|    reward             | 0.6295342 |\n",
      "|    std                | 1.51e+07  |\n",
      "|    value_loss         | 0.0569    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 73000       |\n",
      "|    time_elapsed       | 3516        |\n",
      "|    total_timesteps    | 365000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -521        |\n",
      "|    explained_variance | -0.597      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72999       |\n",
      "|    policy_loss        | -3.79       |\n",
      "|    reward             | 0.032004192 |\n",
      "|    std                | 1.54e+07    |\n",
      "|    value_loss         | 0.00022     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 73100        |\n",
      "|    time_elapsed       | 3520         |\n",
      "|    total_timesteps    | 365500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -521         |\n",
      "|    explained_variance | 0.542        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73099        |\n",
      "|    policy_loss        | 2.09         |\n",
      "|    reward             | -0.023404155 |\n",
      "|    std                | 1.58e+07     |\n",
      "|    value_loss         | 0.000538     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 73200        |\n",
      "|    time_elapsed       | 3525         |\n",
      "|    total_timesteps    | 366000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -522         |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73199        |\n",
      "|    policy_loss        | -9.3         |\n",
      "|    reward             | 0.0013909244 |\n",
      "|    std                | 1.63e+07     |\n",
      "|    value_loss         | 0.000374     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 73300       |\n",
      "|    time_elapsed       | 3530        |\n",
      "|    total_timesteps    | 366500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -523        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | -5.02       |\n",
      "|    reward             | 0.052411705 |\n",
      "|    std                | 1.67e+07    |\n",
      "|    value_loss         | 0.000245    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 3535        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -524        |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | 0.981       |\n",
      "|    reward             | -0.08673674 |\n",
      "|    std                | 1.71e+07    |\n",
      "|    value_loss         | 0.00264     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 73500        |\n",
      "|    time_elapsed       | 3539         |\n",
      "|    total_timesteps    | 367500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -524         |\n",
      "|    explained_variance | 0.0504       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73499        |\n",
      "|    policy_loss        | 6.05         |\n",
      "|    reward             | 0.0010706842 |\n",
      "|    std                | 1.74e+07     |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 73600        |\n",
      "|    time_elapsed       | 3544         |\n",
      "|    total_timesteps    | 368000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -525         |\n",
      "|    explained_variance | 0.766        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73599        |\n",
      "|    policy_loss        | -4.77        |\n",
      "|    reward             | -0.027199605 |\n",
      "|    std                | 1.78e+07     |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 3549        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -526        |\n",
      "|    explained_variance | 0.142       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | -2.95       |\n",
      "|    reward             | 0.052343987 |\n",
      "|    std                | 1.83e+07    |\n",
      "|    value_loss         | 0.000548    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 73800       |\n",
      "|    time_elapsed       | 3554        |\n",
      "|    total_timesteps    | 369000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -527        |\n",
      "|    explained_variance | 0.835       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | 11.2        |\n",
      "|    reward             | 0.030860852 |\n",
      "|    std                | 1.88e+07    |\n",
      "|    value_loss         | 0.000712    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 73900       |\n",
      "|    time_elapsed       | 3558        |\n",
      "|    total_timesteps    | 369500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -527        |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73899       |\n",
      "|    policy_loss        | -2.09       |\n",
      "|    reward             | -0.02124623 |\n",
      "|    std                | 1.94e+07    |\n",
      "|    value_loss         | 7.1e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 74000        |\n",
      "|    time_elapsed       | 3563         |\n",
      "|    total_timesteps    | 370000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -528         |\n",
      "|    explained_variance | 0.621        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73999        |\n",
      "|    policy_loss        | -71.3        |\n",
      "|    reward             | -0.059966892 |\n",
      "|    std                | 1.98e+07     |\n",
      "|    value_loss         | 0.0235       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 74100        |\n",
      "|    time_elapsed       | 3568         |\n",
      "|    total_timesteps    | 370500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -528         |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74099        |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.006144401 |\n",
      "|    std                | 2.01e+07     |\n",
      "|    value_loss         | 4.86e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 74200      |\n",
      "|    time_elapsed       | 3573       |\n",
      "|    total_timesteps    | 371000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -529       |\n",
      "|    explained_variance | 0.904      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 74199      |\n",
      "|    policy_loss        | 0.704      |\n",
      "|    reward             | 0.05393819 |\n",
      "|    std                | 2.06e+07   |\n",
      "|    value_loss         | 0.000162   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 74300       |\n",
      "|    time_elapsed       | 3577        |\n",
      "|    total_timesteps    | 371500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -530        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | 1.95        |\n",
      "|    reward             | -0.04751805 |\n",
      "|    std                | 2.12e+07    |\n",
      "|    value_loss         | 3.57e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 74400       |\n",
      "|    time_elapsed       | 3582        |\n",
      "|    total_timesteps    | 372000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -531        |\n",
      "|    explained_variance | 0.721       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74399       |\n",
      "|    policy_loss        | 21.4        |\n",
      "|    reward             | 0.055402625 |\n",
      "|    std                | 2.18e+07    |\n",
      "|    value_loss         | 0.00254     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 74500        |\n",
      "|    time_elapsed       | 3587         |\n",
      "|    total_timesteps    | 372500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -532         |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74499        |\n",
      "|    policy_loss        | 6.61         |\n",
      "|    reward             | 0.0071490076 |\n",
      "|    std                | 2.24e+07     |\n",
      "|    value_loss         | 0.000423     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 74600        |\n",
      "|    time_elapsed       | 3592         |\n",
      "|    total_timesteps    | 373000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -532         |\n",
      "|    explained_variance | -2.18        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74599        |\n",
      "|    policy_loss        | -4.16        |\n",
      "|    reward             | -0.014767648 |\n",
      "|    std                | 2.28e+07     |\n",
      "|    value_loss         | 0.00481      |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18105964.16\n",
      "total_reward: 8105964.16\n",
      "total_cost: 562636.17\n",
      "total_trades: 82821\n",
      "Sharpe: 0.600\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 74700       |\n",
      "|    time_elapsed       | 3597        |\n",
      "|    total_timesteps    | 373500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -533        |\n",
      "|    explained_variance | 0.6         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74699       |\n",
      "|    policy_loss        | 4.6         |\n",
      "|    reward             | 0.008037109 |\n",
      "|    std                | 2.32e+07    |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 74800        |\n",
      "|    time_elapsed       | 3601         |\n",
      "|    total_timesteps    | 374000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -533         |\n",
      "|    explained_variance | -2.86        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74799        |\n",
      "|    policy_loss        | -8.31        |\n",
      "|    reward             | -0.002224995 |\n",
      "|    std                | 2.38e+07     |\n",
      "|    value_loss         | 0.000313     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 74900         |\n",
      "|    time_elapsed       | 3606          |\n",
      "|    total_timesteps    | 374500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -534          |\n",
      "|    explained_variance | 0.703         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 74899         |\n",
      "|    policy_loss        | -3.4          |\n",
      "|    reward             | -0.0089723505 |\n",
      "|    std                | 2.45e+07      |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 75000       |\n",
      "|    time_elapsed       | 3611        |\n",
      "|    total_timesteps    | 375000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -535        |\n",
      "|    explained_variance | 0.784       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74999       |\n",
      "|    policy_loss        | 2.8         |\n",
      "|    reward             | 0.026042828 |\n",
      "|    std                | 2.54e+07    |\n",
      "|    value_loss         | 0.000296    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 75100       |\n",
      "|    time_elapsed       | 3616        |\n",
      "|    total_timesteps    | 375500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -536        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75099       |\n",
      "|    policy_loss        | -28.5       |\n",
      "|    reward             | -0.11513521 |\n",
      "|    std                | 2.63e+07    |\n",
      "|    value_loss         | 0.00357     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 75200       |\n",
      "|    time_elapsed       | 3620        |\n",
      "|    total_timesteps    | 376000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -537        |\n",
      "|    explained_variance | 0.268       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75199       |\n",
      "|    policy_loss        | 24.8        |\n",
      "|    reward             | -0.54441196 |\n",
      "|    std                | 2.69e+07    |\n",
      "|    value_loss         | 0.00984     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 75300        |\n",
      "|    time_elapsed       | 3625         |\n",
      "|    total_timesteps    | 376500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -537         |\n",
      "|    explained_variance | 0.365        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75299        |\n",
      "|    policy_loss        | -12.5        |\n",
      "|    reward             | -0.021662291 |\n",
      "|    std                | 2.74e+07     |\n",
      "|    value_loss         | 0.000707     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 75400        |\n",
      "|    time_elapsed       | 3630         |\n",
      "|    total_timesteps    | 377000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -538         |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75399        |\n",
      "|    policy_loss        | 2.43         |\n",
      "|    reward             | 0.0025036475 |\n",
      "|    std                | 2.82e+07     |\n",
      "|    value_loss         | 3.89e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 75500       |\n",
      "|    time_elapsed       | 3635        |\n",
      "|    total_timesteps    | 377500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -539        |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75499       |\n",
      "|    policy_loss        | -10.6       |\n",
      "|    reward             | 0.012928454 |\n",
      "|    std                | 2.92e+07    |\n",
      "|    value_loss         | 0.00146     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 75600         |\n",
      "|    time_elapsed       | 3640          |\n",
      "|    total_timesteps    | 378000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -540          |\n",
      "|    explained_variance | 0.201         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 75599         |\n",
      "|    policy_loss        | -4            |\n",
      "|    reward             | -0.0032726536 |\n",
      "|    std                | 3.02e+07      |\n",
      "|    value_loss         | 0.000545      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 75700      |\n",
      "|    time_elapsed       | 3644       |\n",
      "|    total_timesteps    | 378500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -541       |\n",
      "|    explained_variance | -0.419     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 75699      |\n",
      "|    policy_loss        | -8.3       |\n",
      "|    reward             | 0.07392873 |\n",
      "|    std                | 3.11e+07   |\n",
      "|    value_loss         | 0.00146    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 75800       |\n",
      "|    time_elapsed       | 3649        |\n",
      "|    total_timesteps    | 379000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -541        |\n",
      "|    explained_variance | -4.23       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75799       |\n",
      "|    policy_loss        | -18         |\n",
      "|    reward             | 0.009033954 |\n",
      "|    std                | 3.15e+07    |\n",
      "|    value_loss         | 0.00139     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 3654        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -542        |\n",
      "|    explained_variance | -0.00474    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | 0.951       |\n",
      "|    reward             | 0.003505444 |\n",
      "|    std                | 3.22e+07    |\n",
      "|    value_loss         | 5.92e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 76000       |\n",
      "|    time_elapsed       | 3659        |\n",
      "|    total_timesteps    | 380000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -543        |\n",
      "|    explained_variance | 0.0687      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75999       |\n",
      "|    policy_loss        | -1.74       |\n",
      "|    reward             | 0.022761188 |\n",
      "|    std                | 3.31e+07    |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 76100         |\n",
      "|    time_elapsed       | 3663          |\n",
      "|    total_timesteps    | 380500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -544          |\n",
      "|    explained_variance | 0.875         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 76099         |\n",
      "|    policy_loss        | -38.1         |\n",
      "|    reward             | -0.0073991553 |\n",
      "|    std                | 3.41e+07      |\n",
      "|    value_loss         | 0.00567       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 76200       |\n",
      "|    time_elapsed       | 3668        |\n",
      "|    total_timesteps    | 381000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -545        |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76199       |\n",
      "|    policy_loss        | -24.3       |\n",
      "|    reward             | 0.060771994 |\n",
      "|    std                | 3.51e+07    |\n",
      "|    value_loss         | 0.00239     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 76300      |\n",
      "|    time_elapsed       | 3673       |\n",
      "|    total_timesteps    | 381500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -545       |\n",
      "|    explained_variance | 0.666      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76299      |\n",
      "|    policy_loss        | 37.1       |\n",
      "|    reward             | -0.4109729 |\n",
      "|    std                | 3.59e+07   |\n",
      "|    value_loss         | 0.0871     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 76400        |\n",
      "|    time_elapsed       | 3678         |\n",
      "|    total_timesteps    | 382000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -546         |\n",
      "|    explained_variance | -7.72        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 76399        |\n",
      "|    policy_loss        | 9.54         |\n",
      "|    reward             | 0.0013458693 |\n",
      "|    std                | 3.64e+07     |\n",
      "|    value_loss         | 0.000837     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 76500        |\n",
      "|    time_elapsed       | 3682         |\n",
      "|    total_timesteps    | 382500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -546         |\n",
      "|    explained_variance | 0.482        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 76499        |\n",
      "|    policy_loss        | -1.38        |\n",
      "|    reward             | -0.017299777 |\n",
      "|    std                | 3.72e+07     |\n",
      "|    value_loss         | 5.18e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 76600       |\n",
      "|    time_elapsed       | 3687        |\n",
      "|    total_timesteps    | 383000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -547        |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76599       |\n",
      "|    policy_loss        | -1.55       |\n",
      "|    reward             | 0.012010809 |\n",
      "|    std                | 3.82e+07    |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 76700       |\n",
      "|    time_elapsed       | 3692        |\n",
      "|    total_timesteps    | 383500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -548        |\n",
      "|    explained_variance | 0.733       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76699       |\n",
      "|    policy_loss        | 13.6        |\n",
      "|    reward             | 0.015394185 |\n",
      "|    std                | 3.94e+07    |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 76800        |\n",
      "|    time_elapsed       | 3697         |\n",
      "|    total_timesteps    | 384000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -549         |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 76799        |\n",
      "|    policy_loss        | -8.11        |\n",
      "|    reward             | -0.015539825 |\n",
      "|    std                | 4.06e+07     |\n",
      "|    value_loss         | 0.000227     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 76900      |\n",
      "|    time_elapsed       | 3701       |\n",
      "|    total_timesteps    | 384500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -549       |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76899      |\n",
      "|    policy_loss        | 44.3       |\n",
      "|    reward             | 0.15815201 |\n",
      "|    std                | 4.15e+07   |\n",
      "|    value_loss         | 0.00752    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 77000         |\n",
      "|    time_elapsed       | 3706          |\n",
      "|    total_timesteps    | 385000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -550          |\n",
      "|    explained_variance | 0.289         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 76999         |\n",
      "|    policy_loss        | -7.57         |\n",
      "|    reward             | -0.0035674288 |\n",
      "|    std                | 4.22e+07      |\n",
      "|    value_loss         | 0.000272      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 77100        |\n",
      "|    time_elapsed       | 3711         |\n",
      "|    total_timesteps    | 385500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -551         |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77099        |\n",
      "|    policy_loss        | 8.64         |\n",
      "|    reward             | -0.009420641 |\n",
      "|    std                | 4.32e+07     |\n",
      "|    value_loss         | 0.000282     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 77200       |\n",
      "|    time_elapsed       | 3716        |\n",
      "|    total_timesteps    | 386000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -551        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77199       |\n",
      "|    policy_loss        | -8.95       |\n",
      "|    reward             | 0.023097305 |\n",
      "|    std                | 4.45e+07    |\n",
      "|    value_loss         | 0.00027     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 3720        |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -552        |\n",
      "|    explained_variance | 0.606       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77299       |\n",
      "|    policy_loss        | 0.773       |\n",
      "|    reward             | 0.000894792 |\n",
      "|    std                | 4.59e+07    |\n",
      "|    value_loss         | 0.000426    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 77400      |\n",
      "|    time_elapsed       | 3725       |\n",
      "|    total_timesteps    | 387000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -553       |\n",
      "|    explained_variance | 0.433      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77399      |\n",
      "|    policy_loss        | 1.75       |\n",
      "|    reward             | 0.03271521 |\n",
      "|    std                | 4.71e+07   |\n",
      "|    value_loss         | 0.000693   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 77500       |\n",
      "|    time_elapsed       | 3730        |\n",
      "|    total_timesteps    | 387500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -553        |\n",
      "|    explained_variance | 0.634       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77499       |\n",
      "|    policy_loss        | 26.6        |\n",
      "|    reward             | 0.116410166 |\n",
      "|    std                | 4.78e+07    |\n",
      "|    value_loss         | 0.00746     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 77600        |\n",
      "|    time_elapsed       | 3735         |\n",
      "|    total_timesteps    | 388000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -554         |\n",
      "|    explained_variance | -5.44        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77599        |\n",
      "|    policy_loss        | 9.48         |\n",
      "|    reward             | -0.021954577 |\n",
      "|    std                | 4.85e+07     |\n",
      "|    value_loss         | 0.00146      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 77700        |\n",
      "|    time_elapsed       | 3739         |\n",
      "|    total_timesteps    | 388500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -555         |\n",
      "|    explained_variance | -4.3         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77699        |\n",
      "|    policy_loss        | -13.4        |\n",
      "|    reward             | 0.0137887085 |\n",
      "|    std                | 4.97e+07     |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 77800       |\n",
      "|    time_elapsed       | 3744        |\n",
      "|    total_timesteps    | 389000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -555        |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77799       |\n",
      "|    policy_loss        | 3.04        |\n",
      "|    reward             | 0.041001547 |\n",
      "|    std                | 5.12e+07    |\n",
      "|    value_loss         | 0.00018     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 77900        |\n",
      "|    time_elapsed       | 3749         |\n",
      "|    total_timesteps    | 389500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -556         |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77899        |\n",
      "|    policy_loss        | 24.1         |\n",
      "|    reward             | 0.0054850294 |\n",
      "|    std                | 5.26e+07     |\n",
      "|    value_loss         | 0.00221      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 78000       |\n",
      "|    time_elapsed       | 3755        |\n",
      "|    total_timesteps    | 390000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -557        |\n",
      "|    explained_variance | 0.769       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77999       |\n",
      "|    policy_loss        | -27.7       |\n",
      "|    reward             | 0.003965517 |\n",
      "|    std                | 5.4e+07     |\n",
      "|    value_loss         | 0.00658     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 78100      |\n",
      "|    time_elapsed       | 3759       |\n",
      "|    total_timesteps    | 390500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -557       |\n",
      "|    explained_variance | 0.749      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78099      |\n",
      "|    policy_loss        | 350        |\n",
      "|    reward             | 0.37146723 |\n",
      "|    std                | 5.48e+07   |\n",
      "|    value_loss         | 0.424      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 78200       |\n",
      "|    time_elapsed       | 3764        |\n",
      "|    total_timesteps    | 391000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -558        |\n",
      "|    explained_variance | -1.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78199       |\n",
      "|    policy_loss        | -3.35       |\n",
      "|    reward             | 0.017055875 |\n",
      "|    std                | 5.59e+07    |\n",
      "|    value_loss         | 0.000132    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 78300        |\n",
      "|    time_elapsed       | 3769         |\n",
      "|    total_timesteps    | 391500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -559         |\n",
      "|    explained_variance | -0.448       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 78299        |\n",
      "|    policy_loss        | 1.22         |\n",
      "|    reward             | 0.0011770665 |\n",
      "|    std                | 5.73e+07     |\n",
      "|    value_loss         | 7.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 78400        |\n",
      "|    time_elapsed       | 3774         |\n",
      "|    total_timesteps    | 392000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -560         |\n",
      "|    explained_variance | 0.0784       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 78399        |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | -0.020457456 |\n",
      "|    std                | 5.91e+07     |\n",
      "|    value_loss         | 0.000269     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 78500       |\n",
      "|    time_elapsed       | 3779        |\n",
      "|    total_timesteps    | 392500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -561        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78499       |\n",
      "|    policy_loss        | 2.47        |\n",
      "|    reward             | -0.06555242 |\n",
      "|    std                | 6.11e+07    |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 78600      |\n",
      "|    time_elapsed       | 3783       |\n",
      "|    total_timesteps    | 393000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -561       |\n",
      "|    explained_variance | -1.56      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78599      |\n",
      "|    policy_loss        | -28        |\n",
      "|    reward             | 0.07995881 |\n",
      "|    std                | 6.29e+07   |\n",
      "|    value_loss         | 0.00362    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 78700         |\n",
      "|    time_elapsed       | 3788          |\n",
      "|    total_timesteps    | 393500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -562          |\n",
      "|    explained_variance | 0.423         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 78699         |\n",
      "|    policy_loss        | 4.51          |\n",
      "|    reward             | -0.0048393733 |\n",
      "|    std                | 6.37e+07      |\n",
      "|    value_loss         | 0.000127      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 78800       |\n",
      "|    time_elapsed       | 3793        |\n",
      "|    total_timesteps    | 394000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -562        |\n",
      "|    explained_variance | 0.489       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78799       |\n",
      "|    policy_loss        | -11.8       |\n",
      "|    reward             | -0.02327867 |\n",
      "|    std                | 6.51e+07    |\n",
      "|    value_loss         | 0.000666    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 78900       |\n",
      "|    time_elapsed       | 3798        |\n",
      "|    total_timesteps    | 394500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -563        |\n",
      "|    explained_variance | 0.757       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | 9.86        |\n",
      "|    reward             | 0.018653836 |\n",
      "|    std                | 6.7e+07     |\n",
      "|    value_loss         | 0.000431    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79000       |\n",
      "|    time_elapsed       | 3802        |\n",
      "|    total_timesteps    | 395000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -564        |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78999       |\n",
      "|    policy_loss        | -4.03       |\n",
      "|    reward             | 0.014694226 |\n",
      "|    std                | 6.92e+07    |\n",
      "|    value_loss         | 0.000304    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 79100        |\n",
      "|    time_elapsed       | 3807         |\n",
      "|    total_timesteps    | 395500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -565         |\n",
      "|    explained_variance | 0.647        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 79099        |\n",
      "|    policy_loss        | 0.811        |\n",
      "|    reward             | -0.010235319 |\n",
      "|    std                | 7.15e+07     |\n",
      "|    value_loss         | 0.000644     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 3812        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -566        |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | 140         |\n",
      "|    reward             | 0.051094092 |\n",
      "|    std                | 7.31e+07    |\n",
      "|    value_loss         | 0.0629      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79300       |\n",
      "|    time_elapsed       | 3817        |\n",
      "|    total_timesteps    | 396500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -566        |\n",
      "|    explained_variance | 0.285       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79299       |\n",
      "|    policy_loss        | 12.9        |\n",
      "|    reward             | 0.009742759 |\n",
      "|    std                | 7.43e+07    |\n",
      "|    value_loss         | 0.000545    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79400       |\n",
      "|    time_elapsed       | 3821        |\n",
      "|    total_timesteps    | 397000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -567        |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79399       |\n",
      "|    policy_loss        | -39.2       |\n",
      "|    reward             | 0.048030708 |\n",
      "|    std                | 7.6e+07     |\n",
      "|    value_loss         | 0.00536     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 79500        |\n",
      "|    time_elapsed       | 3826         |\n",
      "|    total_timesteps    | 397500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -568         |\n",
      "|    explained_variance | 0.634        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 79499        |\n",
      "|    policy_loss        | 0.565        |\n",
      "|    reward             | -0.004044488 |\n",
      "|    std                | 7.81e+07     |\n",
      "|    value_loss         | 0.000304     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79600       |\n",
      "|    time_elapsed       | 3831        |\n",
      "|    total_timesteps    | 398000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -569        |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79599       |\n",
      "|    policy_loss        | -17.8       |\n",
      "|    reward             | -0.09614066 |\n",
      "|    std                | 8.05e+07    |\n",
      "|    value_loss         | 0.00187     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79700       |\n",
      "|    time_elapsed       | 3836        |\n",
      "|    total_timesteps    | 398500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -569        |\n",
      "|    explained_variance | -0.999      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79699       |\n",
      "|    policy_loss        | 33.9        |\n",
      "|    reward             | 0.029365426 |\n",
      "|    std                | 8.28e+07    |\n",
      "|    value_loss         | 0.00508     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 79800        |\n",
      "|    time_elapsed       | 3840         |\n",
      "|    total_timesteps    | 399000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -570         |\n",
      "|    explained_variance | -0.394       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 79799        |\n",
      "|    policy_loss        | -29          |\n",
      "|    reward             | -0.030065501 |\n",
      "|    std                | 8.44e+07     |\n",
      "|    value_loss         | 0.0053       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 79900       |\n",
      "|    time_elapsed       | 3845        |\n",
      "|    total_timesteps    | 399500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -570        |\n",
      "|    explained_variance | -13.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79899       |\n",
      "|    policy_loss        | 14.7        |\n",
      "|    reward             | 0.002393425 |\n",
      "|    std                | 8.55e+07    |\n",
      "|    value_loss         | 0.000743    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 80000       |\n",
      "|    time_elapsed       | 3850        |\n",
      "|    total_timesteps    | 400000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -571        |\n",
      "|    explained_variance | -2.3        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79999       |\n",
      "|    policy_loss        | -12.9       |\n",
      "|    reward             | 0.021789962 |\n",
      "|    std                | 8.74e+07    |\n",
      "|    value_loss         | 0.000553    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 80100       |\n",
      "|    time_elapsed       | 3855        |\n",
      "|    total_timesteps    | 400500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -572        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80099       |\n",
      "|    policy_loss        | -5.03       |\n",
      "|    reward             | 0.036124703 |\n",
      "|    std                | 8.96e+07    |\n",
      "|    value_loss         | 9.08e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 80200        |\n",
      "|    time_elapsed       | 3860         |\n",
      "|    total_timesteps    | 401000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -573         |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 80199        |\n",
      "|    policy_loss        | -14.7        |\n",
      "|    reward             | -0.072177514 |\n",
      "|    std                | 9.23e+07     |\n",
      "|    value_loss         | 0.000763     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 80300       |\n",
      "|    time_elapsed       | 3864        |\n",
      "|    total_timesteps    | 401500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -573        |\n",
      "|    explained_variance | -3.53       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80299       |\n",
      "|    policy_loss        | 69.9        |\n",
      "|    reward             | 0.030957812 |\n",
      "|    std                | 9.47e+07    |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 80400       |\n",
      "|    time_elapsed       | 3869        |\n",
      "|    total_timesteps    | 402000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -574        |\n",
      "|    explained_variance | 0.6         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80399       |\n",
      "|    policy_loss        | 2.41        |\n",
      "|    reward             | -0.12877442 |\n",
      "|    std                | 9.62e+07    |\n",
      "|    value_loss         | 0.000895    |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18446725.78\n",
      "total_reward: 8446725.78\n",
      "total_cost: 559965.09\n",
      "total_trades: 82435\n",
      "Sharpe: 0.513\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 80500        |\n",
      "|    time_elapsed       | 3874         |\n",
      "|    total_timesteps    | 402500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -574         |\n",
      "|    explained_variance | 0.435        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 80499        |\n",
      "|    policy_loss        | 10.2         |\n",
      "|    reward             | -0.004186362 |\n",
      "|    std                | 9.77e+07     |\n",
      "|    value_loss         | 0.000473     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 80600        |\n",
      "|    time_elapsed       | 3878         |\n",
      "|    total_timesteps    | 403000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -575         |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 80599        |\n",
      "|    policy_loss        | 2.86         |\n",
      "|    reward             | -0.007787424 |\n",
      "|    std                | 1e+08        |\n",
      "|    value_loss         | 9.19e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 80700      |\n",
      "|    time_elapsed       | 3883       |\n",
      "|    total_timesteps    | 403500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -576       |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80699      |\n",
      "|    policy_loss        | 3.5        |\n",
      "|    reward             | 0.04379889 |\n",
      "|    std                | 1.04e+08   |\n",
      "|    value_loss         | 7.84e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 80800        |\n",
      "|    time_elapsed       | 3888         |\n",
      "|    total_timesteps    | 404000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -577         |\n",
      "|    explained_variance | -0.196       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 80799        |\n",
      "|    policy_loss        | 12.4         |\n",
      "|    reward             | -0.040997796 |\n",
      "|    std                | 1.07e+08     |\n",
      "|    value_loss         | 0.000677     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 80900      |\n",
      "|    time_elapsed       | 3893       |\n",
      "|    total_timesteps    | 404500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -578       |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80899      |\n",
      "|    policy_loss        | -4.63      |\n",
      "|    reward             | 0.08313659 |\n",
      "|    std                | 1.1e+08    |\n",
      "|    value_loss         | 0.000289   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 81000      |\n",
      "|    time_elapsed       | 3898       |\n",
      "|    total_timesteps    | 405000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -578       |\n",
      "|    explained_variance | 0.296      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80999      |\n",
      "|    policy_loss        | 194        |\n",
      "|    reward             | 0.22193235 |\n",
      "|    std                | 1.12e+08   |\n",
      "|    value_loss         | 0.121      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 81100        |\n",
      "|    time_elapsed       | 3902         |\n",
      "|    total_timesteps    | 405500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -579         |\n",
      "|    explained_variance | -0.495       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81099        |\n",
      "|    policy_loss        | 10.9         |\n",
      "|    reward             | 0.0026316429 |\n",
      "|    std                | 1.15e+08     |\n",
      "|    value_loss         | 0.000572     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 81200      |\n",
      "|    time_elapsed       | 3907       |\n",
      "|    total_timesteps    | 406000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -580       |\n",
      "|    explained_variance | 0.784      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81199      |\n",
      "|    policy_loss        | 1.24       |\n",
      "|    reward             | 0.04460276 |\n",
      "|    std                | 1.18e+08   |\n",
      "|    value_loss         | 0.000173   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 81300       |\n",
      "|    time_elapsed       | 3912        |\n",
      "|    total_timesteps    | 406500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -581        |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81299       |\n",
      "|    policy_loss        | 6.13        |\n",
      "|    reward             | 0.020355454 |\n",
      "|    std                | 1.22e+08    |\n",
      "|    value_loss         | 0.000174    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 81400       |\n",
      "|    time_elapsed       | 3917        |\n",
      "|    total_timesteps    | 407000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -582        |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81399       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | 0.014492931 |\n",
      "|    std                | 1.27e+08    |\n",
      "|    value_loss         | 0.000173    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 81500      |\n",
      "|    time_elapsed       | 3921       |\n",
      "|    total_timesteps    | 407500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -583       |\n",
      "|    explained_variance | 0.771      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81499      |\n",
      "|    policy_loss        | -63.2      |\n",
      "|    reward             | 0.22139637 |\n",
      "|    std                | 1.31e+08   |\n",
      "|    value_loss         | 0.0125     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 81600       |\n",
      "|    time_elapsed       | 3926        |\n",
      "|    total_timesteps    | 408000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -583        |\n",
      "|    explained_variance | -0.167      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81599       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | 0.015265826 |\n",
      "|    std                | 1.34e+08    |\n",
      "|    value_loss         | 3.52e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 81700       |\n",
      "|    time_elapsed       | 3931        |\n",
      "|    total_timesteps    | 408500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -584        |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81699       |\n",
      "|    policy_loss        | 3.82        |\n",
      "|    reward             | 0.001894341 |\n",
      "|    std                | 1.37e+08    |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 81800         |\n",
      "|    time_elapsed       | 3936          |\n",
      "|    total_timesteps    | 409000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -585          |\n",
      "|    explained_variance | 0.806         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 81799         |\n",
      "|    policy_loss        | 2.7           |\n",
      "|    reward             | -0.0027361058 |\n",
      "|    std                | 1.42e+08      |\n",
      "|    value_loss         | 0.000246      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 81900        |\n",
      "|    time_elapsed       | 3941         |\n",
      "|    total_timesteps    | 409500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -586         |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81899        |\n",
      "|    policy_loss        | 12.9         |\n",
      "|    reward             | -0.014806869 |\n",
      "|    std                | 1.46e+08     |\n",
      "|    value_loss         | 0.000589     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82000       |\n",
      "|    time_elapsed       | 3945        |\n",
      "|    total_timesteps    | 410000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -586        |\n",
      "|    explained_variance | -0.441      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81999       |\n",
      "|    policy_loss        | -1.73       |\n",
      "|    reward             | -0.06967793 |\n",
      "|    std                | 1.49e+08    |\n",
      "|    value_loss         | 0.00051     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82100       |\n",
      "|    time_elapsed       | 3950        |\n",
      "|    total_timesteps    | 410500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -587        |\n",
      "|    explained_variance | 0.195       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82099       |\n",
      "|    policy_loss        | 75.3        |\n",
      "|    reward             | -0.00935457 |\n",
      "|    std                | 1.51e+08    |\n",
      "|    value_loss         | 0.0183      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 82200        |\n",
      "|    time_elapsed       | 3955         |\n",
      "|    total_timesteps    | 411000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -587         |\n",
      "|    explained_variance | 0.664        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 82199        |\n",
      "|    policy_loss        | -7.41        |\n",
      "|    reward             | 0.0074160085 |\n",
      "|    std                | 1.54e+08     |\n",
      "|    value_loss         | 0.00019      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 82300      |\n",
      "|    time_elapsed       | 3960       |\n",
      "|    total_timesteps    | 411500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -588       |\n",
      "|    explained_variance | 0.448      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82299      |\n",
      "|    policy_loss        | 9.04       |\n",
      "|    reward             | 0.04035445 |\n",
      "|    std                | 1.57e+08   |\n",
      "|    value_loss         | 0.00222    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82400       |\n",
      "|    time_elapsed       | 3965        |\n",
      "|    total_timesteps    | 412000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -589        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82399       |\n",
      "|    policy_loss        | 5.64        |\n",
      "|    reward             | 0.028324787 |\n",
      "|    std                | 1.61e+08    |\n",
      "|    value_loss         | 0.000157    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82500       |\n",
      "|    time_elapsed       | 3969        |\n",
      "|    total_timesteps    | 412500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -590        |\n",
      "|    explained_variance | 0.821       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82499       |\n",
      "|    policy_loss        | 20.9        |\n",
      "|    reward             | 0.011455793 |\n",
      "|    std                | 1.66e+08    |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82600       |\n",
      "|    time_elapsed       | 3974        |\n",
      "|    total_timesteps    | 413000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -590        |\n",
      "|    explained_variance | 0.76        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82599       |\n",
      "|    policy_loss        | -38.2       |\n",
      "|    reward             | 0.003746563 |\n",
      "|    std                | 1.71e+08    |\n",
      "|    value_loss         | 0.00556     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82700       |\n",
      "|    time_elapsed       | 3979        |\n",
      "|    total_timesteps    | 413500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -591        |\n",
      "|    explained_variance | 0.639       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 82.4        |\n",
      "|    reward             | 0.017866999 |\n",
      "|    std                | 1.74e+08    |\n",
      "|    value_loss         | 0.0299      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82800       |\n",
      "|    time_elapsed       | 3984        |\n",
      "|    total_timesteps    | 414000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -591        |\n",
      "|    explained_variance | 0.37        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | -0.0936     |\n",
      "|    reward             | 0.012453865 |\n",
      "|    std                | 1.77e+08    |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 82900       |\n",
      "|    time_elapsed       | 3988        |\n",
      "|    total_timesteps    | 414500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -592        |\n",
      "|    explained_variance | 0.0983      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82899       |\n",
      "|    policy_loss        | -1.28       |\n",
      "|    reward             | 0.019297948 |\n",
      "|    std                | 1.81e+08    |\n",
      "|    value_loss         | 7.64e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 83000        |\n",
      "|    time_elapsed       | 3993         |\n",
      "|    total_timesteps    | 415000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -593         |\n",
      "|    explained_variance | -6.9         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 82999        |\n",
      "|    policy_loss        | 47.3         |\n",
      "|    reward             | 0.0041639847 |\n",
      "|    std                | 1.87e+08     |\n",
      "|    value_loss         | 0.0085       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 83100      |\n",
      "|    time_elapsed       | 3998       |\n",
      "|    total_timesteps    | 415500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -594       |\n",
      "|    explained_variance | 0.754      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83099      |\n",
      "|    policy_loss        | 29.9       |\n",
      "|    reward             | 0.12524791 |\n",
      "|    std                | 1.92e+08   |\n",
      "|    value_loss         | 0.00309    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 83200     |\n",
      "|    time_elapsed       | 4003      |\n",
      "|    total_timesteps    | 416000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -595      |\n",
      "|    explained_variance | 0.953     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83199     |\n",
      "|    policy_loss        | -23.7     |\n",
      "|    reward             | 0.1495957 |\n",
      "|    std                | 1.97e+08  |\n",
      "|    value_loss         | 0.00275   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 83300        |\n",
      "|    time_elapsed       | 4008         |\n",
      "|    total_timesteps    | 416500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -595         |\n",
      "|    explained_variance | 0.358        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 83299        |\n",
      "|    policy_loss        | -52.1        |\n",
      "|    reward             | -0.019236648 |\n",
      "|    std                | 2.01e+08     |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 83400       |\n",
      "|    time_elapsed       | 4012        |\n",
      "|    total_timesteps    | 417000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -596        |\n",
      "|    explained_variance | 0.013       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 83399       |\n",
      "|    policy_loss        | 6.82        |\n",
      "|    reward             | 0.020506212 |\n",
      "|    std                | 2.04e+08    |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 83500      |\n",
      "|    time_elapsed       | 4017       |\n",
      "|    total_timesteps    | 417500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -596       |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83499      |\n",
      "|    policy_loss        | 0.931      |\n",
      "|    reward             | 0.00508085 |\n",
      "|    std                | 2.09e+08   |\n",
      "|    value_loss         | 2.54e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 83600        |\n",
      "|    time_elapsed       | 4022         |\n",
      "|    total_timesteps    | 418000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -597         |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 83599        |\n",
      "|    policy_loss        | 11           |\n",
      "|    reward             | -0.016906448 |\n",
      "|    std                | 2.16e+08     |\n",
      "|    value_loss         | 0.000414     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 83700        |\n",
      "|    time_elapsed       | 4027         |\n",
      "|    total_timesteps    | 418500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -598         |\n",
      "|    explained_variance | 0.639        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 83699        |\n",
      "|    policy_loss        | 0.955        |\n",
      "|    reward             | -0.035381377 |\n",
      "|    std                | 2.23e+08     |\n",
      "|    value_loss         | 0.000102     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 83800       |\n",
      "|    time_elapsed       | 4031        |\n",
      "|    total_timesteps    | 419000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -599        |\n",
      "|    explained_variance | 0.65        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 83799       |\n",
      "|    policy_loss        | 29.1        |\n",
      "|    reward             | -0.05840318 |\n",
      "|    std                | 2.29e+08    |\n",
      "|    value_loss         | 0.00296     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 83900         |\n",
      "|    time_elapsed       | 4036          |\n",
      "|    total_timesteps    | 419500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -599          |\n",
      "|    explained_variance | -35.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 83899         |\n",
      "|    policy_loss        | -19           |\n",
      "|    reward             | 0.00052287185 |\n",
      "|    std                | 2.33e+08      |\n",
      "|    value_loss         | 0.00149       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 84000        |\n",
      "|    time_elapsed       | 4041         |\n",
      "|    total_timesteps    | 420000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -600         |\n",
      "|    explained_variance | 0.38         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 83999        |\n",
      "|    policy_loss        | -13.3        |\n",
      "|    reward             | -0.047349468 |\n",
      "|    std                | 2.37e+08     |\n",
      "|    value_loss         | 0.000582     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 84100       |\n",
      "|    time_elapsed       | 4046        |\n",
      "|    total_timesteps    | 420500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -601        |\n",
      "|    explained_variance | 0.755       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84099       |\n",
      "|    policy_loss        | 3.35        |\n",
      "|    reward             | 0.002910465 |\n",
      "|    std                | 2.43e+08    |\n",
      "|    value_loss         | 0.000542    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 84200       |\n",
      "|    time_elapsed       | 4050        |\n",
      "|    total_timesteps    | 421000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -602        |\n",
      "|    explained_variance | 0.703       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84199       |\n",
      "|    policy_loss        | 11.6        |\n",
      "|    reward             | -0.07725394 |\n",
      "|    std                | 2.51e+08    |\n",
      "|    value_loss         | 0.000882    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 84300       |\n",
      "|    time_elapsed       | 4055        |\n",
      "|    total_timesteps    | 421500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -602        |\n",
      "|    explained_variance | 0.34        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84299       |\n",
      "|    policy_loss        | -6.84       |\n",
      "|    reward             | 0.062113587 |\n",
      "|    std                | 2.58e+08    |\n",
      "|    value_loss         | 0.000493    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 84400      |\n",
      "|    time_elapsed       | 4060       |\n",
      "|    total_timesteps    | 422000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -603       |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84399      |\n",
      "|    policy_loss        | -59.6      |\n",
      "|    reward             | 0.19068818 |\n",
      "|    std                | 2.66e+08   |\n",
      "|    value_loss         | 0.0117     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 84500        |\n",
      "|    time_elapsed       | 4065         |\n",
      "|    total_timesteps    | 422500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -604         |\n",
      "|    explained_variance | -0.727       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 84499        |\n",
      "|    policy_loss        | 2.09         |\n",
      "|    reward             | 0.0063037723 |\n",
      "|    std                | 2.71e+08     |\n",
      "|    value_loss         | 4.02e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 84600        |\n",
      "|    time_elapsed       | 4070         |\n",
      "|    total_timesteps    | 423000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -604         |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 84599        |\n",
      "|    policy_loss        | -12.9        |\n",
      "|    reward             | -0.016991934 |\n",
      "|    std                | 2.77e+08     |\n",
      "|    value_loss         | 0.000477     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 84700        |\n",
      "|    time_elapsed       | 4074         |\n",
      "|    total_timesteps    | 423500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -605         |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 84699        |\n",
      "|    policy_loss        | -1.51        |\n",
      "|    reward             | -0.049064957 |\n",
      "|    std                | 2.86e+08     |\n",
      "|    value_loss         | 7.88e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 84800       |\n",
      "|    time_elapsed       | 4079        |\n",
      "|    total_timesteps    | 424000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -606        |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84799       |\n",
      "|    policy_loss        | 17.2        |\n",
      "|    reward             | -0.03315251 |\n",
      "|    std                | 2.96e+08    |\n",
      "|    value_loss         | 0.000882    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 84900       |\n",
      "|    time_elapsed       | 4084        |\n",
      "|    total_timesteps    | 424500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -607        |\n",
      "|    explained_variance | 0.78        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84899       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.034120284 |\n",
      "|    std                | 3.05e+08    |\n",
      "|    value_loss         | 0.000217    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 85000      |\n",
      "|    time_elapsed       | 4089       |\n",
      "|    total_timesteps    | 425000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -608       |\n",
      "|    explained_variance | 0.777      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84999      |\n",
      "|    policy_loss        | 16.5       |\n",
      "|    reward             | 0.09242908 |\n",
      "|    std                | 3.12e+08   |\n",
      "|    value_loss         | 0.00286    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 85100       |\n",
      "|    time_elapsed       | 4094        |\n",
      "|    total_timesteps    | 425500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -608        |\n",
      "|    explained_variance | 0.444       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85099       |\n",
      "|    policy_loss        | -1.89       |\n",
      "|    reward             | 0.004768986 |\n",
      "|    std                | 3.17e+08    |\n",
      "|    value_loss         | 2.33e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 85200        |\n",
      "|    time_elapsed       | 4098         |\n",
      "|    total_timesteps    | 426000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -609         |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 85199        |\n",
      "|    policy_loss        | -18.6        |\n",
      "|    reward             | -0.013034671 |\n",
      "|    std                | 3.25e+08     |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 85300         |\n",
      "|    time_elapsed       | 4103          |\n",
      "|    total_timesteps    | 426500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -610          |\n",
      "|    explained_variance | 0.856         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 85299         |\n",
      "|    policy_loss        | -7.51         |\n",
      "|    reward             | -0.0049007856 |\n",
      "|    std                | 3.34e+08      |\n",
      "|    value_loss         | 0.000222      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 85400       |\n",
      "|    time_elapsed       | 4108        |\n",
      "|    total_timesteps    | 427000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -611        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85399       |\n",
      "|    policy_loss        | -8.45       |\n",
      "|    reward             | -0.05673483 |\n",
      "|    std                | 3.45e+08    |\n",
      "|    value_loss         | 0.000215    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 85500        |\n",
      "|    time_elapsed       | 4113         |\n",
      "|    total_timesteps    | 427500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -612         |\n",
      "|    explained_variance | 0.421        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 85499        |\n",
      "|    policy_loss        | -13.1        |\n",
      "|    reward             | -0.004820138 |\n",
      "|    std                | 3.55e+08     |\n",
      "|    value_loss         | 0.00071      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 85600      |\n",
      "|    time_elapsed       | 4117       |\n",
      "|    total_timesteps    | 428000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -612       |\n",
      "|    explained_variance | 0.607      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85599      |\n",
      "|    policy_loss        | 43.6       |\n",
      "|    reward             | 0.01927931 |\n",
      "|    std                | 3.63e+08   |\n",
      "|    value_loss         | 0.00577    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 85700        |\n",
      "|    time_elapsed       | 4122         |\n",
      "|    total_timesteps    | 428500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -613         |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 85699        |\n",
      "|    policy_loss        | -1.52        |\n",
      "|    reward             | -0.016801726 |\n",
      "|    std                | 3.69e+08     |\n",
      "|    value_loss         | 7.07e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 85800        |\n",
      "|    time_elapsed       | 4127         |\n",
      "|    total_timesteps    | 429000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -614         |\n",
      "|    explained_variance | 0.232        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 85799        |\n",
      "|    policy_loss        | -9.3         |\n",
      "|    reward             | -0.013959101 |\n",
      "|    std                | 3.79e+08     |\n",
      "|    value_loss         | 0.000545     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 85900       |\n",
      "|    time_elapsed       | 4132        |\n",
      "|    total_timesteps    | 429500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -614        |\n",
      "|    explained_variance | 0.651       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85899       |\n",
      "|    policy_loss        | 3.67        |\n",
      "|    reward             | -0.05113149 |\n",
      "|    std                | 3.91e+08    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 86000         |\n",
      "|    time_elapsed       | 4137          |\n",
      "|    total_timesteps    | 430000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -615          |\n",
      "|    explained_variance | 0.705         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 85999         |\n",
      "|    policy_loss        | 6.33          |\n",
      "|    reward             | -0.0072423466 |\n",
      "|    std                | 4.03e+08      |\n",
      "|    value_loss         | 0.000682      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 86100     |\n",
      "|    time_elapsed       | 4141      |\n",
      "|    total_timesteps    | 430500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -616      |\n",
      "|    explained_variance | 0.536     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 86099     |\n",
      "|    policy_loss        | -40.3     |\n",
      "|    reward             | 0.1337416 |\n",
      "|    std                | 4.13e+08  |\n",
      "|    value_loss         | 0.0189    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 86200      |\n",
      "|    time_elapsed       | 4146       |\n",
      "|    total_timesteps    | 431000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -617       |\n",
      "|    explained_variance | 0.606      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86199      |\n",
      "|    policy_loss        | 9.38       |\n",
      "|    reward             | 0.19167791 |\n",
      "|    std                | 4.2e+08    |\n",
      "|    value_loss         | 0.0704     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19922097.81\n",
      "total_reward: 9922097.81\n",
      "total_cost: 562110.73\n",
      "total_trades: 82698\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 86300         |\n",
      "|    time_elapsed       | 4151          |\n",
      "|    total_timesteps    | 431500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -617          |\n",
      "|    explained_variance | 0.448         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 86299         |\n",
      "|    policy_loss        | -0.469        |\n",
      "|    reward             | -0.0012403873 |\n",
      "|    std                | 4.27e+08      |\n",
      "|    value_loss         | 5.79e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 86400        |\n",
      "|    time_elapsed       | 4156         |\n",
      "|    total_timesteps    | 432000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -618         |\n",
      "|    explained_variance | -0.0901      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 86399        |\n",
      "|    policy_loss        | -5.94        |\n",
      "|    reward             | -0.016471269 |\n",
      "|    std                | 4.39e+08     |\n",
      "|    value_loss         | 0.000138     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 86500      |\n",
      "|    time_elapsed       | 4161       |\n",
      "|    total_timesteps    | 432500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -619       |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86499      |\n",
      "|    policy_loss        | -0.955     |\n",
      "|    reward             | 0.05313325 |\n",
      "|    std                | 4.54e+08   |\n",
      "|    value_loss         | 5.04e-06   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 86600       |\n",
      "|    time_elapsed       | 4165        |\n",
      "|    total_timesteps    | 433000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -620        |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86599       |\n",
      "|    policy_loss        | -5.98       |\n",
      "|    reward             | 0.071884364 |\n",
      "|    std                | 4.68e+08    |\n",
      "|    value_loss         | 0.00122     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 86700       |\n",
      "|    time_elapsed       | 4170        |\n",
      "|    total_timesteps    | 433500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -620        |\n",
      "|    explained_variance | 0.222       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86699       |\n",
      "|    policy_loss        | -4.45       |\n",
      "|    reward             | -0.06052086 |\n",
      "|    std                | 4.8e+08     |\n",
      "|    value_loss         | 0.000222    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 86800       |\n",
      "|    time_elapsed       | 4175        |\n",
      "|    total_timesteps    | 434000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -621        |\n",
      "|    explained_variance | 0.513       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86799       |\n",
      "|    policy_loss        | -0.129      |\n",
      "|    reward             | 0.013990349 |\n",
      "|    std                | 4.9e+08     |\n",
      "|    value_loss         | 3.32e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 86900        |\n",
      "|    time_elapsed       | 4179         |\n",
      "|    total_timesteps    | 434500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -622         |\n",
      "|    explained_variance | 0.128        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 86899        |\n",
      "|    policy_loss        | 12.8         |\n",
      "|    reward             | -0.032951504 |\n",
      "|    std                | 5e+08        |\n",
      "|    value_loss         | 0.000612     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 87000      |\n",
      "|    time_elapsed       | 4184       |\n",
      "|    total_timesteps    | 435000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -622       |\n",
      "|    explained_variance | 0.749      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86999      |\n",
      "|    policy_loss        | -8.58      |\n",
      "|    reward             | 0.02308824 |\n",
      "|    std                | 5.14e+08   |\n",
      "|    value_loss         | 0.000425   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 4189         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -623         |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | -12.4        |\n",
      "|    reward             | -0.016700463 |\n",
      "|    std                | 5.29e+08     |\n",
      "|    value_loss         | 0.000625     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 4194        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -624        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | -4.33       |\n",
      "|    reward             | 0.008632478 |\n",
      "|    std                | 5.44e+08    |\n",
      "|    value_loss         | 0.000684    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 87300       |\n",
      "|    time_elapsed       | 4199        |\n",
      "|    total_timesteps    | 436500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -625        |\n",
      "|    explained_variance | 0.641       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87299       |\n",
      "|    policy_loss        | -47.3       |\n",
      "|    reward             | -0.08303182 |\n",
      "|    std                | 5.56e+08    |\n",
      "|    value_loss         | 0.0109      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 87400        |\n",
      "|    time_elapsed       | 4203         |\n",
      "|    total_timesteps    | 437000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -625         |\n",
      "|    explained_variance | -5.13        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87399        |\n",
      "|    policy_loss        | 13.4         |\n",
      "|    reward             | 0.0047794185 |\n",
      "|    std                | 5.63e+08     |\n",
      "|    value_loss         | 0.000661     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 87500      |\n",
      "|    time_elapsed       | 4208       |\n",
      "|    total_timesteps    | 437500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -626       |\n",
      "|    explained_variance | 0.79       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87499      |\n",
      "|    policy_loss        | 17.1       |\n",
      "|    reward             | 0.08348847 |\n",
      "|    std                | 5.75e+08   |\n",
      "|    value_loss         | 0.00089    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 87600        |\n",
      "|    time_elapsed       | 4213         |\n",
      "|    total_timesteps    | 438000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -626         |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87599        |\n",
      "|    policy_loss        | -0.771       |\n",
      "|    reward             | 0.0029737537 |\n",
      "|    std                | 5.91e+08     |\n",
      "|    value_loss         | 2.7e-06      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 87700         |\n",
      "|    time_elapsed       | 4218          |\n",
      "|    total_timesteps    | 438500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -627          |\n",
      "|    explained_variance | 0.819         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 87699         |\n",
      "|    policy_loss        | 6.09          |\n",
      "|    reward             | -0.0071113054 |\n",
      "|    std                | 6.08e+08      |\n",
      "|    value_loss         | 0.000731      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 87800       |\n",
      "|    time_elapsed       | 4222        |\n",
      "|    total_timesteps    | 439000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -628        |\n",
      "|    explained_variance | 0.742       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | -10.8       |\n",
      "|    reward             | 0.025570013 |\n",
      "|    std                | 6.25e+08    |\n",
      "|    value_loss         | 0.000465    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 87900        |\n",
      "|    time_elapsed       | 4227         |\n",
      "|    total_timesteps    | 439500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -629         |\n",
      "|    explained_variance | 0.669        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87899        |\n",
      "|    policy_loss        | 14.9         |\n",
      "|    reward             | -0.074455634 |\n",
      "|    std                | 6.42e+08     |\n",
      "|    value_loss         | 0.00175      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 88000        |\n",
      "|    time_elapsed       | 4232         |\n",
      "|    total_timesteps    | 440000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -629         |\n",
      "|    explained_variance | -0.0671      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87999        |\n",
      "|    policy_loss        | 0.637        |\n",
      "|    reward             | -0.020830028 |\n",
      "|    std                | 6.54e+08     |\n",
      "|    value_loss         | 2.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 88100        |\n",
      "|    time_elapsed       | 4237         |\n",
      "|    total_timesteps    | 440500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -630         |\n",
      "|    explained_variance | 0.652        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88099        |\n",
      "|    policy_loss        | 2.35         |\n",
      "|    reward             | -0.018974707 |\n",
      "|    std                | 6.72e+08     |\n",
      "|    value_loss         | 9.59e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 88200        |\n",
      "|    time_elapsed       | 4242         |\n",
      "|    total_timesteps    | 441000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -631         |\n",
      "|    explained_variance | 0.521        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88199        |\n",
      "|    policy_loss        | 9.09         |\n",
      "|    reward             | 0.0031788654 |\n",
      "|    std                | 6.94e+08     |\n",
      "|    value_loss         | 0.000261     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 88300       |\n",
      "|    time_elapsed       | 4246        |\n",
      "|    total_timesteps    | 441500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -632        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88299       |\n",
      "|    policy_loss        | 20          |\n",
      "|    reward             | -0.12771285 |\n",
      "|    std                | 7.18e+08    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 88400       |\n",
      "|    time_elapsed       | 4251        |\n",
      "|    total_timesteps    | 442000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -633        |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88399       |\n",
      "|    policy_loss        | 7.31        |\n",
      "|    reward             | -0.08293632 |\n",
      "|    std                | 7.35e+08    |\n",
      "|    value_loss         | 0.000312    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 88500       |\n",
      "|    time_elapsed       | 4256        |\n",
      "|    total_timesteps    | 442500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -633        |\n",
      "|    explained_variance | 0.704       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88499       |\n",
      "|    policy_loss        | 77.1        |\n",
      "|    reward             | 0.052321713 |\n",
      "|    std                | 7.5e+08     |\n",
      "|    value_loss         | 0.0176      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 88600        |\n",
      "|    time_elapsed       | 4261         |\n",
      "|    total_timesteps    | 443000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -634         |\n",
      "|    explained_variance | 0.696        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88599        |\n",
      "|    policy_loss        | -2.86        |\n",
      "|    reward             | -0.019022174 |\n",
      "|    std                | 7.61e+08     |\n",
      "|    value_loss         | 7.63e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 88700         |\n",
      "|    time_elapsed       | 4266          |\n",
      "|    total_timesteps    | 443500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -634          |\n",
      "|    explained_variance | 0.749         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 88699         |\n",
      "|    policy_loss        | -6.17         |\n",
      "|    reward             | -0.0065027424 |\n",
      "|    std                | 7.8e+08       |\n",
      "|    value_loss         | 0.000503      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 88800      |\n",
      "|    time_elapsed       | 4270       |\n",
      "|    total_timesteps    | 444000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -635       |\n",
      "|    explained_variance | 0.427      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88799      |\n",
      "|    policy_loss        | -24        |\n",
      "|    reward             | 0.00559235 |\n",
      "|    std                | 8.04e+08   |\n",
      "|    value_loss         | 0.00175    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 88900        |\n",
      "|    time_elapsed       | 4275         |\n",
      "|    total_timesteps    | 444500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -636         |\n",
      "|    explained_variance | -0.147       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88899        |\n",
      "|    policy_loss        | 1.81         |\n",
      "|    reward             | 0.0005420133 |\n",
      "|    std                | 8.3e+08      |\n",
      "|    value_loss         | 0.000429     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 89000        |\n",
      "|    time_elapsed       | 4280         |\n",
      "|    total_timesteps    | 445000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -637         |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88999        |\n",
      "|    policy_loss        | -65.7        |\n",
      "|    reward             | -0.005073024 |\n",
      "|    std                | 8.53e+08     |\n",
      "|    value_loss         | 0.0111       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 89100      |\n",
      "|    time_elapsed       | 4285       |\n",
      "|    total_timesteps    | 445500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -638       |\n",
      "|    explained_variance | 0.863      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89099      |\n",
      "|    policy_loss        | -21.6      |\n",
      "|    reward             | 0.08461228 |\n",
      "|    std                | 8.67e+08   |\n",
      "|    value_loss         | 0.00634    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 89200      |\n",
      "|    time_elapsed       | 4289       |\n",
      "|    total_timesteps    | 446000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -638       |\n",
      "|    explained_variance | 0.925      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89199      |\n",
      "|    policy_loss        | 2.71       |\n",
      "|    reward             | 0.02513412 |\n",
      "|    std                | 8.85e+08   |\n",
      "|    value_loss         | 6.01e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 89300      |\n",
      "|    time_elapsed       | 4294       |\n",
      "|    total_timesteps    | 446500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -639       |\n",
      "|    explained_variance | 0.874      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89299      |\n",
      "|    policy_loss        | -22.3      |\n",
      "|    reward             | 0.00916856 |\n",
      "|    std                | 9.1e+08    |\n",
      "|    value_loss         | 0.0017     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 89400        |\n",
      "|    time_elapsed       | 4299         |\n",
      "|    total_timesteps    | 447000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -640         |\n",
      "|    explained_variance | -0.396       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 89399        |\n",
      "|    policy_loss        | -18.6        |\n",
      "|    reward             | 0.0062362286 |\n",
      "|    std                | 9.4e+08      |\n",
      "|    value_loss         | 0.00109      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 89500      |\n",
      "|    time_elapsed       | 4304       |\n",
      "|    total_timesteps    | 447500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -641       |\n",
      "|    explained_variance | 0.627      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89499      |\n",
      "|    policy_loss        | 45.8       |\n",
      "|    reward             | 0.09202835 |\n",
      "|    std                | 9.71e+08   |\n",
      "|    value_loss         | 0.00569    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 89600      |\n",
      "|    time_elapsed       | 4308       |\n",
      "|    total_timesteps    | 448000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -641       |\n",
      "|    explained_variance | 0.727      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89599      |\n",
      "|    policy_loss        | -24.1      |\n",
      "|    reward             | 0.11955151 |\n",
      "|    std                | 9.94e+08   |\n",
      "|    value_loss         | 0.00557    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 89700       |\n",
      "|    time_elapsed       | 4313        |\n",
      "|    total_timesteps    | 448500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -642        |\n",
      "|    explained_variance | -1.74       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89699       |\n",
      "|    policy_loss        | 8.21        |\n",
      "|    reward             | 0.010544607 |\n",
      "|    std                | 1.01e+09    |\n",
      "|    value_loss         | 0.000178    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 89800        |\n",
      "|    time_elapsed       | 4318         |\n",
      "|    total_timesteps    | 449000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -643         |\n",
      "|    explained_variance | -0.826       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 89799        |\n",
      "|    policy_loss        | 3.86         |\n",
      "|    reward             | 0.0055438275 |\n",
      "|    std                | 1.04e+09     |\n",
      "|    value_loss         | 0.000297     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 89900         |\n",
      "|    time_elapsed       | 4323          |\n",
      "|    total_timesteps    | 449500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -644          |\n",
      "|    explained_variance | 0.423         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 89899         |\n",
      "|    policy_loss        | -53           |\n",
      "|    reward             | -0.0022789848 |\n",
      "|    std                | 1.07e+09      |\n",
      "|    value_loss         | 0.00782       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 90000      |\n",
      "|    time_elapsed       | 4327       |\n",
      "|    total_timesteps    | 450000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -644       |\n",
      "|    explained_variance | 0.886      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89999      |\n",
      "|    policy_loss        | -4.8       |\n",
      "|    reward             | 0.04316106 |\n",
      "|    std                | 1.1e+09    |\n",
      "|    value_loss         | 0.00012    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 90100      |\n",
      "|    time_elapsed       | 4332       |\n",
      "|    total_timesteps    | 450500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -645       |\n",
      "|    explained_variance | 0.488      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90099      |\n",
      "|    policy_loss        | -8.99      |\n",
      "|    reward             | 0.10515958 |\n",
      "|    std                | 1.14e+09   |\n",
      "|    value_loss         | 0.000386   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 90200       |\n",
      "|    time_elapsed       | 4337        |\n",
      "|    total_timesteps    | 451000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -646        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90199       |\n",
      "|    policy_loss        | 17.3        |\n",
      "|    reward             | -0.03844529 |\n",
      "|    std                | 1.16e+09    |\n",
      "|    value_loss         | 0.00135     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 4342        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -646        |\n",
      "|    explained_variance | 0.0364      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | 2.78        |\n",
      "|    reward             | 0.007058658 |\n",
      "|    std                | 1.18e+09    |\n",
      "|    value_loss         | 5.76e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 90400       |\n",
      "|    time_elapsed       | 4346        |\n",
      "|    total_timesteps    | 452000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -647        |\n",
      "|    explained_variance | 0.696       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90399       |\n",
      "|    policy_loss        | -41         |\n",
      "|    reward             | -0.07642503 |\n",
      "|    std                | 1.21e+09    |\n",
      "|    value_loss         | 0.00603     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 90500        |\n",
      "|    time_elapsed       | 4351         |\n",
      "|    total_timesteps    | 452500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -648         |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90499        |\n",
      "|    policy_loss        | 0.0183       |\n",
      "|    reward             | -0.031383157 |\n",
      "|    std                | 1.24e+09     |\n",
      "|    value_loss         | 3.91e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 90600       |\n",
      "|    time_elapsed       | 4356        |\n",
      "|    total_timesteps    | 453000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -649        |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90599       |\n",
      "|    policy_loss        | 24.8        |\n",
      "|    reward             | -0.02615037 |\n",
      "|    std                | 1.28e+09    |\n",
      "|    value_loss         | 0.0016      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 90700       |\n",
      "|    time_elapsed       | 4361        |\n",
      "|    total_timesteps    | 453500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -649        |\n",
      "|    explained_variance | 0.768       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90699       |\n",
      "|    policy_loss        | 45.8        |\n",
      "|    reward             | 0.034710485 |\n",
      "|    std                | 1.31e+09    |\n",
      "|    value_loss         | 0.00537     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 90800       |\n",
      "|    time_elapsed       | 4365        |\n",
      "|    total_timesteps    | 454000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -650        |\n",
      "|    explained_variance | 0.79        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90799       |\n",
      "|    policy_loss        | 40.5        |\n",
      "|    reward             | 0.035189927 |\n",
      "|    std                | 1.34e+09    |\n",
      "|    value_loss         | 0.00667     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 90900        |\n",
      "|    time_elapsed       | 4370         |\n",
      "|    total_timesteps    | 454500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -650         |\n",
      "|    explained_variance | 0.383        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90899        |\n",
      "|    policy_loss        | 13.3         |\n",
      "|    reward             | 0.0059980173 |\n",
      "|    std                | 1.36e+09     |\n",
      "|    value_loss         | 0.000465     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 91000       |\n",
      "|    time_elapsed       | 4375        |\n",
      "|    total_timesteps    | 455000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -651        |\n",
      "|    explained_variance | 0.352       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90999       |\n",
      "|    policy_loss        | -12.5       |\n",
      "|    reward             | -0.06102286 |\n",
      "|    std                | 1.39e+09    |\n",
      "|    value_loss         | 0.000501    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 91100      |\n",
      "|    time_elapsed       | 4380       |\n",
      "|    total_timesteps    | 455500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -652       |\n",
      "|    explained_variance | 0.674      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91099      |\n",
      "|    policy_loss        | -3.08      |\n",
      "|    reward             | 0.09139964 |\n",
      "|    std                | 1.43e+09   |\n",
      "|    value_loss         | 0.000173   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 91200        |\n",
      "|    time_elapsed       | 4384         |\n",
      "|    total_timesteps    | 456000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -653         |\n",
      "|    explained_variance | 0.718        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 91199        |\n",
      "|    policy_loss        | 19.6         |\n",
      "|    reward             | 0.0016497405 |\n",
      "|    std                | 1.48e+09     |\n",
      "|    value_loss         | 0.00558      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 91300       |\n",
      "|    time_elapsed       | 4389        |\n",
      "|    total_timesteps    | 456500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -654        |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91299       |\n",
      "|    policy_loss        | 58.1        |\n",
      "|    reward             | -0.10515479 |\n",
      "|    std                | 1.52e+09    |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 91400       |\n",
      "|    time_elapsed       | 4395        |\n",
      "|    total_timesteps    | 457000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -654        |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91399       |\n",
      "|    policy_loss        | -6.96       |\n",
      "|    reward             | -0.08527349 |\n",
      "|    std                | 1.54e+09    |\n",
      "|    value_loss         | 0.00911     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 91500        |\n",
      "|    time_elapsed       | 4400         |\n",
      "|    total_timesteps    | 457500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -655         |\n",
      "|    explained_variance | -0.129       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 91499        |\n",
      "|    policy_loss        | -5.48        |\n",
      "|    reward             | -0.003406359 |\n",
      "|    std                | 1.57e+09     |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 91600       |\n",
      "|    time_elapsed       | 4404        |\n",
      "|    total_timesteps    | 458000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -655        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91599       |\n",
      "|    policy_loss        | 7.99        |\n",
      "|    reward             | 0.013487996 |\n",
      "|    std                | 1.61e+09    |\n",
      "|    value_loss         | 0.000255    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 4409         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -656         |\n",
      "|    explained_variance | -3.87        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | -14.5        |\n",
      "|    reward             | -0.044566873 |\n",
      "|    std                | 1.66e+09     |\n",
      "|    value_loss         | 0.000831     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 91800        |\n",
      "|    time_elapsed       | 4414         |\n",
      "|    total_timesteps    | 459000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -657         |\n",
      "|    explained_variance | 0.713        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 91799        |\n",
      "|    policy_loss        | 2.64         |\n",
      "|    reward             | -0.003632245 |\n",
      "|    std                | 1.71e+09     |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 91900       |\n",
      "|    time_elapsed       | 4419        |\n",
      "|    total_timesteps    | 459500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -658        |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91899       |\n",
      "|    policy_loss        | 31.7        |\n",
      "|    reward             | 0.058381315 |\n",
      "|    std                | 1.75e+09    |\n",
      "|    value_loss         | 0.00373     |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16127201.83\n",
      "total_reward: 6127201.83\n",
      "total_cost: 558065.55\n",
      "total_trades: 82256\n",
      "Sharpe: 0.436\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 92000         |\n",
      "|    time_elapsed       | 4424          |\n",
      "|    total_timesteps    | 460000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -658          |\n",
      "|    explained_variance | -39.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 91999         |\n",
      "|    policy_loss        | 4.55          |\n",
      "|    reward             | -0.0039125076 |\n",
      "|    std                | 1.78e+09      |\n",
      "|    value_loss         | 0.00154       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 92100       |\n",
      "|    time_elapsed       | 4429        |\n",
      "|    total_timesteps    | 460500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -659        |\n",
      "|    explained_variance | 0.099       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | -10.4       |\n",
      "|    reward             | 0.029562728 |\n",
      "|    std                | 1.82e+09    |\n",
      "|    value_loss         | 0.000457    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 92200        |\n",
      "|    time_elapsed       | 4433         |\n",
      "|    total_timesteps    | 461000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -660         |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92199        |\n",
      "|    policy_loss        | 12.9         |\n",
      "|    reward             | 0.0015184404 |\n",
      "|    std                | 1.86e+09     |\n",
      "|    value_loss         | 0.000651     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 92300      |\n",
      "|    time_elapsed       | 4438       |\n",
      "|    total_timesteps    | 461500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -661       |\n",
      "|    explained_variance | 0.691      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 92299      |\n",
      "|    policy_loss        | -4.55      |\n",
      "|    reward             | 0.07367516 |\n",
      "|    std                | 1.92e+09   |\n",
      "|    value_loss         | 0.000112   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 92400        |\n",
      "|    time_elapsed       | 4443         |\n",
      "|    total_timesteps    | 462000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -661         |\n",
      "|    explained_variance | -0.55        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92399        |\n",
      "|    policy_loss        | -24.3        |\n",
      "|    reward             | -0.035117865 |\n",
      "|    std                | 1.98e+09     |\n",
      "|    value_loss         | 0.00148      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 92500      |\n",
      "|    time_elapsed       | 4448       |\n",
      "|    total_timesteps    | 462500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -662       |\n",
      "|    explained_variance | 0.869      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 92499      |\n",
      "|    policy_loss        | -151       |\n",
      "|    reward             | 0.19647716 |\n",
      "|    std                | 2.03e+09   |\n",
      "|    value_loss         | 0.0649     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 92600       |\n",
      "|    time_elapsed       | 4452        |\n",
      "|    total_timesteps    | 463000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -663        |\n",
      "|    explained_variance | 0.339       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92599       |\n",
      "|    policy_loss        | -3.65       |\n",
      "|    reward             | 0.020071594 |\n",
      "|    std                | 2.06e+09    |\n",
      "|    value_loss         | 0.000181    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 92700        |\n",
      "|    time_elapsed       | 4457         |\n",
      "|    total_timesteps    | 463500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -663         |\n",
      "|    explained_variance | 0.599        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92699        |\n",
      "|    policy_loss        | -2.86        |\n",
      "|    reward             | 0.0066070342 |\n",
      "|    std                | 2.11e+09     |\n",
      "|    value_loss         | 6.09e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 92800      |\n",
      "|    time_elapsed       | 4462       |\n",
      "|    total_timesteps    | 464000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -664       |\n",
      "|    explained_variance | 0.832      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 92799      |\n",
      "|    policy_loss        | 12.5       |\n",
      "|    reward             | 0.04649505 |\n",
      "|    std                | 2.17e+09   |\n",
      "|    value_loss         | 0.000801   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 92900       |\n",
      "|    time_elapsed       | 4467        |\n",
      "|    total_timesteps    | 464500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -665        |\n",
      "|    explained_variance | 0.796       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92899       |\n",
      "|    policy_loss        | 15.1        |\n",
      "|    reward             | 0.042616226 |\n",
      "|    std                | 2.23e+09    |\n",
      "|    value_loss         | 0.000604    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 93000        |\n",
      "|    time_elapsed       | 4471         |\n",
      "|    total_timesteps    | 465000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -666         |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92999        |\n",
      "|    policy_loss        | -13.4        |\n",
      "|    reward             | -0.061535332 |\n",
      "|    std                | 2.29e+09     |\n",
      "|    value_loss         | 0.000535     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 93100       |\n",
      "|    time_elapsed       | 4476        |\n",
      "|    total_timesteps    | 465500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -666        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93099       |\n",
      "|    policy_loss        | 11.6        |\n",
      "|    reward             | 0.106696896 |\n",
      "|    std                | 2.34e+09    |\n",
      "|    value_loss         | 0.000462    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 93200        |\n",
      "|    time_elapsed       | 4481         |\n",
      "|    total_timesteps    | 466000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -667         |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93199        |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | 0.0035723003 |\n",
      "|    std                | 2.37e+09     |\n",
      "|    value_loss         | 1.17e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 93300        |\n",
      "|    time_elapsed       | 4486         |\n",
      "|    total_timesteps    | 466500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -667         |\n",
      "|    explained_variance | 0.775        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93299        |\n",
      "|    policy_loss        | -12.1        |\n",
      "|    reward             | 0.0009525363 |\n",
      "|    std                | 2.43e+09     |\n",
      "|    value_loss         | 0.00076      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 4490        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -668        |\n",
      "|    explained_variance | 0.52        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | -6.31       |\n",
      "|    reward             | 0.023003891 |\n",
      "|    std                | 2.5e+09     |\n",
      "|    value_loss         | 0.00035     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 93500        |\n",
      "|    time_elapsed       | 4495         |\n",
      "|    total_timesteps    | 467500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -669         |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93499        |\n",
      "|    policy_loss        | -11.6        |\n",
      "|    reward             | -0.022629708 |\n",
      "|    std                | 2.59e+09     |\n",
      "|    value_loss         | 0.000407     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 93600        |\n",
      "|    time_elapsed       | 4500         |\n",
      "|    total_timesteps    | 468000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -670         |\n",
      "|    explained_variance | -0.542       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93599        |\n",
      "|    policy_loss        | 46           |\n",
      "|    reward             | 0.0022717472 |\n",
      "|    std                | 2.67e+09     |\n",
      "|    value_loss         | 0.00677      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 93700     |\n",
      "|    time_elapsed       | 4505      |\n",
      "|    total_timesteps    | 468500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -671      |\n",
      "|    explained_variance | -1.24     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93699     |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.2248428 |\n",
      "|    std                | 2.72e+09  |\n",
      "|    value_loss         | 0.00698   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 93800       |\n",
      "|    time_elapsed       | 4509        |\n",
      "|    total_timesteps    | 469000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -671        |\n",
      "|    explained_variance | -4.75       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93799       |\n",
      "|    policy_loss        | -3.83       |\n",
      "|    reward             | 0.026142307 |\n",
      "|    std                | 2.77e+09    |\n",
      "|    value_loss         | 0.000154    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 93900       |\n",
      "|    time_elapsed       | 4514        |\n",
      "|    total_timesteps    | 469500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -672        |\n",
      "|    explained_variance | 0.538       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93899       |\n",
      "|    policy_loss        | 13.2        |\n",
      "|    reward             | 0.015148513 |\n",
      "|    std                | 2.84e+09    |\n",
      "|    value_loss         | 0.00075     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 94000        |\n",
      "|    time_elapsed       | 4519         |\n",
      "|    total_timesteps    | 470000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -673         |\n",
      "|    explained_variance | 0.844        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93999        |\n",
      "|    policy_loss        | 0.354        |\n",
      "|    reward             | -0.019034049 |\n",
      "|    std                | 2.92e+09     |\n",
      "|    value_loss         | 0.000865     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 94100      |\n",
      "|    time_elapsed       | 4524       |\n",
      "|    total_timesteps    | 470500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -673       |\n",
      "|    explained_variance | 0.854      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94099      |\n",
      "|    policy_loss        | -35.3      |\n",
      "|    reward             | 0.05042505 |\n",
      "|    std                | 3.01e+09   |\n",
      "|    value_loss         | 0.00303    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 94200      |\n",
      "|    time_elapsed       | 4528       |\n",
      "|    total_timesteps    | 471000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -674       |\n",
      "|    explained_variance | 0.617      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94199      |\n",
      "|    policy_loss        | 95.3       |\n",
      "|    reward             | 0.14462087 |\n",
      "|    std                | 3.09e+09   |\n",
      "|    value_loss         | 0.0241     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 94300       |\n",
      "|    time_elapsed       | 4533        |\n",
      "|    total_timesteps    | 471500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -675        |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94299       |\n",
      "|    policy_loss        | 127         |\n",
      "|    reward             | -0.08380487 |\n",
      "|    std                | 3.14e+09    |\n",
      "|    value_loss         | 0.0524      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 94400        |\n",
      "|    time_elapsed       | 4538         |\n",
      "|    total_timesteps    | 472000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -675         |\n",
      "|    explained_variance | 0.63         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94399        |\n",
      "|    policy_loss        | 2.89         |\n",
      "|    reward             | -0.012481032 |\n",
      "|    std                | 3.2e+09      |\n",
      "|    value_loss         | 8.09e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 94500        |\n",
      "|    time_elapsed       | 4543         |\n",
      "|    total_timesteps    | 472500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -676         |\n",
      "|    explained_variance | 0.74         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94499        |\n",
      "|    policy_loss        | -0.955       |\n",
      "|    reward             | -0.012286072 |\n",
      "|    std                | 3.3e+09      |\n",
      "|    value_loss         | 8.13e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 94600       |\n",
      "|    time_elapsed       | 4548        |\n",
      "|    total_timesteps    | 473000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -677        |\n",
      "|    explained_variance | 0.785       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | 5.37        |\n",
      "|    reward             | 0.060691908 |\n",
      "|    std                | 3.41e+09    |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 94700        |\n",
      "|    time_elapsed       | 4553         |\n",
      "|    total_timesteps    | 473500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -678         |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94699        |\n",
      "|    policy_loss        | 37.6         |\n",
      "|    reward             | -0.010244106 |\n",
      "|    std                | 3.53e+09     |\n",
      "|    value_loss         | 0.0037       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 94800       |\n",
      "|    time_elapsed       | 4558        |\n",
      "|    total_timesteps    | 474000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -679        |\n",
      "|    explained_variance | 0.608       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94799       |\n",
      "|    policy_loss        | 52.5        |\n",
      "|    reward             | 0.107549116 |\n",
      "|    std                | 3.63e+09    |\n",
      "|    value_loss         | 0.00687     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 94900        |\n",
      "|    time_elapsed       | 4563         |\n",
      "|    total_timesteps    | 474500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -679         |\n",
      "|    explained_variance | -0.307       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94899        |\n",
      "|    policy_loss        | 8.23         |\n",
      "|    reward             | 0.0031723368 |\n",
      "|    std                | 3.69e+09     |\n",
      "|    value_loss         | 0.000216     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 95000       |\n",
      "|    time_elapsed       | 4568        |\n",
      "|    total_timesteps    | 475000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -680        |\n",
      "|    explained_variance | 0.699       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94999       |\n",
      "|    policy_loss        | 3.47        |\n",
      "|    reward             | 0.020898113 |\n",
      "|    std                | 3.77e+09    |\n",
      "|    value_loss         | 6.13e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 95100       |\n",
      "|    time_elapsed       | 4572        |\n",
      "|    total_timesteps    | 475500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -681        |\n",
      "|    explained_variance | 0.779       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95099       |\n",
      "|    policy_loss        | 5.03        |\n",
      "|    reward             | 0.021178594 |\n",
      "|    std                | 3.88e+09    |\n",
      "|    value_loss         | 0.000249    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 95200        |\n",
      "|    time_elapsed       | 4577         |\n",
      "|    total_timesteps    | 476000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -682         |\n",
      "|    explained_variance | 0.678        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 95199        |\n",
      "|    policy_loss        | 11.4         |\n",
      "|    reward             | -0.030780267 |\n",
      "|    std                | 4.02e+09     |\n",
      "|    value_loss         | 0.000374     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 95300       |\n",
      "|    time_elapsed       | 4582        |\n",
      "|    total_timesteps    | 476500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -683        |\n",
      "|    explained_variance | 0.506       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95299       |\n",
      "|    policy_loss        | -45.8       |\n",
      "|    reward             | 0.017868962 |\n",
      "|    std                | 4.13e+09    |\n",
      "|    value_loss         | 0.00579     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 95400       |\n",
      "|    time_elapsed       | 4587        |\n",
      "|    total_timesteps    | 477000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -683        |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95399       |\n",
      "|    policy_loss        | -17.2       |\n",
      "|    reward             | -0.02961827 |\n",
      "|    std                | 4.23e+09    |\n",
      "|    value_loss         | 0.0011      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 95500        |\n",
      "|    time_elapsed       | 4592         |\n",
      "|    total_timesteps    | 477500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -684         |\n",
      "|    explained_variance | 0.763        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 95499        |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | -0.010309405 |\n",
      "|    std                | 4.28e+09     |\n",
      "|    value_loss         | 9.37e-06     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 95600      |\n",
      "|    time_elapsed       | 4596       |\n",
      "|    total_timesteps    | 478000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -684       |\n",
      "|    explained_variance | 0.362      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95599      |\n",
      "|    policy_loss        | -8.14      |\n",
      "|    reward             | 0.08799503 |\n",
      "|    std                | 4.37e+09   |\n",
      "|    value_loss         | 0.000588   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 95700     |\n",
      "|    time_elapsed       | 4601      |\n",
      "|    total_timesteps    | 478500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -685      |\n",
      "|    explained_variance | 0.0861    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 95699     |\n",
      "|    policy_loss        | 8.13      |\n",
      "|    reward             | -0.027911 |\n",
      "|    std                | 4.49e+09  |\n",
      "|    value_loss         | 0.000225  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 95800       |\n",
      "|    time_elapsed       | 4606        |\n",
      "|    total_timesteps    | 479000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -686        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95799       |\n",
      "|    policy_loss        | 15.1        |\n",
      "|    reward             | 0.006906149 |\n",
      "|    std                | 4.66e+09    |\n",
      "|    value_loss         | 0.000514    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 95900      |\n",
      "|    time_elapsed       | 4611       |\n",
      "|    total_timesteps    | 479500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -687       |\n",
      "|    explained_variance | 0.463      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95899      |\n",
      "|    policy_loss        | 33         |\n",
      "|    reward             | 0.09261133 |\n",
      "|    std                | 4.8e+09    |\n",
      "|    value_loss         | 0.00258    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 96000      |\n",
      "|    time_elapsed       | 4616       |\n",
      "|    total_timesteps    | 480000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -688       |\n",
      "|    explained_variance | 0.936      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95999      |\n",
      "|    policy_loss        | 45.4       |\n",
      "|    reward             | 0.11828641 |\n",
      "|    std                | 4.91e+09   |\n",
      "|    value_loss         | 0.00631    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 96100       |\n",
      "|    time_elapsed       | 4620        |\n",
      "|    total_timesteps    | 480500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -688        |\n",
      "|    explained_variance | -1.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 96099       |\n",
      "|    policy_loss        | -8.12       |\n",
      "|    reward             | 0.021555139 |\n",
      "|    std                | 5e+09       |\n",
      "|    value_loss         | 0.000196    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 96200        |\n",
      "|    time_elapsed       | 4625         |\n",
      "|    total_timesteps    | 481000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -689         |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96199        |\n",
      "|    policy_loss        | 4.31         |\n",
      "|    reward             | 0.0023814428 |\n",
      "|    std                | 5.12e+09     |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 96300        |\n",
      "|    time_elapsed       | 4630         |\n",
      "|    total_timesteps    | 481500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -690         |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96299        |\n",
      "|    policy_loss        | -7.13        |\n",
      "|    reward             | -0.029335726 |\n",
      "|    std                | 5.27e+09     |\n",
      "|    value_loss         | 0.000225     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 96400        |\n",
      "|    time_elapsed       | 4635         |\n",
      "|    total_timesteps    | 482000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -691         |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96399        |\n",
      "|    policy_loss        | 8.23         |\n",
      "|    reward             | -0.113535024 |\n",
      "|    std                | 5.44e+09     |\n",
      "|    value_loss         | 0.000271     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 96500       |\n",
      "|    time_elapsed       | 4639        |\n",
      "|    total_timesteps    | 482500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -691        |\n",
      "|    explained_variance | 0.519       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 96499       |\n",
      "|    policy_loss        | 48.5        |\n",
      "|    reward             | 0.009821531 |\n",
      "|    std                | 5.59e+09    |\n",
      "|    value_loss         | 0.00632     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 96600        |\n",
      "|    time_elapsed       | 4644         |\n",
      "|    total_timesteps    | 483000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -692         |\n",
      "|    explained_variance | 0.513        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96599        |\n",
      "|    policy_loss        | 122          |\n",
      "|    reward             | 0.0031802803 |\n",
      "|    std                | 5.68e+09     |\n",
      "|    value_loss         | 0.0331       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 96700        |\n",
      "|    time_elapsed       | 4649         |\n",
      "|    total_timesteps    | 483500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -692         |\n",
      "|    explained_variance | 0.593        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96699        |\n",
      "|    policy_loss        | 25.9         |\n",
      "|    reward             | -0.022927769 |\n",
      "|    std                | 5.79e+09     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 96800      |\n",
      "|    time_elapsed       | 4654       |\n",
      "|    total_timesteps    | 484000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -693       |\n",
      "|    explained_variance | 0.52       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96799      |\n",
      "|    policy_loss        | 15.1       |\n",
      "|    reward             | 0.04340686 |\n",
      "|    std                | 5.93e+09   |\n",
      "|    value_loss         | 0.00128    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 96900        |\n",
      "|    time_elapsed       | 4658         |\n",
      "|    total_timesteps    | 484500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -694         |\n",
      "|    explained_variance | 0.623        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96899        |\n",
      "|    policy_loss        | 5.43         |\n",
      "|    reward             | -0.041689523 |\n",
      "|    std                | 6.12e+09     |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 97000       |\n",
      "|    time_elapsed       | 4663        |\n",
      "|    total_timesteps    | 485000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -695        |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 96999       |\n",
      "|    policy_loss        | 23          |\n",
      "|    reward             | -0.01933743 |\n",
      "|    std                | 6.3e+09     |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 97100      |\n",
      "|    time_elapsed       | 4668       |\n",
      "|    total_timesteps    | 485500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -696       |\n",
      "|    explained_variance | 0.857      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97099      |\n",
      "|    policy_loss        | -6.6       |\n",
      "|    reward             | 0.13991527 |\n",
      "|    std                | 6.45e+09   |\n",
      "|    value_loss         | 0.000731   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 97200       |\n",
      "|    time_elapsed       | 4673        |\n",
      "|    total_timesteps    | 486000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -696        |\n",
      "|    explained_variance | 0.703       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | -57.3       |\n",
      "|    reward             | -0.07610882 |\n",
      "|    std                | 6.57e+09    |\n",
      "|    value_loss         | 0.0222      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 97300        |\n",
      "|    time_elapsed       | 4677         |\n",
      "|    total_timesteps    | 486500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -697         |\n",
      "|    explained_variance | 0.678        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 97299        |\n",
      "|    policy_loss        | -6.56        |\n",
      "|    reward             | -0.006569587 |\n",
      "|    std                | 6.7e+09      |\n",
      "|    value_loss         | 0.000298     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 97400       |\n",
      "|    time_elapsed       | 4682        |\n",
      "|    total_timesteps    | 487000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -697        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97399       |\n",
      "|    policy_loss        | 37.4        |\n",
      "|    reward             | 0.017242985 |\n",
      "|    std                | 6.88e+09    |\n",
      "|    value_loss         | 0.00304     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 97500        |\n",
      "|    time_elapsed       | 4687         |\n",
      "|    total_timesteps    | 487500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -698         |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 97499        |\n",
      "|    policy_loss        | -5.52        |\n",
      "|    reward             | -0.002089438 |\n",
      "|    std                | 7.11e+09     |\n",
      "|    value_loss         | 0.000215     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 97600      |\n",
      "|    time_elapsed       | 4692       |\n",
      "|    total_timesteps    | 488000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -699       |\n",
      "|    explained_variance | 0.734      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97599      |\n",
      "|    policy_loss        | 8.42       |\n",
      "|    reward             | 0.17792952 |\n",
      "|    std                | 7.33e+09   |\n",
      "|    value_loss         | 0.000545   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 97700      |\n",
      "|    time_elapsed       | 4697       |\n",
      "|    total_timesteps    | 488500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -700       |\n",
      "|    explained_variance | 0.626      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97699      |\n",
      "|    policy_loss        | -12.5      |\n",
      "|    reward             | 0.17208736 |\n",
      "|    std                | 7.52e+09   |\n",
      "|    value_loss         | 0.0147     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17153838.60\n",
      "total_reward: 7153838.60\n",
      "total_cost: 559639.11\n",
      "total_trades: 82493\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 97800       |\n",
      "|    time_elapsed       | 4701        |\n",
      "|    total_timesteps    | 489000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -700        |\n",
      "|    explained_variance | -6.45       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97799       |\n",
      "|    policy_loss        | -14.4       |\n",
      "|    reward             | 0.017552571 |\n",
      "|    std                | 7.62e+09    |\n",
      "|    value_loss         | 0.000652    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 97900       |\n",
      "|    time_elapsed       | 4706        |\n",
      "|    total_timesteps    | 489500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -701        |\n",
      "|    explained_variance | 0.286       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97899       |\n",
      "|    policy_loss        | 34.4        |\n",
      "|    reward             | 0.011342812 |\n",
      "|    std                | 7.79e+09    |\n",
      "|    value_loss         | 0.00252     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 98000       |\n",
      "|    time_elapsed       | 4711        |\n",
      "|    total_timesteps    | 490000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -702        |\n",
      "|    explained_variance | -1.68       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97999       |\n",
      "|    policy_loss        | 21.8        |\n",
      "|    reward             | 0.002641855 |\n",
      "|    std                | 7.99e+09    |\n",
      "|    value_loss         | 0.00258     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 98100       |\n",
      "|    time_elapsed       | 4716        |\n",
      "|    total_timesteps    | 490500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -703        |\n",
      "|    explained_variance | 0.612       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98099       |\n",
      "|    policy_loss        | -6.1        |\n",
      "|    reward             | 0.077951215 |\n",
      "|    std                | 8.24e+09    |\n",
      "|    value_loss         | 0.000465    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 98200        |\n",
      "|    time_elapsed       | 4720         |\n",
      "|    total_timesteps    | 491000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -704         |\n",
      "|    explained_variance | 0.492        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 98199        |\n",
      "|    policy_loss        | -9.18        |\n",
      "|    reward             | -0.040081106 |\n",
      "|    std                | 8.51e+09     |\n",
      "|    value_loss         | 0.000365     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 98300       |\n",
      "|    time_elapsed       | 4725        |\n",
      "|    total_timesteps    | 491500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -704        |\n",
      "|    explained_variance | 0.734       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98299       |\n",
      "|    policy_loss        | 65.8        |\n",
      "|    reward             | -0.10978184 |\n",
      "|    std                | 8.67e+09    |\n",
      "|    value_loss         | 0.0169      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 98400       |\n",
      "|    time_elapsed       | 4730        |\n",
      "|    total_timesteps    | 492000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -705        |\n",
      "|    explained_variance | 0.317       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98399       |\n",
      "|    policy_loss        | -9.04       |\n",
      "|    reward             | 0.009064811 |\n",
      "|    std                | 8.8e+09     |\n",
      "|    value_loss         | 0.000205    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 98500        |\n",
      "|    time_elapsed       | 4735         |\n",
      "|    total_timesteps    | 492500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -705         |\n",
      "|    explained_variance | -0.966       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 98499        |\n",
      "|    policy_loss        | -36.8        |\n",
      "|    reward             | -0.039902646 |\n",
      "|    std                | 9e+09        |\n",
      "|    value_loss         | 0.00329      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 98600        |\n",
      "|    time_elapsed       | 4740         |\n",
      "|    total_timesteps    | 493000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -706         |\n",
      "|    explained_variance | 0.858        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 98599        |\n",
      "|    policy_loss        | -7.88        |\n",
      "|    reward             | -0.022292705 |\n",
      "|    std                | 9.26e+09     |\n",
      "|    value_loss         | 0.000259     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 98700      |\n",
      "|    time_elapsed       | 4744       |\n",
      "|    total_timesteps    | 493500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -707       |\n",
      "|    explained_variance | 0.899      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98699      |\n",
      "|    policy_loss        | -6.96      |\n",
      "|    reward             | 0.04298449 |\n",
      "|    std                | 9.55e+09   |\n",
      "|    value_loss         | 0.000418   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 98800       |\n",
      "|    time_elapsed       | 4749        |\n",
      "|    total_timesteps    | 494000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -708        |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98799       |\n",
      "|    policy_loss        | 6.4         |\n",
      "|    reward             | 0.012949015 |\n",
      "|    std                | 9.81e+09    |\n",
      "|    value_loss         | 0.000437    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 4754       |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -708       |\n",
      "|    explained_variance | 0.805      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98899      |\n",
      "|    policy_loss        | 5.82       |\n",
      "|    reward             | 0.14800481 |\n",
      "|    std                | 1e+10      |\n",
      "|    value_loss         | 0.00481    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 99000      |\n",
      "|    time_elapsed       | 4759       |\n",
      "|    total_timesteps    | 495000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -709       |\n",
      "|    explained_variance | 0.757      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98999      |\n",
      "|    policy_loss        | -3.77      |\n",
      "|    reward             | 0.00275443 |\n",
      "|    std                | 1.02e+10   |\n",
      "|    value_loss         | 3.36e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 99100        |\n",
      "|    time_elapsed       | 4764         |\n",
      "|    total_timesteps    | 495500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -709         |\n",
      "|    explained_variance | -0.0382      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99099        |\n",
      "|    policy_loss        | 4.53         |\n",
      "|    reward             | -0.005010164 |\n",
      "|    std                | 1.04e+10     |\n",
      "|    value_loss         | 8.45e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 99200       |\n",
      "|    time_elapsed       | 4768        |\n",
      "|    total_timesteps    | 496000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -710        |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99199       |\n",
      "|    policy_loss        | -32.5       |\n",
      "|    reward             | 0.011269251 |\n",
      "|    std                | 1.07e+10    |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 99300         |\n",
      "|    time_elapsed       | 4773          |\n",
      "|    total_timesteps    | 496500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -711          |\n",
      "|    explained_variance | 0.777         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99299         |\n",
      "|    policy_loss        | 25.9          |\n",
      "|    reward             | -0.0027167916 |\n",
      "|    std                | 1.11e+10      |\n",
      "|    value_loss         | 0.00258       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 99400       |\n",
      "|    time_elapsed       | 4778        |\n",
      "|    total_timesteps    | 497000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -712        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99399       |\n",
      "|    policy_loss        | -51.4       |\n",
      "|    reward             | 0.008870519 |\n",
      "|    std                | 1.13e+10    |\n",
      "|    value_loss         | 0.00943     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 99500        |\n",
      "|    time_elapsed       | 4783         |\n",
      "|    total_timesteps    | 497500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -712         |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99499        |\n",
      "|    policy_loss        | -21.4        |\n",
      "|    reward             | -0.064457744 |\n",
      "|    std                | 1.15e+10     |\n",
      "|    value_loss         | 0.019        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 99600       |\n",
      "|    time_elapsed       | 4787        |\n",
      "|    total_timesteps    | 498000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -713        |\n",
      "|    explained_variance | 0.688       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99599       |\n",
      "|    policy_loss        | 0.565       |\n",
      "|    reward             | -0.06394507 |\n",
      "|    std                | 1.17e+10    |\n",
      "|    value_loss         | 9.14e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 99700      |\n",
      "|    time_elapsed       | 4792       |\n",
      "|    total_timesteps    | 498500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -713       |\n",
      "|    explained_variance | -0.668     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99699      |\n",
      "|    policy_loss        | -21.6      |\n",
      "|    reward             | 0.06311969 |\n",
      "|    std                | 1.2e+10    |\n",
      "|    value_loss         | 0.00172    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 99800        |\n",
      "|    time_elapsed       | 4797         |\n",
      "|    total_timesteps    | 499000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -714         |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99799        |\n",
      "|    policy_loss        | -2.57        |\n",
      "|    reward             | -0.030876637 |\n",
      "|    std                | 1.23e+10     |\n",
      "|    value_loss         | 2.43e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 99900        |\n",
      "|    time_elapsed       | 4802         |\n",
      "|    total_timesteps    | 499500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -715         |\n",
      "|    explained_variance | 0.381        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99899        |\n",
      "|    policy_loss        | 9.26         |\n",
      "|    reward             | -0.016227346 |\n",
      "|    std                | 1.27e+10     |\n",
      "|    value_loss         | 0.000645     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 100000        |\n",
      "|    time_elapsed       | 4806          |\n",
      "|    total_timesteps    | 500000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -716          |\n",
      "|    explained_variance | 0.789         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99999         |\n",
      "|    policy_loss        | 19            |\n",
      "|    reward             | -0.0017720301 |\n",
      "|    std                | 1.3e+10       |\n",
      "|    value_loss         | 0.00174       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 100100       |\n",
      "|    time_elapsed       | 4811         |\n",
      "|    total_timesteps    | 500500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -716         |\n",
      "|    explained_variance | -88.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 100099       |\n",
      "|    policy_loss        | 3.68         |\n",
      "|    reward             | -0.005526931 |\n",
      "|    std                | 1.32e+10     |\n",
      "|    value_loss         | 0.000728     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 100200      |\n",
      "|    time_elapsed       | 4816        |\n",
      "|    total_timesteps    | 501000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -717        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100199      |\n",
      "|    policy_loss        | -5.67       |\n",
      "|    reward             | 0.014081868 |\n",
      "|    std                | 1.34e+10    |\n",
      "|    value_loss         | 6.76e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 100300      |\n",
      "|    time_elapsed       | 4821        |\n",
      "|    total_timesteps    | 501500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -718        |\n",
      "|    explained_variance | 0.722       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100299      |\n",
      "|    policy_loss        | -0.356      |\n",
      "|    reward             | 0.025923427 |\n",
      "|    std                | 1.38e+10    |\n",
      "|    value_loss         | 0.000182    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 100400      |\n",
      "|    time_elapsed       | 4826        |\n",
      "|    total_timesteps    | 502000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -719        |\n",
      "|    explained_variance | -5          |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100399      |\n",
      "|    policy_loss        | -21.2       |\n",
      "|    reward             | -0.10039287 |\n",
      "|    std                | 1.43e+10    |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 100500      |\n",
      "|    time_elapsed       | 4830        |\n",
      "|    total_timesteps    | 502500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -719        |\n",
      "|    explained_variance | 0.297       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100499      |\n",
      "|    policy_loss        | 2.56        |\n",
      "|    reward             | -0.04531286 |\n",
      "|    std                | 1.47e+10    |\n",
      "|    value_loss         | 0.000372    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 100600     |\n",
      "|    time_elapsed       | 4835       |\n",
      "|    total_timesteps    | 503000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -720       |\n",
      "|    explained_variance | 0.88       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100599     |\n",
      "|    policy_loss        | -104       |\n",
      "|    reward             | -0.3690496 |\n",
      "|    std                | 1.51e+10   |\n",
      "|    value_loss         | 0.0223     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 100700        |\n",
      "|    time_elapsed       | 4840          |\n",
      "|    total_timesteps    | 503500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -721          |\n",
      "|    explained_variance | 0.267         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 100699        |\n",
      "|    policy_loss        | -18           |\n",
      "|    reward             | -0.0035594902 |\n",
      "|    std                | 1.53e+10      |\n",
      "|    value_loss         | 0.000671      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 100800       |\n",
      "|    time_elapsed       | 4845         |\n",
      "|    total_timesteps    | 504000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -721         |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 100799       |\n",
      "|    policy_loss        | -27.4        |\n",
      "|    reward             | 0.0070351167 |\n",
      "|    std                | 1.56e+10     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 100900     |\n",
      "|    time_elapsed       | 4849       |\n",
      "|    total_timesteps    | 504500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -722       |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100899     |\n",
      "|    policy_loss        | -8.08      |\n",
      "|    reward             | 0.05220511 |\n",
      "|    std                | 1.61e+10   |\n",
      "|    value_loss         | 0.000164   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 101000       |\n",
      "|    time_elapsed       | 4854         |\n",
      "|    total_timesteps    | 505000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -723         |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 100999       |\n",
      "|    policy_loss        | 5.57         |\n",
      "|    reward             | 0.0008673847 |\n",
      "|    std                | 1.66e+10     |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 101100     |\n",
      "|    time_elapsed       | 4859       |\n",
      "|    total_timesteps    | 505500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -724       |\n",
      "|    explained_variance | 0.763      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101099     |\n",
      "|    policy_loss        | 5.23       |\n",
      "|    reward             | 0.04642776 |\n",
      "|    std                | 1.71e+10   |\n",
      "|    value_loss         | 0.000214   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 101200      |\n",
      "|    time_elapsed       | 4864        |\n",
      "|    total_timesteps    | 506000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -725        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101199      |\n",
      "|    policy_loss        | -2.5        |\n",
      "|    reward             | 0.063866384 |\n",
      "|    std                | 1.76e+10    |\n",
      "|    value_loss         | 0.000301    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 101300      |\n",
      "|    time_elapsed       | 4869        |\n",
      "|    total_timesteps    | 506500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -725        |\n",
      "|    explained_variance | -5.59       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101299      |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | 0.013281824 |\n",
      "|    std                | 1.78e+10    |\n",
      "|    value_loss         | 0.000301    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 101400       |\n",
      "|    time_elapsed       | 4873         |\n",
      "|    total_timesteps    | 507000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -726         |\n",
      "|    explained_variance | 0.197        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 101399       |\n",
      "|    policy_loss        | -5.88        |\n",
      "|    reward             | -0.057214264 |\n",
      "|    std                | 1.83e+10     |\n",
      "|    value_loss         | 0.00047      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 101500      |\n",
      "|    time_elapsed       | 4878        |\n",
      "|    total_timesteps    | 507500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -727        |\n",
      "|    explained_variance | -1.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101499      |\n",
      "|    policy_loss        | 5.16        |\n",
      "|    reward             | 0.022493508 |\n",
      "|    std                | 1.88e+10    |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 101600      |\n",
      "|    time_elapsed       | 4883        |\n",
      "|    total_timesteps    | 508000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -728        |\n",
      "|    explained_variance | 0.0193      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101599      |\n",
      "|    policy_loss        | 25.2        |\n",
      "|    reward             | -0.09399488 |\n",
      "|    std                | 1.94e+10    |\n",
      "|    value_loss         | 0.00166     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 101700      |\n",
      "|    time_elapsed       | 4888        |\n",
      "|    total_timesteps    | 508500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -728        |\n",
      "|    explained_variance | 0.726       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101699      |\n",
      "|    policy_loss        | 3.89        |\n",
      "|    reward             | 0.043676745 |\n",
      "|    std                | 2e+10       |\n",
      "|    value_loss         | 0.000468    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 101800     |\n",
      "|    time_elapsed       | 4892       |\n",
      "|    total_timesteps    | 509000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -729       |\n",
      "|    explained_variance | 0.86       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101799     |\n",
      "|    policy_loss        | 25.6       |\n",
      "|    reward             | 0.07097842 |\n",
      "|    std                | 2.04e+10   |\n",
      "|    value_loss         | 0.00274    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 101900      |\n",
      "|    time_elapsed       | 4897        |\n",
      "|    total_timesteps    | 509500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -729        |\n",
      "|    explained_variance | 0.522       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101899      |\n",
      "|    policy_loss        | -10.6       |\n",
      "|    reward             | 0.025282634 |\n",
      "|    std                | 2.07e+10    |\n",
      "|    value_loss         | 0.000451    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 102000       |\n",
      "|    time_elapsed       | 4902         |\n",
      "|    total_timesteps    | 510000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -730         |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 101999       |\n",
      "|    policy_loss        | 7.23         |\n",
      "|    reward             | -0.022891691 |\n",
      "|    std                | 2.13e+10     |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 102100      |\n",
      "|    time_elapsed       | 4907        |\n",
      "|    total_timesteps    | 510500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -731        |\n",
      "|    explained_variance | 0.775       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102099      |\n",
      "|    policy_loss        | -26.5       |\n",
      "|    reward             | 0.013414008 |\n",
      "|    std                | 2.2e+10     |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 102200      |\n",
      "|    time_elapsed       | 4912        |\n",
      "|    total_timesteps    | 511000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -732        |\n",
      "|    explained_variance | 0.685       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102199      |\n",
      "|    policy_loss        | 34.1        |\n",
      "|    reward             | 0.013777452 |\n",
      "|    std                | 2.27e+10    |\n",
      "|    value_loss         | 0.00256     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 102300     |\n",
      "|    time_elapsed       | 4916       |\n",
      "|    total_timesteps    | 511500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -733       |\n",
      "|    explained_variance | 0.642      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102299     |\n",
      "|    policy_loss        | 55.4       |\n",
      "|    reward             | 0.26626247 |\n",
      "|    std                | 2.33e+10   |\n",
      "|    value_loss         | 0.0129     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 102400     |\n",
      "|    time_elapsed       | 4921       |\n",
      "|    total_timesteps    | 512000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -733       |\n",
      "|    explained_variance | 0.116      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102399     |\n",
      "|    policy_loss        | 636        |\n",
      "|    reward             | -0.3026301 |\n",
      "|    std                | 2.36e+10   |\n",
      "|    value_loss         | 1.97       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 102500      |\n",
      "|    time_elapsed       | 4926        |\n",
      "|    total_timesteps    | 512500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -734        |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102499      |\n",
      "|    policy_loss        | -2.55       |\n",
      "|    reward             | -0.00457819 |\n",
      "|    std                | 2.41e+10    |\n",
      "|    value_loss         | 2.85e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 102600        |\n",
      "|    time_elapsed       | 4931          |\n",
      "|    total_timesteps    | 513000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -734          |\n",
      "|    explained_variance | 0.958         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 102599        |\n",
      "|    policy_loss        | -5.64         |\n",
      "|    reward             | -0.0085631665 |\n",
      "|    std                | 2.46e+10      |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 102700       |\n",
      "|    time_elapsed       | 4935         |\n",
      "|    total_timesteps    | 513500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -735         |\n",
      "|    explained_variance | 0.52         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 102699       |\n",
      "|    policy_loss        | 5.55         |\n",
      "|    reward             | -0.045258608 |\n",
      "|    std                | 2.54e+10     |\n",
      "|    value_loss         | 0.000263     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 102800     |\n",
      "|    time_elapsed       | 4940       |\n",
      "|    total_timesteps    | 514000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -736       |\n",
      "|    explained_variance | -1.75      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102799     |\n",
      "|    policy_loss        | -7.66      |\n",
      "|    reward             | 0.09319204 |\n",
      "|    std                | 2.62e+10   |\n",
      "|    value_loss         | 0.000707   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 102900        |\n",
      "|    time_elapsed       | 4945          |\n",
      "|    total_timesteps    | 514500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -737          |\n",
      "|    explained_variance | -0.629        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 102899        |\n",
      "|    policy_loss        | -18.3         |\n",
      "|    reward             | -0.0064799646 |\n",
      "|    std                | 2.69e+10      |\n",
      "|    value_loss         | 0.0017        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 103000       |\n",
      "|    time_elapsed       | 4950         |\n",
      "|    total_timesteps    | 515000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -737         |\n",
      "|    explained_variance | 0.671        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 102999       |\n",
      "|    policy_loss        | -13          |\n",
      "|    reward             | 0.0070618107 |\n",
      "|    std                | 2.74e+10     |\n",
      "|    value_loss         | 0.000384     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 103100      |\n",
      "|    time_elapsed       | 4954        |\n",
      "|    total_timesteps    | 515500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -738        |\n",
      "|    explained_variance | 0.231       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103099      |\n",
      "|    policy_loss        | -9.35       |\n",
      "|    reward             | -0.02052874 |\n",
      "|    std                | 2.8e+10     |\n",
      "|    value_loss         | 0.000715    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 103200      |\n",
      "|    time_elapsed       | 4959        |\n",
      "|    total_timesteps    | 516000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -739        |\n",
      "|    explained_variance | 0.389       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103199      |\n",
      "|    policy_loss        | -17.5       |\n",
      "|    reward             | 0.034224495 |\n",
      "|    std                | 2.88e+10    |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 103300        |\n",
      "|    time_elapsed       | 4964          |\n",
      "|    total_timesteps    | 516500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -740          |\n",
      "|    explained_variance | 0.759         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 103299        |\n",
      "|    policy_loss        | 37.7          |\n",
      "|    reward             | -0.0052028503 |\n",
      "|    std                | 2.95e+10      |\n",
      "|    value_loss         | 0.00382       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 103400       |\n",
      "|    time_elapsed       | 4969         |\n",
      "|    total_timesteps    | 517000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -740         |\n",
      "|    explained_variance | 0.798        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 103399       |\n",
      "|    policy_loss        | 7.04         |\n",
      "|    reward             | -0.005906671 |\n",
      "|    std                | 3.02e+10     |\n",
      "|    value_loss         | 0.000236     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 103500      |\n",
      "|    time_elapsed       | 4974        |\n",
      "|    total_timesteps    | 517500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -741        |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103499      |\n",
      "|    policy_loss        | 25.7        |\n",
      "|    reward             | -0.05486375 |\n",
      "|    std                | 3.08e+10    |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 20371320.47\n",
      "total_reward: 10371320.47\n",
      "total_cost: 562989.29\n",
      "total_trades: 82810\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 103600    |\n",
      "|    time_elapsed       | 4978      |\n",
      "|    total_timesteps    | 518000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -741      |\n",
      "|    explained_variance | 0.738     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103599    |\n",
      "|    policy_loss        | -0.703    |\n",
      "|    reward             | 0.0091788 |\n",
      "|    std                | 3.13e+10  |\n",
      "|    value_loss         | 6.65e-06  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 103700      |\n",
      "|    time_elapsed       | 4983        |\n",
      "|    total_timesteps    | 518500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -742        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103699      |\n",
      "|    policy_loss        | -10.1       |\n",
      "|    reward             | 0.009653452 |\n",
      "|    std                | 3.2e+10     |\n",
      "|    value_loss         | 0.000241    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 103800       |\n",
      "|    time_elapsed       | 4988         |\n",
      "|    total_timesteps    | 519000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -743         |\n",
      "|    explained_variance | 0.207        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 103799       |\n",
      "|    policy_loss        | 5.15         |\n",
      "|    reward             | 0.0055583417 |\n",
      "|    std                | 3.3e+10      |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 103900      |\n",
      "|    time_elapsed       | 4993        |\n",
      "|    total_timesteps    | 519500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -744        |\n",
      "|    explained_variance | 0.475       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103899      |\n",
      "|    policy_loss        | -18.1       |\n",
      "|    reward             | 0.022625268 |\n",
      "|    std                | 3.41e+10    |\n",
      "|    value_loss         | 0.000903    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 104000       |\n",
      "|    time_elapsed       | 4997         |\n",
      "|    total_timesteps    | 520000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -745         |\n",
      "|    explained_variance | 0.777        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 103999       |\n",
      "|    policy_loss        | 10.4         |\n",
      "|    reward             | -0.009438116 |\n",
      "|    std                | 3.51e+10     |\n",
      "|    value_loss         | 0.000302     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 104100      |\n",
      "|    time_elapsed       | 5002        |\n",
      "|    total_timesteps    | 520500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -745        |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104099      |\n",
      "|    policy_loss        | 21.1        |\n",
      "|    reward             | -0.09761299 |\n",
      "|    std                | 3.58e+10    |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 104200       |\n",
      "|    time_elapsed       | 5007         |\n",
      "|    total_timesteps    | 521000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -746         |\n",
      "|    explained_variance | 0.258        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 104199       |\n",
      "|    policy_loss        | -0.646       |\n",
      "|    reward             | 0.0066467724 |\n",
      "|    std                | 3.64e+10     |\n",
      "|    value_loss         | 8.14e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 104300      |\n",
      "|    time_elapsed       | 5012        |\n",
      "|    total_timesteps    | 521500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -746        |\n",
      "|    explained_variance | 0.794       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104299      |\n",
      "|    policy_loss        | -3.98       |\n",
      "|    reward             | 0.011632286 |\n",
      "|    std                | 3.74e+10    |\n",
      "|    value_loss         | 0.000108    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 104400       |\n",
      "|    time_elapsed       | 5016         |\n",
      "|    total_timesteps    | 522000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -747         |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 104399       |\n",
      "|    policy_loss        | 0.243        |\n",
      "|    reward             | -0.008503824 |\n",
      "|    std                | 3.86e+10     |\n",
      "|    value_loss         | 3.18e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 104500       |\n",
      "|    time_elapsed       | 5021         |\n",
      "|    total_timesteps    | 522500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -748         |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 104499       |\n",
      "|    policy_loss        | -10.8        |\n",
      "|    reward             | -0.049528573 |\n",
      "|    std                | 3.98e+10     |\n",
      "|    value_loss         | 0.000393     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 104600      |\n",
      "|    time_elapsed       | 5026        |\n",
      "|    total_timesteps    | 523000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -749        |\n",
      "|    explained_variance | 0.442       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104599      |\n",
      "|    policy_loss        | 17.3        |\n",
      "|    reward             | -0.04008284 |\n",
      "|    std                | 4.1e+10     |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 104700      |\n",
      "|    time_elapsed       | 5031        |\n",
      "|    total_timesteps    | 523500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -750        |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104699      |\n",
      "|    policy_loss        | -79.9       |\n",
      "|    reward             | 0.112415485 |\n",
      "|    std                | 4.18e+10    |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 104800        |\n",
      "|    time_elapsed       | 5036          |\n",
      "|    total_timesteps    | 524000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -750          |\n",
      "|    explained_variance | 0.193         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 104799        |\n",
      "|    policy_loss        | 24.6          |\n",
      "|    reward             | 4.9613016e-05 |\n",
      "|    std                | 4.26e+10      |\n",
      "|    value_loss         | 0.00129       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 104900     |\n",
      "|    time_elapsed       | 5040       |\n",
      "|    total_timesteps    | 524500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -751       |\n",
      "|    explained_variance | 0.816      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 104899     |\n",
      "|    policy_loss        | -33.4      |\n",
      "|    reward             | 0.03856476 |\n",
      "|    std                | 4.37e+10   |\n",
      "|    value_loss         | 0.00275    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 105000      |\n",
      "|    time_elapsed       | 5045        |\n",
      "|    total_timesteps    | 525000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -752        |\n",
      "|    explained_variance | 0.608       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104999      |\n",
      "|    policy_loss        | -2.16       |\n",
      "|    reward             | 0.007548311 |\n",
      "|    std                | 4.52e+10    |\n",
      "|    value_loss         | 5.97e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 105100      |\n",
      "|    time_elapsed       | 5050        |\n",
      "|    total_timesteps    | 525500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -753        |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 105099      |\n",
      "|    policy_loss        | -12.5       |\n",
      "|    reward             | -0.04620792 |\n",
      "|    std                | 4.65e+10    |\n",
      "|    value_loss         | 0.0003      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 105200     |\n",
      "|    time_elapsed       | 5055       |\n",
      "|    total_timesteps    | 526000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -754       |\n",
      "|    explained_variance | 0.506      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 105199     |\n",
      "|    policy_loss        | -81.5      |\n",
      "|    reward             | 0.22005554 |\n",
      "|    std                | 4.77e+10   |\n",
      "|    value_loss         | 0.0131     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 105300     |\n",
      "|    time_elapsed       | 5060       |\n",
      "|    total_timesteps    | 526500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -754       |\n",
      "|    explained_variance | 0.334      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 105299     |\n",
      "|    policy_loss        | 144        |\n",
      "|    reward             | 0.42080545 |\n",
      "|    std                | 4.84e+10   |\n",
      "|    value_loss         | 0.0884     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 105400      |\n",
      "|    time_elapsed       | 5064        |\n",
      "|    total_timesteps    | 527000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -755        |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 105399      |\n",
      "|    policy_loss        | -4.82       |\n",
      "|    reward             | 0.028772226 |\n",
      "|    std                | 4.94e+10    |\n",
      "|    value_loss         | 5.25e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 105500      |\n",
      "|    time_elapsed       | 5069        |\n",
      "|    total_timesteps    | 527500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -755        |\n",
      "|    explained_variance | 0.565       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 105499      |\n",
      "|    policy_loss        | 6.92        |\n",
      "|    reward             | -0.05137755 |\n",
      "|    std                | 5.07e+10    |\n",
      "|    value_loss         | 0.00023     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 105600     |\n",
      "|    time_elapsed       | 5074       |\n",
      "|    total_timesteps    | 528000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -756       |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 105599     |\n",
      "|    policy_loss        | -25.4      |\n",
      "|    reward             | 0.03045273 |\n",
      "|    std                | 5.23e+10   |\n",
      "|    value_loss         | 0.0014     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 105700       |\n",
      "|    time_elapsed       | 5079         |\n",
      "|    total_timesteps    | 528500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -757         |\n",
      "|    explained_variance | 0.0998       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 105699       |\n",
      "|    policy_loss        | 0.516        |\n",
      "|    reward             | -0.025774393 |\n",
      "|    std                | 5.37e+10     |\n",
      "|    value_loss         | 0.000299     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 105800    |\n",
      "|    time_elapsed       | 5083      |\n",
      "|    total_timesteps    | 529000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -758      |\n",
      "|    explained_variance | 0.61      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105799    |\n",
      "|    policy_loss        | 56.6      |\n",
      "|    reward             | 0.2252911 |\n",
      "|    std                | 5.49e+10  |\n",
      "|    value_loss         | 0.0102    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 105900        |\n",
      "|    time_elapsed       | 5088          |\n",
      "|    total_timesteps    | 529500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -758          |\n",
      "|    explained_variance | 0.827         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 105899        |\n",
      "|    policy_loss        | -6.07         |\n",
      "|    reward             | -0.0040319646 |\n",
      "|    std                | 5.58e+10      |\n",
      "|    value_loss         | 7.39e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 106000        |\n",
      "|    time_elapsed       | 5093          |\n",
      "|    total_timesteps    | 530000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -759          |\n",
      "|    explained_variance | -1.76         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 105999        |\n",
      "|    policy_loss        | 9.91          |\n",
      "|    reward             | 0.00079088093 |\n",
      "|    std                | 5.71e+10      |\n",
      "|    value_loss         | 0.000255      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 106100       |\n",
      "|    time_elapsed       | 5098         |\n",
      "|    total_timesteps    | 530500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -760         |\n",
      "|    explained_variance | 0.735        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 106099       |\n",
      "|    policy_loss        | 3.66         |\n",
      "|    reward             | 0.0100450395 |\n",
      "|    std                | 5.88e+10     |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 106200      |\n",
      "|    time_elapsed       | 5102        |\n",
      "|    total_timesteps    | 531000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -761        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 106199      |\n",
      "|    policy_loss        | 2.8         |\n",
      "|    reward             | 0.018324666 |\n",
      "|    std                | 6.08e+10    |\n",
      "|    value_loss         | 5.48e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 106300      |\n",
      "|    time_elapsed       | 5107        |\n",
      "|    total_timesteps    | 531500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -761        |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 106299      |\n",
      "|    policy_loss        | 2.86        |\n",
      "|    reward             | 0.009706451 |\n",
      "|    std                | 6.23e+10    |\n",
      "|    value_loss         | 0.000618    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 106400      |\n",
      "|    time_elapsed       | 5112        |\n",
      "|    total_timesteps    | 532000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -762        |\n",
      "|    explained_variance | 0.714       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 106399      |\n",
      "|    policy_loss        | -40.7       |\n",
      "|    reward             | 0.015959842 |\n",
      "|    std                | 6.36e+10    |\n",
      "|    value_loss         | 0.00353     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 106500       |\n",
      "|    time_elapsed       | 5118         |\n",
      "|    total_timesteps    | 532500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -762         |\n",
      "|    explained_variance | 0.486        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 106499       |\n",
      "|    policy_loss        | -4.78        |\n",
      "|    reward             | -0.023921244 |\n",
      "|    std                | 6.46e+10     |\n",
      "|    value_loss         | 4.91e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 106600      |\n",
      "|    time_elapsed       | 5123        |\n",
      "|    total_timesteps    | 533000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -763        |\n",
      "|    explained_variance | 0.0773      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 106599      |\n",
      "|    policy_loss        | 33.8        |\n",
      "|    reward             | 0.053229988 |\n",
      "|    std                | 6.62e+10    |\n",
      "|    value_loss         | 0.004       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 106700       |\n",
      "|    time_elapsed       | 5127         |\n",
      "|    total_timesteps    | 533500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -764         |\n",
      "|    explained_variance | 0.383        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 106699       |\n",
      "|    policy_loss        | -10.4        |\n",
      "|    reward             | -0.030430801 |\n",
      "|    std                | 6.81e+10     |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 106800       |\n",
      "|    time_elapsed       | 5132         |\n",
      "|    total_timesteps    | 534000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -765         |\n",
      "|    explained_variance | 0.475        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 106799       |\n",
      "|    policy_loss        | -46.7        |\n",
      "|    reward             | -0.029700322 |\n",
      "|    std                | 7.03e+10     |\n",
      "|    value_loss         | 0.007        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 106900     |\n",
      "|    time_elapsed       | 5137       |\n",
      "|    total_timesteps    | 534500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -766       |\n",
      "|    explained_variance | 0.806      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106899     |\n",
      "|    policy_loss        | -28.8      |\n",
      "|    reward             | 0.02846519 |\n",
      "|    std                | 7.22e+10   |\n",
      "|    value_loss         | 0.00149    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 107000      |\n",
      "|    time_elapsed       | 5142        |\n",
      "|    total_timesteps    | 535000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -766        |\n",
      "|    explained_variance | 0.807       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 106999      |\n",
      "|    policy_loss        | -75.3       |\n",
      "|    reward             | -0.09784622 |\n",
      "|    std                | 7.36e+10    |\n",
      "|    value_loss         | 0.0141      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 107100      |\n",
      "|    time_elapsed       | 5146        |\n",
      "|    total_timesteps    | 535500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -767        |\n",
      "|    explained_variance | 0.34        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 107099      |\n",
      "|    policy_loss        | -0.606      |\n",
      "|    reward             | 0.004712254 |\n",
      "|    std                | 7.48e+10    |\n",
      "|    value_loss         | 1.72e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 107200       |\n",
      "|    time_elapsed       | 5151         |\n",
      "|    total_timesteps    | 536000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -767         |\n",
      "|    explained_variance | 0.0995       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 107199       |\n",
      "|    policy_loss        | -17.8        |\n",
      "|    reward             | -0.015982296 |\n",
      "|    std                | 7.68e+10     |\n",
      "|    value_loss         | 0.000625     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 107300       |\n",
      "|    time_elapsed       | 5156         |\n",
      "|    total_timesteps    | 536500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -768         |\n",
      "|    explained_variance | -0.12        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 107299       |\n",
      "|    policy_loss        | -0.882       |\n",
      "|    reward             | -0.008437256 |\n",
      "|    std                | 7.94e+10     |\n",
      "|    value_loss         | 0.000756     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 107400     |\n",
      "|    time_elapsed       | 5161       |\n",
      "|    total_timesteps    | 537000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -769       |\n",
      "|    explained_variance | 0.907      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107399     |\n",
      "|    policy_loss        | 61.7       |\n",
      "|    reward             | 0.09078959 |\n",
      "|    std                | 8.15e+10   |\n",
      "|    value_loss         | 0.0071     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 107500     |\n",
      "|    time_elapsed       | 5166       |\n",
      "|    total_timesteps    | 537500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -770       |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107499     |\n",
      "|    policy_loss        | 15.8       |\n",
      "|    reward             | 0.17633322 |\n",
      "|    std                | 8.33e+10   |\n",
      "|    value_loss         | 0.00809    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 107600      |\n",
      "|    time_elapsed       | 5170        |\n",
      "|    total_timesteps    | 538000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -770        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 107599      |\n",
      "|    policy_loss        | 94.3        |\n",
      "|    reward             | 0.055047683 |\n",
      "|    std                | 8.47e+10    |\n",
      "|    value_loss         | 0.0186      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 107700      |\n",
      "|    time_elapsed       | 5175        |\n",
      "|    total_timesteps    | 538500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -771        |\n",
      "|    explained_variance | 0.303       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 107699      |\n",
      "|    policy_loss        | 12.6        |\n",
      "|    reward             | 0.013486002 |\n",
      "|    std                | 8.6e+10     |\n",
      "|    value_loss         | 0.000292    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 107800       |\n",
      "|    time_elapsed       | 5180         |\n",
      "|    total_timesteps    | 539000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -771         |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 107799       |\n",
      "|    policy_loss        | 13.7         |\n",
      "|    reward             | -0.013641154 |\n",
      "|    std                | 8.81e+10     |\n",
      "|    value_loss         | 0.000429     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 107900      |\n",
      "|    time_elapsed       | 5185        |\n",
      "|    total_timesteps    | 539500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -772        |\n",
      "|    explained_variance | 0.702       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 107899      |\n",
      "|    policy_loss        | 6.03        |\n",
      "|    reward             | 0.042417895 |\n",
      "|    std                | 9.07e+10    |\n",
      "|    value_loss         | 0.000371    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 108000      |\n",
      "|    time_elapsed       | 5189        |\n",
      "|    total_timesteps    | 540000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -773        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 107999      |\n",
      "|    policy_loss        | -5.18       |\n",
      "|    reward             | -0.03353156 |\n",
      "|    std                | 9.32e+10    |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 108100      |\n",
      "|    time_elapsed       | 5194        |\n",
      "|    total_timesteps    | 540500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -774        |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108099      |\n",
      "|    policy_loss        | 45.9        |\n",
      "|    reward             | -0.15321185 |\n",
      "|    std                | 9.52e+10    |\n",
      "|    value_loss         | 0.00491     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 108200       |\n",
      "|    time_elapsed       | 5199         |\n",
      "|    total_timesteps    | 541000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -774         |\n",
      "|    explained_variance | -3.34        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 108199       |\n",
      "|    policy_loss        | 3.28         |\n",
      "|    reward             | -0.001049706 |\n",
      "|    std                | 9.65e+10     |\n",
      "|    value_loss         | 0.00572      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 108300        |\n",
      "|    time_elapsed       | 5204          |\n",
      "|    total_timesteps    | 541500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -774          |\n",
      "|    explained_variance | 0.532         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 108299        |\n",
      "|    policy_loss        | -2.37         |\n",
      "|    reward             | -0.0011245069 |\n",
      "|    std                | 9.84e+10      |\n",
      "|    value_loss         | 1.33e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 108400       |\n",
      "|    time_elapsed       | 5209         |\n",
      "|    total_timesteps    | 542000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -775         |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 108399       |\n",
      "|    policy_loss        | -16.8        |\n",
      "|    reward             | -0.014465185 |\n",
      "|    std                | 1.01e+11     |\n",
      "|    value_loss         | 0.00051      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 108500      |\n",
      "|    time_elapsed       | 5213        |\n",
      "|    total_timesteps    | 542500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -776        |\n",
      "|    explained_variance | 0.645       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108499      |\n",
      "|    policy_loss        | -111        |\n",
      "|    reward             | -0.06824857 |\n",
      "|    std                | 1.04e+11    |\n",
      "|    value_loss         | 0.0259      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 108600      |\n",
      "|    time_elapsed       | 5218        |\n",
      "|    total_timesteps    | 543000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -777        |\n",
      "|    explained_variance | 0.728       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108599      |\n",
      "|    policy_loss        | 19.6        |\n",
      "|    reward             | 0.017805638 |\n",
      "|    std                | 1.06e+11    |\n",
      "|    value_loss         | 0.00104     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 108700     |\n",
      "|    time_elapsed       | 5223       |\n",
      "|    total_timesteps    | 543500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -777       |\n",
      "|    explained_variance | 0.772      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108699     |\n",
      "|    policy_loss        | 12         |\n",
      "|    reward             | -0.3698543 |\n",
      "|    std                | 1.09e+11   |\n",
      "|    value_loss         | 0.00829    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 108800        |\n",
      "|    time_elapsed       | 5228          |\n",
      "|    total_timesteps    | 544000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -778          |\n",
      "|    explained_variance | -1.11         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 108799        |\n",
      "|    policy_loss        | -19           |\n",
      "|    reward             | -0.0028605189 |\n",
      "|    std                | 1.1e+11       |\n",
      "|    value_loss         | 0.000673      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 108900      |\n",
      "|    time_elapsed       | 5233        |\n",
      "|    total_timesteps    | 544500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -778        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108899      |\n",
      "|    policy_loss        | 17.1        |\n",
      "|    reward             | 0.024827832 |\n",
      "|    std                | 1.13e+11    |\n",
      "|    value_loss         | 0.000556    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 109000      |\n",
      "|    time_elapsed       | 5237        |\n",
      "|    total_timesteps    | 545000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -779        |\n",
      "|    explained_variance | 0.664       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108999      |\n",
      "|    policy_loss        | -19.9       |\n",
      "|    reward             | -0.04966124 |\n",
      "|    std                | 1.16e+11    |\n",
      "|    value_loss         | 0.000911    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 109100       |\n",
      "|    time_elapsed       | 5242         |\n",
      "|    total_timesteps    | 545500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -780         |\n",
      "|    explained_variance | 0.792        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 109099       |\n",
      "|    policy_loss        | -19.6        |\n",
      "|    reward             | -0.010043168 |\n",
      "|    std                | 1.19e+11     |\n",
      "|    value_loss         | 0.000894     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 109200       |\n",
      "|    time_elapsed       | 5247         |\n",
      "|    total_timesteps    | 546000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -781         |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 109199       |\n",
      "|    policy_loss        | -7.41        |\n",
      "|    reward             | -0.022945972 |\n",
      "|    std                | 1.23e+11     |\n",
      "|    value_loss         | 0.000473     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 109300      |\n",
      "|    time_elapsed       | 5252        |\n",
      "|    total_timesteps    | 546500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -781        |\n",
      "|    explained_variance | 0.768       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 109299      |\n",
      "|    policy_loss        | -16.6       |\n",
      "|    reward             | -0.12341193 |\n",
      "|    std                | 1.25e+11    |\n",
      "|    value_loss         | 0.00472     |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17587209.13\n",
      "total_reward: 7587209.13\n",
      "total_cost: 562842.57\n",
      "total_trades: 82778\n",
      "Sharpe: 0.480\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 109400       |\n",
      "|    time_elapsed       | 5256         |\n",
      "|    total_timesteps    | 547000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -782         |\n",
      "|    explained_variance | -0.251       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 109399       |\n",
      "|    policy_loss        | 0.262        |\n",
      "|    reward             | -0.012626219 |\n",
      "|    std                | 1.27e+11     |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 109500       |\n",
      "|    time_elapsed       | 5261         |\n",
      "|    total_timesteps    | 547500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -783         |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 109499       |\n",
      "|    policy_loss        | 5.15         |\n",
      "|    reward             | -0.012539332 |\n",
      "|    std                | 1.3e+11      |\n",
      "|    value_loss         | 0.000155     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 109600      |\n",
      "|    time_elapsed       | 5266        |\n",
      "|    total_timesteps    | 548000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -784        |\n",
      "|    explained_variance | 0.721       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 109599      |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.012910893 |\n",
      "|    std                | 1.34e+11    |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 109700       |\n",
      "|    time_elapsed       | 5271         |\n",
      "|    total_timesteps    | 548500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -784         |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 109699       |\n",
      "|    policy_loss        | 16.4         |\n",
      "|    reward             | -0.009461072 |\n",
      "|    std                | 1.39e+11     |\n",
      "|    value_loss         | 0.000744     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 109800       |\n",
      "|    time_elapsed       | 5275         |\n",
      "|    total_timesteps    | 549000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -785         |\n",
      "|    explained_variance | 0.55         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 109799       |\n",
      "|    policy_loss        | 54.2         |\n",
      "|    reward             | -0.008503895 |\n",
      "|    std                | 1.42e+11     |\n",
      "|    value_loss         | 0.0108       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 109900     |\n",
      "|    time_elapsed       | 5280       |\n",
      "|    total_timesteps    | 549500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -785       |\n",
      "|    explained_variance | 0.414      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109899     |\n",
      "|    policy_loss        | -408       |\n",
      "|    reward             | 0.17099579 |\n",
      "|    std                | 1.43e+11   |\n",
      "|    value_loss         | 0.306      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 110000      |\n",
      "|    time_elapsed       | 5285        |\n",
      "|    total_timesteps    | 550000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -786        |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 109999      |\n",
      "|    policy_loss        | -18         |\n",
      "|    reward             | -0.02813177 |\n",
      "|    std                | 1.45e+11    |\n",
      "|    value_loss         | 0.000728    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 110100       |\n",
      "|    time_elapsed       | 5290         |\n",
      "|    total_timesteps    | 550500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -786         |\n",
      "|    explained_variance | 0.798        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 110099       |\n",
      "|    policy_loss        | 17.1         |\n",
      "|    reward             | -0.033680413 |\n",
      "|    std                | 1.48e+11     |\n",
      "|    value_loss         | 0.000997     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 110200      |\n",
      "|    time_elapsed       | 5295        |\n",
      "|    total_timesteps    | 551000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -787        |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 110199      |\n",
      "|    policy_loss        | -0.76       |\n",
      "|    reward             | 0.063681185 |\n",
      "|    std                | 1.52e+11    |\n",
      "|    value_loss         | 0.000696    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 110300      |\n",
      "|    time_elapsed       | 5299        |\n",
      "|    total_timesteps    | 551500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -788        |\n",
      "|    explained_variance | 0.594       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 110299      |\n",
      "|    policy_loss        | 12.8        |\n",
      "|    reward             | 0.067758925 |\n",
      "|    std                | 1.56e+11    |\n",
      "|    value_loss         | 0.000716    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 110400      |\n",
      "|    time_elapsed       | 5304        |\n",
      "|    total_timesteps    | 552000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -788        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 110399      |\n",
      "|    policy_loss        | 31.1        |\n",
      "|    reward             | -0.36193013 |\n",
      "|    std                | 1.59e+11    |\n",
      "|    value_loss         | 0.00191     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 110500     |\n",
      "|    time_elapsed       | 5309       |\n",
      "|    total_timesteps    | 552500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -789       |\n",
      "|    explained_variance | 0.049      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 110499     |\n",
      "|    policy_loss        | 885        |\n",
      "|    reward             | -0.7846719 |\n",
      "|    std                | 1.62e+11   |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 110600       |\n",
      "|    time_elapsed       | 5314         |\n",
      "|    total_timesteps    | 553000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -789         |\n",
      "|    explained_variance | 0.218        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 110599       |\n",
      "|    policy_loss        | 17.8         |\n",
      "|    reward             | 0.0056758258 |\n",
      "|    std                | 1.65e+11     |\n",
      "|    value_loss         | 0.000687     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 110700        |\n",
      "|    time_elapsed       | 5318          |\n",
      "|    total_timesteps    | 553500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -790          |\n",
      "|    explained_variance | -5.73         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 110699        |\n",
      "|    policy_loss        | -19.9         |\n",
      "|    reward             | -0.0011758037 |\n",
      "|    std                | 1.69e+11      |\n",
      "|    value_loss         | 0.00123       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 110800      |\n",
      "|    time_elapsed       | 5323        |\n",
      "|    total_timesteps    | 554000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -791        |\n",
      "|    explained_variance | 0.0848      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 110799      |\n",
      "|    policy_loss        | 24.1        |\n",
      "|    reward             | 0.052308057 |\n",
      "|    std                | 1.75e+11    |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 110900      |\n",
      "|    time_elapsed       | 5328        |\n",
      "|    total_timesteps    | 554500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -792        |\n",
      "|    explained_variance | 0.491       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 110899      |\n",
      "|    policy_loss        | -32.4       |\n",
      "|    reward             | -0.12537001 |\n",
      "|    std                | 1.8e+11     |\n",
      "|    value_loss         | 0.00246     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 111000       |\n",
      "|    time_elapsed       | 5333         |\n",
      "|    total_timesteps    | 555000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -793         |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 110999       |\n",
      "|    policy_loss        | -20.8        |\n",
      "|    reward             | -0.018830184 |\n",
      "|    std                | 1.84e+11     |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 111100        |\n",
      "|    time_elapsed       | 5338          |\n",
      "|    total_timesteps    | 555500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -793          |\n",
      "|    explained_variance | -0.138        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 111099        |\n",
      "|    policy_loss        | -10.7         |\n",
      "|    reward             | -0.0041506705 |\n",
      "|    std                | 1.87e+11      |\n",
      "|    value_loss         | 0.000221      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 111200        |\n",
      "|    time_elapsed       | 5342          |\n",
      "|    total_timesteps    | 556000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -794          |\n",
      "|    explained_variance | 0.383         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 111199        |\n",
      "|    policy_loss        | -34.3         |\n",
      "|    reward             | 6.4739215e-05 |\n",
      "|    std                | 1.91e+11      |\n",
      "|    value_loss         | 0.00205       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 111300     |\n",
      "|    time_elapsed       | 5347       |\n",
      "|    total_timesteps    | 556500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -794       |\n",
      "|    explained_variance | 0.26       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 111299     |\n",
      "|    policy_loss        | -25.2      |\n",
      "|    reward             | 0.05947782 |\n",
      "|    std                | 1.96e+11   |\n",
      "|    value_loss         | 0.00105    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 111400        |\n",
      "|    time_elapsed       | 5352          |\n",
      "|    total_timesteps    | 557000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -795          |\n",
      "|    explained_variance | 0.974         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 111399        |\n",
      "|    policy_loss        | 19            |\n",
      "|    reward             | -0.0020176275 |\n",
      "|    std                | 2.01e+11      |\n",
      "|    value_loss         | 0.000615      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 111500     |\n",
      "|    time_elapsed       | 5357       |\n",
      "|    total_timesteps    | 557500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -796       |\n",
      "|    explained_variance | -8.24      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 111499     |\n",
      "|    policy_loss        | -21.3      |\n",
      "|    reward             | 0.06937158 |\n",
      "|    std                | 2.07e+11   |\n",
      "|    value_loss         | 0.00355    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 111600     |\n",
      "|    time_elapsed       | 5362       |\n",
      "|    total_timesteps    | 558000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -797       |\n",
      "|    explained_variance | 0.573      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 111599     |\n",
      "|    policy_loss        | -129       |\n",
      "|    reward             | 0.30825213 |\n",
      "|    std                | 2.11e+11   |\n",
      "|    value_loss         | 0.0364     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 111700       |\n",
      "|    time_elapsed       | 5366         |\n",
      "|    total_timesteps    | 558500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -797         |\n",
      "|    explained_variance | -1.07        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 111699       |\n",
      "|    policy_loss        | 5.58         |\n",
      "|    reward             | -0.006408269 |\n",
      "|    std                | 2.13e+11     |\n",
      "|    value_loss         | 8.36e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 111800     |\n",
      "|    time_elapsed       | 5371       |\n",
      "|    total_timesteps    | 559000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -797       |\n",
      "|    explained_variance | -1.62      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 111799     |\n",
      "|    policy_loss        | -48        |\n",
      "|    reward             | 0.01074281 |\n",
      "|    std                | 2.18e+11   |\n",
      "|    value_loss         | 0.0038     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 111900       |\n",
      "|    time_elapsed       | 5376         |\n",
      "|    total_timesteps    | 559500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -798         |\n",
      "|    explained_variance | 0.58         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 111899       |\n",
      "|    policy_loss        | -2.3         |\n",
      "|    reward             | -0.008003508 |\n",
      "|    std                | 2.24e+11     |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 112000      |\n",
      "|    time_elapsed       | 5381        |\n",
      "|    total_timesteps    | 560000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -799        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 111999      |\n",
      "|    policy_loss        | -20.9       |\n",
      "|    reward             | -0.06489168 |\n",
      "|    std                | 2.3e+11     |\n",
      "|    value_loss         | 0.000779    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 112100        |\n",
      "|    time_elapsed       | 5386          |\n",
      "|    total_timesteps    | 560500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -800          |\n",
      "|    explained_variance | 0.85          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 112099        |\n",
      "|    policy_loss        | -11.8         |\n",
      "|    reward             | -0.0050738594 |\n",
      "|    std                | 2.36e+11      |\n",
      "|    value_loss         | 0.000335      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 112200      |\n",
      "|    time_elapsed       | 5390        |\n",
      "|    total_timesteps    | 561000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -800        |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 112199      |\n",
      "|    policy_loss        | -15.9       |\n",
      "|    reward             | 0.053091496 |\n",
      "|    std                | 2.39e+11    |\n",
      "|    value_loss         | 0.00097     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 112300      |\n",
      "|    time_elapsed       | 5395        |\n",
      "|    total_timesteps    | 561500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -801        |\n",
      "|    explained_variance | 0.153       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 112299      |\n",
      "|    policy_loss        | -8.83       |\n",
      "|    reward             | -0.01054895 |\n",
      "|    std                | 2.42e+11    |\n",
      "|    value_loss         | 0.000149    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 112400      |\n",
      "|    time_elapsed       | 5400        |\n",
      "|    total_timesteps    | 562000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -801        |\n",
      "|    explained_variance | 0.619       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 112399      |\n",
      "|    policy_loss        | 3.04        |\n",
      "|    reward             | 0.008662048 |\n",
      "|    std                | 2.48e+11    |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 112500      |\n",
      "|    time_elapsed       | 5405        |\n",
      "|    total_timesteps    | 562500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -802        |\n",
      "|    explained_variance | 0.453       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 112499      |\n",
      "|    policy_loss        | -3.27       |\n",
      "|    reward             | -0.03586299 |\n",
      "|    std                | 2.55e+11    |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 112600       |\n",
      "|    time_elapsed       | 5410         |\n",
      "|    total_timesteps    | 563000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -803         |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 112599       |\n",
      "|    policy_loss        | 91.8         |\n",
      "|    reward             | -0.011951697 |\n",
      "|    std                | 2.63e+11     |\n",
      "|    value_loss         | 0.0144       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 112700       |\n",
      "|    time_elapsed       | 5415         |\n",
      "|    total_timesteps    | 563500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -804         |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 112699       |\n",
      "|    policy_loss        | 38.9         |\n",
      "|    reward             | -0.022344122 |\n",
      "|    std                | 2.7e+11      |\n",
      "|    value_loss         | 0.0029       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 112800      |\n",
      "|    time_elapsed       | 5419        |\n",
      "|    total_timesteps    | 564000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -804        |\n",
      "|    explained_variance | 0.735       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 112799      |\n",
      "|    policy_loss        | 16.6        |\n",
      "|    reward             | 0.041001145 |\n",
      "|    std                | 2.75e+11    |\n",
      "|    value_loss         | 0.00197     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 112900       |\n",
      "|    time_elapsed       | 5424         |\n",
      "|    total_timesteps    | 564500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -805         |\n",
      "|    explained_variance | 0.662        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 112899       |\n",
      "|    policy_loss        | -8.73        |\n",
      "|    reward             | 0.0032185954 |\n",
      "|    std                | 2.79e+11     |\n",
      "|    value_loss         | 0.000692     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 113000      |\n",
      "|    time_elapsed       | 5429        |\n",
      "|    total_timesteps    | 565000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -805        |\n",
      "|    explained_variance | -0.152      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 112999      |\n",
      "|    policy_loss        | -16.5       |\n",
      "|    reward             | 0.020305768 |\n",
      "|    std                | 2.87e+11    |\n",
      "|    value_loss         | 0.000986    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 113100      |\n",
      "|    time_elapsed       | 5434        |\n",
      "|    total_timesteps    | 565500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -806        |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 113099      |\n",
      "|    policy_loss        | 4           |\n",
      "|    reward             | 0.019933095 |\n",
      "|    std                | 2.95e+11    |\n",
      "|    value_loss         | 7.99e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 104            |\n",
      "|    iterations         | 113200         |\n",
      "|    time_elapsed       | 5438           |\n",
      "|    total_timesteps    | 566000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -807           |\n",
      "|    explained_variance | -0.0383        |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 113199         |\n",
      "|    policy_loss        | 28.7           |\n",
      "|    reward             | -0.00011627279 |\n",
      "|    std                | 3.04e+11       |\n",
      "|    value_loss         | 0.00159        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 113300       |\n",
      "|    time_elapsed       | 5443         |\n",
      "|    total_timesteps    | 566500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -808         |\n",
      "|    explained_variance | 0.713        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 113299       |\n",
      "|    policy_loss        | -16.6        |\n",
      "|    reward             | -0.004326292 |\n",
      "|    std                | 3.12e+11     |\n",
      "|    value_loss         | 0.00124      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 113400       |\n",
      "|    time_elapsed       | 5448         |\n",
      "|    total_timesteps    | 567000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -808         |\n",
      "|    explained_variance | 0.79         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 113399       |\n",
      "|    policy_loss        | 0.0769       |\n",
      "|    reward             | -0.070286684 |\n",
      "|    std                | 3.17e+11     |\n",
      "|    value_loss         | 0.0145       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 113500       |\n",
      "|    time_elapsed       | 5453         |\n",
      "|    total_timesteps    | 567500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -809         |\n",
      "|    explained_variance | 0.561        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 113499       |\n",
      "|    policy_loss        | 5.07         |\n",
      "|    reward             | -0.028201286 |\n",
      "|    std                | 3.23e+11     |\n",
      "|    value_loss         | 0.000245     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 113600        |\n",
      "|    time_elapsed       | 5458          |\n",
      "|    total_timesteps    | 568000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -810          |\n",
      "|    explained_variance | 0.618         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 113599        |\n",
      "|    policy_loss        | 12.7          |\n",
      "|    reward             | -0.0007113041 |\n",
      "|    std                | 3.33e+11      |\n",
      "|    value_loss         | 0.000496      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 113700      |\n",
      "|    time_elapsed       | 5462        |\n",
      "|    total_timesteps    | 568500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -811        |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 113699      |\n",
      "|    policy_loss        | 47.8        |\n",
      "|    reward             | 0.032731358 |\n",
      "|    std                | 3.44e+11    |\n",
      "|    value_loss         | 0.00383     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 113800      |\n",
      "|    time_elapsed       | 5467        |\n",
      "|    total_timesteps    | 569000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -811        |\n",
      "|    explained_variance | -2.34       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 113799      |\n",
      "|    policy_loss        | 2.22        |\n",
      "|    reward             | -0.06456662 |\n",
      "|    std                | 3.53e+11    |\n",
      "|    value_loss         | 0.000792    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 113900      |\n",
      "|    time_elapsed       | 5472        |\n",
      "|    total_timesteps    | 569500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -812        |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 113899      |\n",
      "|    policy_loss        | 258         |\n",
      "|    reward             | -0.33637586 |\n",
      "|    std                | 3.61e+11    |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 114000       |\n",
      "|    time_elapsed       | 5477         |\n",
      "|    total_timesteps    | 570000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -812         |\n",
      "|    explained_variance | -0.344       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 113999       |\n",
      "|    policy_loss        | 0.0651       |\n",
      "|    reward             | 0.0009784335 |\n",
      "|    std                | 3.65e+11     |\n",
      "|    value_loss         | 8.72e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 114100      |\n",
      "|    time_elapsed       | 5482        |\n",
      "|    total_timesteps    | 570500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -813        |\n",
      "|    explained_variance | 0.493       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 114099      |\n",
      "|    policy_loss        | 7.07        |\n",
      "|    reward             | 0.045217413 |\n",
      "|    std                | 3.72e+11    |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 114200       |\n",
      "|    time_elapsed       | 5486         |\n",
      "|    total_timesteps    | 571000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -814         |\n",
      "|    explained_variance | 0.62         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 114199       |\n",
      "|    policy_loss        | -14.2        |\n",
      "|    reward             | -0.034154274 |\n",
      "|    std                | 3.81e+11     |\n",
      "|    value_loss         | 0.000695     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 114300      |\n",
      "|    time_elapsed       | 5491        |\n",
      "|    total_timesteps    | 571500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -815        |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 114299      |\n",
      "|    policy_loss        | -7.54       |\n",
      "|    reward             | 0.019988982 |\n",
      "|    std                | 3.92e+11    |\n",
      "|    value_loss         | 0.000453    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 114400       |\n",
      "|    time_elapsed       | 5496         |\n",
      "|    total_timesteps    | 572000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -815         |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 114399       |\n",
      "|    policy_loss        | -9.29        |\n",
      "|    reward             | 0.0065907678 |\n",
      "|    std                | 4.02e+11     |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 114500      |\n",
      "|    time_elapsed       | 5501        |\n",
      "|    total_timesteps    | 572500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -816        |\n",
      "|    explained_variance | 0.515       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 114499      |\n",
      "|    policy_loss        | -11.7       |\n",
      "|    reward             | 0.059758123 |\n",
      "|    std                | 4.09e+11    |\n",
      "|    value_loss         | 0.00757     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 114600        |\n",
      "|    time_elapsed       | 5506          |\n",
      "|    total_timesteps    | 573000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -816          |\n",
      "|    explained_variance | 0.679         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 114599        |\n",
      "|    policy_loss        | 6.93          |\n",
      "|    reward             | -0.0028024665 |\n",
      "|    std                | 4.14e+11      |\n",
      "|    value_loss         | 9.19e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 114700      |\n",
      "|    time_elapsed       | 5511        |\n",
      "|    total_timesteps    | 573500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -817        |\n",
      "|    explained_variance | 0.291       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 114699      |\n",
      "|    policy_loss        | -19.4       |\n",
      "|    reward             | -0.11165491 |\n",
      "|    std                | 4.23e+11    |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 114800       |\n",
      "|    time_elapsed       | 5515         |\n",
      "|    total_timesteps    | 574000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -818         |\n",
      "|    explained_variance | 0.731        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 114799       |\n",
      "|    policy_loss        | -26.5        |\n",
      "|    reward             | 0.0029825282 |\n",
      "|    std                | 4.35e+11     |\n",
      "|    value_loss         | 0.00234      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 114900     |\n",
      "|    time_elapsed       | 5520       |\n",
      "|    total_timesteps    | 574500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -818       |\n",
      "|    explained_variance | 0.906      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 114899     |\n",
      "|    policy_loss        | 8.68       |\n",
      "|    reward             | 0.11091329 |\n",
      "|    std                | 4.47e+11   |\n",
      "|    value_loss         | 0.000917   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 115000      |\n",
      "|    time_elapsed       | 5525        |\n",
      "|    total_timesteps    | 575000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -819        |\n",
      "|    explained_variance | -2.99       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 114999      |\n",
      "|    policy_loss        | 15.7        |\n",
      "|    reward             | 0.033043068 |\n",
      "|    std                | 4.58e+11    |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 115100     |\n",
      "|    time_elapsed       | 5530       |\n",
      "|    total_timesteps    | 575500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -819       |\n",
      "|    explained_variance | 0.884      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 115099     |\n",
      "|    policy_loss        | 19.5       |\n",
      "|    reward             | 0.35127535 |\n",
      "|    std                | 4.66e+11   |\n",
      "|    value_loss         | 0.00479    |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 200\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19960841.18\n",
      "total_reward: 9960841.18\n",
      "total_cost: 562974.40\n",
      "total_trades: 82955\n",
      "Sharpe: 0.553\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 115200      |\n",
      "|    time_elapsed       | 5534        |\n",
      "|    total_timesteps    | 576000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -820        |\n",
      "|    explained_variance | -18.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 115199      |\n",
      "|    policy_loss        | 27.5        |\n",
      "|    reward             | 0.013047472 |\n",
      "|    std                | 4.73e+11    |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 115300        |\n",
      "|    time_elapsed       | 5539          |\n",
      "|    total_timesteps    | 576500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -821          |\n",
      "|    explained_variance | -2.64         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 115299        |\n",
      "|    policy_loss        | -3.58         |\n",
      "|    reward             | -0.0005125546 |\n",
      "|    std                | 4.84e+11      |\n",
      "|    value_loss         | 0.000294      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 115400      |\n",
      "|    time_elapsed       | 5544        |\n",
      "|    total_timesteps    | 577000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -821        |\n",
      "|    explained_variance | -0.709      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 115399      |\n",
      "|    policy_loss        | -82.7       |\n",
      "|    reward             | 0.047524896 |\n",
      "|    std                | 4.97e+11    |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 115500     |\n",
      "|    time_elapsed       | 5549       |\n",
      "|    total_timesteps    | 577500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -822       |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 115499     |\n",
      "|    policy_loss        | -9.04      |\n",
      "|    reward             | -0.0429109 |\n",
      "|    std                | 5.12e+11   |\n",
      "|    value_loss         | 0.00151    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 115600     |\n",
      "|    time_elapsed       | 5554       |\n",
      "|    total_timesteps    | 578000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -823       |\n",
      "|    explained_variance | 0.863      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 115599     |\n",
      "|    policy_loss        | -115       |\n",
      "|    reward             | 0.26843902 |\n",
      "|    std                | 5.27e+11   |\n",
      "|    value_loss         | 0.027      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 115700      |\n",
      "|    time_elapsed       | 5559        |\n",
      "|    total_timesteps    | 578500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -824        |\n",
      "|    explained_variance | 0.681       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 115699      |\n",
      "|    policy_loss        | -229        |\n",
      "|    reward             | -0.20412184 |\n",
      "|    std                | 5.35e+11    |\n",
      "|    value_loss         | 0.0818      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 115800       |\n",
      "|    time_elapsed       | 5563         |\n",
      "|    total_timesteps    | 579000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -824         |\n",
      "|    explained_variance | -0.757       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 115799       |\n",
      "|    policy_loss        | -11.7        |\n",
      "|    reward             | 0.0031180775 |\n",
      "|    std                | 5.44e+11     |\n",
      "|    value_loss         | 0.000402     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 115900       |\n",
      "|    time_elapsed       | 5568         |\n",
      "|    total_timesteps    | 579500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -825         |\n",
      "|    explained_variance | 0.637        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 115899       |\n",
      "|    policy_loss        | 11.8         |\n",
      "|    reward             | -0.008613986 |\n",
      "|    std                | 5.59e+11     |\n",
      "|    value_loss         | 0.000433     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 116000       |\n",
      "|    time_elapsed       | 5573         |\n",
      "|    total_timesteps    | 580000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -826         |\n",
      "|    explained_variance | 0.817        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 115999       |\n",
      "|    policy_loss        | -11.7        |\n",
      "|    reward             | -0.001066747 |\n",
      "|    std                | 5.75e+11     |\n",
      "|    value_loss         | 0.000386     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 116100       |\n",
      "|    time_elapsed       | 5578         |\n",
      "|    total_timesteps    | 580500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -827         |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 116099       |\n",
      "|    policy_loss        | 8.66         |\n",
      "|    reward             | -0.046730373 |\n",
      "|    std                | 5.92e+11     |\n",
      "|    value_loss         | 0.000522     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 116200     |\n",
      "|    time_elapsed       | 5583       |\n",
      "|    total_timesteps    | 581000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -827       |\n",
      "|    explained_variance | 0.0202     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 116199     |\n",
      "|    policy_loss        | -165       |\n",
      "|    reward             | 0.03844973 |\n",
      "|    std                | 6.09e+11   |\n",
      "|    value_loss         | 0.0484     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 116300       |\n",
      "|    time_elapsed       | 5587         |\n",
      "|    total_timesteps    | 581500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -828         |\n",
      "|    explained_variance | -0.281       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 116299       |\n",
      "|    policy_loss        | 254          |\n",
      "|    reward             | 0.0004067906 |\n",
      "|    std                | 6.19e+11     |\n",
      "|    value_loss         | 0.144        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 116400        |\n",
      "|    time_elapsed       | 5592          |\n",
      "|    total_timesteps    | 582000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -828          |\n",
      "|    explained_variance | 0.113         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 116399        |\n",
      "|    policy_loss        | -15.2         |\n",
      "|    reward             | -0.0066274656 |\n",
      "|    std                | 6.32e+11      |\n",
      "|    value_loss         | 0.000374      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 116500       |\n",
      "|    time_elapsed       | 5597         |\n",
      "|    total_timesteps    | 582500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -829         |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 116499       |\n",
      "|    policy_loss        | -29.6        |\n",
      "|    reward             | -0.012671256 |\n",
      "|    std                | 6.47e+11     |\n",
      "|    value_loss         | 0.00162      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 116600        |\n",
      "|    time_elapsed       | 5602          |\n",
      "|    total_timesteps    | 583000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -830          |\n",
      "|    explained_variance | 0.952         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 116599        |\n",
      "|    policy_loss        | 47.6          |\n",
      "|    reward             | -0.0017197856 |\n",
      "|    std                | 6.65e+11      |\n",
      "|    value_loss         | 0.00411       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 116700       |\n",
      "|    time_elapsed       | 5606         |\n",
      "|    total_timesteps    | 583500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -831         |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 116699       |\n",
      "|    policy_loss        | -54.1        |\n",
      "|    reward             | -0.023361553 |\n",
      "|    std                | 6.82e+11     |\n",
      "|    value_loss         | 0.00454      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 116800      |\n",
      "|    time_elapsed       | 5611        |\n",
      "|    total_timesteps    | 584000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -831        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 116799      |\n",
      "|    policy_loss        | -28.5       |\n",
      "|    reward             | 0.014028628 |\n",
      "|    std                | 6.98e+11    |\n",
      "|    value_loss         | 0.00482     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 116900        |\n",
      "|    time_elapsed       | 5616          |\n",
      "|    total_timesteps    | 584500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -832          |\n",
      "|    explained_variance | -0.23         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 116899        |\n",
      "|    policy_loss        | -4.94         |\n",
      "|    reward             | -0.0028851526 |\n",
      "|    std                | 7.07e+11      |\n",
      "|    value_loss         | 6.09e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 117000       |\n",
      "|    time_elapsed       | 5621         |\n",
      "|    total_timesteps    | 585000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -832         |\n",
      "|    explained_variance | 0.103        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 116999       |\n",
      "|    policy_loss        | 14.8         |\n",
      "|    reward             | -0.029107941 |\n",
      "|    std                | 7.23e+11     |\n",
      "|    value_loss         | 0.000588     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 117100     |\n",
      "|    time_elapsed       | 5626       |\n",
      "|    total_timesteps    | 585500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -833       |\n",
      "|    explained_variance | -0.831     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 117099     |\n",
      "|    policy_loss        | -11        |\n",
      "|    reward             | 0.03691814 |\n",
      "|    std                | 7.41e+11   |\n",
      "|    value_loss         | 0.000313   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117200      |\n",
      "|    time_elapsed       | 5630        |\n",
      "|    total_timesteps    | 586000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -834        |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117199      |\n",
      "|    policy_loss        | -5.97       |\n",
      "|    reward             | 0.009447851 |\n",
      "|    std                | 7.62e+11    |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117300      |\n",
      "|    time_elapsed       | 5635        |\n",
      "|    total_timesteps    | 586500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -835        |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117299      |\n",
      "|    policy_loss        | 52.2        |\n",
      "|    reward             | 0.001765208 |\n",
      "|    std                | 7.82e+11    |\n",
      "|    value_loss         | 0.00482     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117400      |\n",
      "|    time_elapsed       | 5640        |\n",
      "|    total_timesteps    | 587000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -835        |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117399      |\n",
      "|    policy_loss        | 48.1        |\n",
      "|    reward             | -0.16128907 |\n",
      "|    std                | 8.01e+11    |\n",
      "|    value_loss         | 0.00432     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 104            |\n",
      "|    iterations         | 117500         |\n",
      "|    time_elapsed       | 5645           |\n",
      "|    total_timesteps    | 587500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -836           |\n",
      "|    explained_variance | 0.331          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 117499         |\n",
      "|    policy_loss        | 23.7           |\n",
      "|    reward             | -0.00018047534 |\n",
      "|    std                | 8.14e+11       |\n",
      "|    value_loss         | 0.000992       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117600      |\n",
      "|    time_elapsed       | 5650        |\n",
      "|    total_timesteps    | 588000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -836        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117599      |\n",
      "|    policy_loss        | 25.2        |\n",
      "|    reward             | 0.024292704 |\n",
      "|    std                | 8.34e+11    |\n",
      "|    value_loss         | 0.00114     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117700      |\n",
      "|    time_elapsed       | 5654        |\n",
      "|    total_timesteps    | 588500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -837        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117699      |\n",
      "|    policy_loss        | -22.1       |\n",
      "|    reward             | -0.06865951 |\n",
      "|    std                | 8.6e+11     |\n",
      "|    value_loss         | 0.000731    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117800      |\n",
      "|    time_elapsed       | 5659        |\n",
      "|    total_timesteps    | 589000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -838        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117799      |\n",
      "|    policy_loss        | 53.7        |\n",
      "|    reward             | 0.024325524 |\n",
      "|    std                | 8.84e+11    |\n",
      "|    value_loss         | 0.00437     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 117900      |\n",
      "|    time_elapsed       | 5664        |\n",
      "|    total_timesteps    | 589500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -839        |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 117899      |\n",
      "|    policy_loss        | -51.3       |\n",
      "|    reward             | 0.027136872 |\n",
      "|    std                | 9.04e+11    |\n",
      "|    value_loss         | 0.005       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 118000       |\n",
      "|    time_elapsed       | 5669         |\n",
      "|    total_timesteps    | 590000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -839         |\n",
      "|    explained_variance | 0.61         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 117999       |\n",
      "|    policy_loss        | 129          |\n",
      "|    reward             | -0.026759075 |\n",
      "|    std                | 9.2e+11      |\n",
      "|    value_loss         | 0.0314       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 118100      |\n",
      "|    time_elapsed       | 5673        |\n",
      "|    total_timesteps    | 590500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -840        |\n",
      "|    explained_variance | 0.73        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 118099      |\n",
      "|    policy_loss        | 5.99        |\n",
      "|    reward             | 0.009305057 |\n",
      "|    std                | 9.34e+11    |\n",
      "|    value_loss         | 7.14e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 118200     |\n",
      "|    time_elapsed       | 5678       |\n",
      "|    total_timesteps    | 591000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -840       |\n",
      "|    explained_variance | 0.538      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 118199     |\n",
      "|    policy_loss        | -48.5      |\n",
      "|    reward             | 0.03610402 |\n",
      "|    std                | 9.57e+11   |\n",
      "|    value_loss         | 0.00361    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 118300     |\n",
      "|    time_elapsed       | 5683       |\n",
      "|    total_timesteps    | 591500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -841       |\n",
      "|    explained_variance | -0.475     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 118299     |\n",
      "|    policy_loss        | 45.4       |\n",
      "|    reward             | 0.03318441 |\n",
      "|    std                | 9.88e+11   |\n",
      "|    value_loss         | 0.00331    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 118400      |\n",
      "|    time_elapsed       | 5688        |\n",
      "|    total_timesteps    | 592000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -842        |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 118399      |\n",
      "|    policy_loss        | 16.8        |\n",
      "|    reward             | 0.008939054 |\n",
      "|    std                | 1.02e+12    |\n",
      "|    value_loss         | 0.000493    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 118500      |\n",
      "|    time_elapsed       | 5693        |\n",
      "|    total_timesteps    | 592500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -843        |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 118499      |\n",
      "|    policy_loss        | 40.3        |\n",
      "|    reward             | 0.115451775 |\n",
      "|    std                | 1.05e+12    |\n",
      "|    value_loss         | 0.00597     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 118600   |\n",
      "|    time_elapsed       | 5697     |\n",
      "|    total_timesteps    | 593000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -844     |\n",
      "|    explained_variance | 0.861    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 118599   |\n",
      "|    policy_loss        | -449     |\n",
      "|    reward             | 0.365127 |\n",
      "|    std                | 1.07e+12 |\n",
      "|    value_loss         | 0.304    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 118700     |\n",
      "|    time_elapsed       | 5702       |\n",
      "|    total_timesteps    | 593500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -844       |\n",
      "|    explained_variance | 0.75       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 118699     |\n",
      "|    policy_loss        | 1.72       |\n",
      "|    reward             | 0.03798125 |\n",
      "|    std                | 1.09e+12   |\n",
      "|    value_loss         | 3.33e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 118800       |\n",
      "|    time_elapsed       | 5707         |\n",
      "|    total_timesteps    | 594000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -845         |\n",
      "|    explained_variance | 0.0224       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 118799       |\n",
      "|    policy_loss        | -43.6        |\n",
      "|    reward             | 0.0005285824 |\n",
      "|    std                | 1.12e+12     |\n",
      "|    value_loss         | 0.00324      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 118900    |\n",
      "|    time_elapsed       | 5712      |\n",
      "|    total_timesteps    | 594500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -846      |\n",
      "|    explained_variance | -0.985    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 118899    |\n",
      "|    policy_loss        | -0.323    |\n",
      "|    reward             | 0.0395533 |\n",
      "|    std                | 1.16e+12  |\n",
      "|    value_loss         | 0.000357  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 119000      |\n",
      "|    time_elapsed       | 5717        |\n",
      "|    total_timesteps    | 595000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -847        |\n",
      "|    explained_variance | -0.0394     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 118999      |\n",
      "|    policy_loss        | 40.4        |\n",
      "|    reward             | -0.18915422 |\n",
      "|    std                | 1.19e+12    |\n",
      "|    value_loss         | 0.00252     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 119100       |\n",
      "|    time_elapsed       | 5722         |\n",
      "|    total_timesteps    | 595500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -848         |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 119099       |\n",
      "|    policy_loss        | -64.3        |\n",
      "|    reward             | -0.014821729 |\n",
      "|    std                | 1.23e+12     |\n",
      "|    value_loss         | 0.00683      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 119200       |\n",
      "|    time_elapsed       | 5726         |\n",
      "|    total_timesteps    | 596000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -848         |\n",
      "|    explained_variance | -0.387       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 119199       |\n",
      "|    policy_loss        | 3.47         |\n",
      "|    reward             | -0.015539662 |\n",
      "|    std                | 1.25e+12     |\n",
      "|    value_loss         | 6.99e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 119300      |\n",
      "|    time_elapsed       | 5731        |\n",
      "|    total_timesteps    | 596500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -849        |\n",
      "|    explained_variance | -10.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 119299      |\n",
      "|    policy_loss        | 19.7        |\n",
      "|    reward             | 0.010101575 |\n",
      "|    std                | 1.27e+12    |\n",
      "|    value_loss         | 0.000606    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 119400      |\n",
      "|    time_elapsed       | 5736        |\n",
      "|    total_timesteps    | 597000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -849        |\n",
      "|    explained_variance | 0.427       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 119399      |\n",
      "|    policy_loss        | -16.9       |\n",
      "|    reward             | -0.07977297 |\n",
      "|    std                | 1.31e+12    |\n",
      "|    value_loss         | 0.000433    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 119500      |\n",
      "|    time_elapsed       | 5741        |\n",
      "|    total_timesteps    | 597500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -850        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 119499      |\n",
      "|    policy_loss        | 19.3        |\n",
      "|    reward             | 0.006777344 |\n",
      "|    std                | 1.35e+12    |\n",
      "|    value_loss         | 0.000622    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 119600     |\n",
      "|    time_elapsed       | 5745       |\n",
      "|    total_timesteps    | 598000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -851       |\n",
      "|    explained_variance | 0.936      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 119599     |\n",
      "|    policy_loss        | -0.298     |\n",
      "|    reward             | 0.08527249 |\n",
      "|    std                | 1.39e+12   |\n",
      "|    value_loss         | 0.000175   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 119700      |\n",
      "|    time_elapsed       | 5750        |\n",
      "|    total_timesteps    | 598500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -852        |\n",
      "|    explained_variance | 0.718       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 119699      |\n",
      "|    policy_loss        | 117         |\n",
      "|    reward             | -0.02113516 |\n",
      "|    std                | 1.42e+12    |\n",
      "|    value_loss         | 0.0254      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 119800        |\n",
      "|    time_elapsed       | 5755          |\n",
      "|    total_timesteps    | 599000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -852          |\n",
      "|    explained_variance | 0.224         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 119799        |\n",
      "|    policy_loss        | 5.3           |\n",
      "|    reward             | -0.0052698664 |\n",
      "|    std                | 1.44e+12      |\n",
      "|    value_loss         | 4.56e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 119900        |\n",
      "|    time_elapsed       | 5760          |\n",
      "|    total_timesteps    | 599500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -853          |\n",
      "|    explained_variance | 0.797         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 119899        |\n",
      "|    policy_loss        | -19.4         |\n",
      "|    reward             | -0.0020424281 |\n",
      "|    std                | 1.47e+12      |\n",
      "|    value_loss         | 0.000673      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 120000       |\n",
      "|    time_elapsed       | 5765         |\n",
      "|    total_timesteps    | 600000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -854         |\n",
      "|    explained_variance | 0.478        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 119999       |\n",
      "|    policy_loss        | -7.82        |\n",
      "|    reward             | -0.012661389 |\n",
      "|    std                | 1.51e+12     |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 120100       |\n",
      "|    time_elapsed       | 5769         |\n",
      "|    total_timesteps    | 600500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -854         |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 120099       |\n",
      "|    policy_loss        | 19.7         |\n",
      "|    reward             | -0.046123736 |\n",
      "|    std                | 1.55e+12     |\n",
      "|    value_loss         | 0.000827     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 120200       |\n",
      "|    time_elapsed       | 5774         |\n",
      "|    total_timesteps    | 601000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -855         |\n",
      "|    explained_variance | 0.675        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 120199       |\n",
      "|    policy_loss        | -17.8        |\n",
      "|    reward             | -0.014016519 |\n",
      "|    std                | 1.59e+12     |\n",
      "|    value_loss         | 0.000854     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 120300      |\n",
      "|    time_elapsed       | 5779        |\n",
      "|    total_timesteps    | 601500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -856        |\n",
      "|    explained_variance | 0.729       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 120299      |\n",
      "|    policy_loss        | -13.9       |\n",
      "|    reward             | -0.01235831 |\n",
      "|    std                | 1.63e+12    |\n",
      "|    value_loss         | 0.00171     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 120400       |\n",
      "|    time_elapsed       | 5784         |\n",
      "|    total_timesteps    | 602000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -856         |\n",
      "|    explained_variance | -13.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 120399       |\n",
      "|    policy_loss        | -5.04        |\n",
      "|    reward             | 0.0028499991 |\n",
      "|    std                | 1.66e+12     |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 120500      |\n",
      "|    time_elapsed       | 5788        |\n",
      "|    total_timesteps    | 602500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -857        |\n",
      "|    explained_variance | 0.635       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 120499      |\n",
      "|    policy_loss        | 4.31        |\n",
      "|    reward             | 0.071940765 |\n",
      "|    std                | 1.69e+12    |\n",
      "|    value_loss         | 0.000899    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 120600      |\n",
      "|    time_elapsed       | 5793        |\n",
      "|    total_timesteps    | 603000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -858        |\n",
      "|    explained_variance | 0.753       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 120599      |\n",
      "|    policy_loss        | -37.6       |\n",
      "|    reward             | 0.015959077 |\n",
      "|    std                | 1.73e+12    |\n",
      "|    value_loss         | 0.00303     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 120700    |\n",
      "|    time_elapsed       | 5798      |\n",
      "|    total_timesteps    | 603500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -858      |\n",
      "|    explained_variance | 0.969     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 120699    |\n",
      "|    policy_loss        | 19.1      |\n",
      "|    reward             | 0.0865611 |\n",
      "|    std                | 1.78e+12  |\n",
      "|    value_loss         | 0.000652  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 120800     |\n",
      "|    time_elapsed       | 5803       |\n",
      "|    total_timesteps    | 604000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -859       |\n",
      "|    explained_variance | 0.649      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 120799     |\n",
      "|    policy_loss        | -0.045     |\n",
      "|    reward             | 0.08290404 |\n",
      "|    std                | 1.82e+12   |\n",
      "|    value_loss         | 0.00282    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 120900      |\n",
      "|    time_elapsed       | 5808        |\n",
      "|    total_timesteps    | 604500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -859        |\n",
      "|    explained_variance | 0.719       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 120899      |\n",
      "|    policy_loss        | 41.3        |\n",
      "|    reward             | 0.033475723 |\n",
      "|    std                | 1.84e+12    |\n",
      "|    value_loss         | 0.0219      |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 210\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 21978003.46\n",
      "total_reward: 11978003.46\n",
      "total_cost: 561457.81\n",
      "total_trades: 82627\n",
      "Sharpe: 0.602\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 121000        |\n",
      "|    time_elapsed       | 5812          |\n",
      "|    total_timesteps    | 605000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -860          |\n",
      "|    explained_variance | 0.602         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 120999        |\n",
      "|    policy_loss        | -31.1         |\n",
      "|    reward             | -0.0011511086 |\n",
      "|    std                | 1.87e+12      |\n",
      "|    value_loss         | 0.00151       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 121100      |\n",
      "|    time_elapsed       | 5817        |\n",
      "|    total_timesteps    | 605500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -860        |\n",
      "|    explained_variance | -17.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 121099      |\n",
      "|    policy_loss        | 64.3        |\n",
      "|    reward             | 0.085954554 |\n",
      "|    std                | 1.91e+12    |\n",
      "|    value_loss         | 0.00748     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 121200      |\n",
      "|    time_elapsed       | 5822        |\n",
      "|    total_timesteps    | 606000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -861        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 121199      |\n",
      "|    policy_loss        | -24.6       |\n",
      "|    reward             | 0.046891373 |\n",
      "|    std                | 1.96e+12    |\n",
      "|    value_loss         | 0.000962    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 121300      |\n",
      "|    time_elapsed       | 5827        |\n",
      "|    total_timesteps    | 606500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -862        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 121299      |\n",
      "|    policy_loss        | -47.8       |\n",
      "|    reward             | 0.027145647 |\n",
      "|    std                | 2.02e+12    |\n",
      "|    value_loss         | 0.00323     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 121400      |\n",
      "|    time_elapsed       | 5832        |\n",
      "|    total_timesteps    | 607000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -863        |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 121399      |\n",
      "|    policy_loss        | -43.7       |\n",
      "|    reward             | 0.082971446 |\n",
      "|    std                | 2.06e+12    |\n",
      "|    value_loss         | 0.00385     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 121500      |\n",
      "|    time_elapsed       | 5837        |\n",
      "|    total_timesteps    | 607500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -863        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 121499      |\n",
      "|    policy_loss        | 35.3        |\n",
      "|    reward             | -0.37336355 |\n",
      "|    std                | 2.09e+12    |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 121600       |\n",
      "|    time_elapsed       | 5842         |\n",
      "|    total_timesteps    | 608000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -864         |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 121599       |\n",
      "|    policy_loss        | 17.8         |\n",
      "|    reward             | -0.022298433 |\n",
      "|    std                | 2.12e+12     |\n",
      "|    value_loss         | 0.000485     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 121700       |\n",
      "|    time_elapsed       | 5846         |\n",
      "|    total_timesteps    | 608500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -864         |\n",
      "|    explained_variance | -0.746       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 121699       |\n",
      "|    policy_loss        | -33          |\n",
      "|    reward             | -0.034124646 |\n",
      "|    std                | 2.18e+12     |\n",
      "|    value_loss         | 0.00165      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 121800       |\n",
      "|    time_elapsed       | 5851         |\n",
      "|    total_timesteps    | 609000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -865         |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 121799       |\n",
      "|    policy_loss        | 5.41         |\n",
      "|    reward             | -0.023171125 |\n",
      "|    std                | 2.24e+12     |\n",
      "|    value_loss         | 9.95e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 121900       |\n",
      "|    time_elapsed       | 5856         |\n",
      "|    total_timesteps    | 609500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -866         |\n",
      "|    explained_variance | -2.18        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 121899       |\n",
      "|    policy_loss        | 42.5         |\n",
      "|    reward             | -0.003278576 |\n",
      "|    std                | 2.31e+12     |\n",
      "|    value_loss         | 0.00427      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 122000      |\n",
      "|    time_elapsed       | 5861        |\n",
      "|    total_timesteps    | 610000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -867        |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 121999      |\n",
      "|    policy_loss        | -56.6       |\n",
      "|    reward             | -0.38949257 |\n",
      "|    std                | 2.36e+12    |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 122100       |\n",
      "|    time_elapsed       | 5866         |\n",
      "|    total_timesteps    | 610500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -867         |\n",
      "|    explained_variance | 0.104        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 122099       |\n",
      "|    policy_loss        | 1.62         |\n",
      "|    reward             | 0.0023866852 |\n",
      "|    std                | 2.39e+12     |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 122200     |\n",
      "|    time_elapsed       | 5871       |\n",
      "|    total_timesteps    | 611000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -868       |\n",
      "|    explained_variance | -0.548     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 122199     |\n",
      "|    policy_loss        | -5.5       |\n",
      "|    reward             | -0.0228451 |\n",
      "|    std                | 2.44e+12   |\n",
      "|    value_loss         | 7.12e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 122300      |\n",
      "|    time_elapsed       | 5876        |\n",
      "|    total_timesteps    | 611500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -868        |\n",
      "|    explained_variance | -0.252      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 122299      |\n",
      "|    policy_loss        | -4.47       |\n",
      "|    reward             | 0.073248304 |\n",
      "|    std                | 2.49e+12    |\n",
      "|    value_loss         | 0.000741    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 122400      |\n",
      "|    time_elapsed       | 5881        |\n",
      "|    total_timesteps    | 612000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -869        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 122399      |\n",
      "|    policy_loss        | -2.14       |\n",
      "|    reward             | 0.022075051 |\n",
      "|    std                | 2.57e+12    |\n",
      "|    value_loss         | 3.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 122500       |\n",
      "|    time_elapsed       | 5886         |\n",
      "|    total_timesteps    | 612500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -870         |\n",
      "|    explained_variance | 0.801        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 122499       |\n",
      "|    policy_loss        | -3.19        |\n",
      "|    reward             | 0.0126721775 |\n",
      "|    std                | 2.64e+12     |\n",
      "|    value_loss         | 0.000186     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 122600     |\n",
      "|    time_elapsed       | 5890       |\n",
      "|    total_timesteps    | 613000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -870       |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 122599     |\n",
      "|    policy_loss        | -30.8      |\n",
      "|    reward             | 0.12556405 |\n",
      "|    std                | 2.7e+12    |\n",
      "|    value_loss         | 0.00166    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 122700       |\n",
      "|    time_elapsed       | 5895         |\n",
      "|    total_timesteps    | 613500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -871         |\n",
      "|    explained_variance | 0.478        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 122699       |\n",
      "|    policy_loss        | 13.3         |\n",
      "|    reward             | -0.010053745 |\n",
      "|    std                | 2.74e+12     |\n",
      "|    value_loss         | 0.000308     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 122800      |\n",
      "|    time_elapsed       | 5901        |\n",
      "|    total_timesteps    | 614000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -872        |\n",
      "|    explained_variance | 0.685       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 122799      |\n",
      "|    policy_loss        | 1.94        |\n",
      "|    reward             | -0.01795048 |\n",
      "|    std                | 2.8e+12     |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 122900      |\n",
      "|    time_elapsed       | 5906        |\n",
      "|    total_timesteps    | 614500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -872        |\n",
      "|    explained_variance | -0.239      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 122899      |\n",
      "|    policy_loss        | 102         |\n",
      "|    reward             | 0.008877197 |\n",
      "|    std                | 2.86e+12    |\n",
      "|    value_loss         | 0.0153      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 123000     |\n",
      "|    time_elapsed       | 5911       |\n",
      "|    total_timesteps    | 615000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -873       |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 122999     |\n",
      "|    policy_loss        | 9.22       |\n",
      "|    reward             | 0.06990352 |\n",
      "|    std                | 2.94e+12   |\n",
      "|    value_loss         | 0.000864   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 123100      |\n",
      "|    time_elapsed       | 5916        |\n",
      "|    total_timesteps    | 615500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -874        |\n",
      "|    explained_variance | 0.606       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 123099      |\n",
      "|    policy_loss        | 27.8        |\n",
      "|    reward             | 0.006401992 |\n",
      "|    std                | 3.02e+12    |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 123200      |\n",
      "|    time_elapsed       | 5920        |\n",
      "|    total_timesteps    | 616000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -874        |\n",
      "|    explained_variance | 0.764       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 123199      |\n",
      "|    policy_loss        | 31.1        |\n",
      "|    reward             | -0.22149251 |\n",
      "|    std                | 3.07e+12    |\n",
      "|    value_loss         | 0.00829     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 123300       |\n",
      "|    time_elapsed       | 5925         |\n",
      "|    total_timesteps    | 616500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -875         |\n",
      "|    explained_variance | -5.08        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 123299       |\n",
      "|    policy_loss        | 2.54         |\n",
      "|    reward             | 0.0031236904 |\n",
      "|    std                | 3.12e+12     |\n",
      "|    value_loss         | 0.000132     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 123400      |\n",
      "|    time_elapsed       | 5930        |\n",
      "|    total_timesteps    | 617000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -875        |\n",
      "|    explained_variance | 0.0858      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 123399      |\n",
      "|    policy_loss        | 11.1        |\n",
      "|    reward             | 0.018853083 |\n",
      "|    std                | 3.19e+12    |\n",
      "|    value_loss         | 0.000451    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 123500      |\n",
      "|    time_elapsed       | 5935        |\n",
      "|    total_timesteps    | 617500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -876        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 123499      |\n",
      "|    policy_loss        | 5.41        |\n",
      "|    reward             | 0.034259558 |\n",
      "|    std                | 3.28e+12    |\n",
      "|    value_loss         | 0.000163    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 123600     |\n",
      "|    time_elapsed       | 5940       |\n",
      "|    total_timesteps    | 618000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -877       |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 123599     |\n",
      "|    policy_loss        | -41.4      |\n",
      "|    reward             | 0.12654673 |\n",
      "|    std                | 3.38e+12   |\n",
      "|    value_loss         | 0.00278    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 123700     |\n",
      "|    time_elapsed       | 5944       |\n",
      "|    total_timesteps    | 618500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -878       |\n",
      "|    explained_variance | 0.585      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 123699     |\n",
      "|    policy_loss        | -84.2      |\n",
      "|    reward             | -0.5066775 |\n",
      "|    std                | 3.46e+12   |\n",
      "|    value_loss         | 0.0178     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 123800     |\n",
      "|    time_elapsed       | 5949       |\n",
      "|    total_timesteps    | 619000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -878       |\n",
      "|    explained_variance | 0.918      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 123799     |\n",
      "|    policy_loss        | -58.9      |\n",
      "|    reward             | 0.28701243 |\n",
      "|    std                | 3.52e+12   |\n",
      "|    value_loss         | 0.00797    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 123900      |\n",
      "|    time_elapsed       | 5954        |\n",
      "|    total_timesteps    | 619500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -879        |\n",
      "|    explained_variance | 0.19        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 123899      |\n",
      "|    policy_loss        | 23.8        |\n",
      "|    reward             | -0.01038317 |\n",
      "|    std                | 3.58e+12    |\n",
      "|    value_loss         | 0.0012      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 124000     |\n",
      "|    time_elapsed       | 5959       |\n",
      "|    total_timesteps    | 620000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -879       |\n",
      "|    explained_variance | 0.887      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 123999     |\n",
      "|    policy_loss        | -24.5      |\n",
      "|    reward             | 0.06945573 |\n",
      "|    std                | 3.67e+12   |\n",
      "|    value_loss         | 0.000889   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 124100      |\n",
      "|    time_elapsed       | 5963        |\n",
      "|    total_timesteps    | 620500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -880        |\n",
      "|    explained_variance | -1.6        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 124099      |\n",
      "|    policy_loss        | -22.9       |\n",
      "|    reward             | 0.010713165 |\n",
      "|    std                | 3.78e+12    |\n",
      "|    value_loss         | 0.000843    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 124200      |\n",
      "|    time_elapsed       | 5968        |\n",
      "|    total_timesteps    | 621000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -881        |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 124199      |\n",
      "|    policy_loss        | 34.2        |\n",
      "|    reward             | 0.015738241 |\n",
      "|    std                | 3.9e+12     |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 124300      |\n",
      "|    time_elapsed       | 5973        |\n",
      "|    total_timesteps    | 621500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -882        |\n",
      "|    explained_variance | -0.0918     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 124299      |\n",
      "|    policy_loss        | -21.3       |\n",
      "|    reward             | 0.014915906 |\n",
      "|    std                | 3.99e+12    |\n",
      "|    value_loss         | 0.00388     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 124400        |\n",
      "|    time_elapsed       | 5978          |\n",
      "|    total_timesteps    | 622000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -882          |\n",
      "|    explained_variance | 0.681         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 124399        |\n",
      "|    policy_loss        | 104           |\n",
      "|    reward             | -0.0032165607 |\n",
      "|    std                | 4.06e+12      |\n",
      "|    value_loss         | 0.0265        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 124500        |\n",
      "|    time_elapsed       | 5983          |\n",
      "|    total_timesteps    | 622500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -883          |\n",
      "|    explained_variance | -1.76         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 124499        |\n",
      "|    policy_loss        | -14.6         |\n",
      "|    reward             | -0.0036962219 |\n",
      "|    std                | 4.14e+12      |\n",
      "|    value_loss         | 0.000394      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 124600      |\n",
      "|    time_elapsed       | 5987        |\n",
      "|    total_timesteps    | 623000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -884        |\n",
      "|    explained_variance | 0.751       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 124599      |\n",
      "|    policy_loss        | -5.61       |\n",
      "|    reward             | 0.064166024 |\n",
      "|    std                | 4.26e+12    |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 124700      |\n",
      "|    time_elapsed       | 5992        |\n",
      "|    total_timesteps    | 623500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -885        |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 124699      |\n",
      "|    policy_loss        | 2.11        |\n",
      "|    reward             | 0.014172417 |\n",
      "|    std                | 4.41e+12    |\n",
      "|    value_loss         | 0.000563    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 124800       |\n",
      "|    time_elapsed       | 5997         |\n",
      "|    total_timesteps    | 624000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -886         |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 124799       |\n",
      "|    policy_loss        | -8.03        |\n",
      "|    reward             | -0.004130507 |\n",
      "|    std                | 4.54e+12     |\n",
      "|    value_loss         | 0.000794     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 124900      |\n",
      "|    time_elapsed       | 6002        |\n",
      "|    total_timesteps    | 624500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -886        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 124899      |\n",
      "|    policy_loss        | -108        |\n",
      "|    reward             | -0.39158174 |\n",
      "|    std                | 4.65e+12    |\n",
      "|    value_loss         | 0.016       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 125000       |\n",
      "|    time_elapsed       | 6007         |\n",
      "|    total_timesteps    | 625000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -887         |\n",
      "|    explained_variance | -1.16        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 124999       |\n",
      "|    policy_loss        | 8.03         |\n",
      "|    reward             | -0.017511806 |\n",
      "|    std                | 4.71e+12     |\n",
      "|    value_loss         | 0.000183     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 125100       |\n",
      "|    time_elapsed       | 6012         |\n",
      "|    total_timesteps    | 625500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -887         |\n",
      "|    explained_variance | 0.482        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 125099       |\n",
      "|    policy_loss        | -12.8        |\n",
      "|    reward             | -0.007461555 |\n",
      "|    std                | 4.81e+12     |\n",
      "|    value_loss         | 0.000274     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 125200      |\n",
      "|    time_elapsed       | 6016        |\n",
      "|    total_timesteps    | 626000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -888        |\n",
      "|    explained_variance | 0.683       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 125199      |\n",
      "|    policy_loss        | -5.4        |\n",
      "|    reward             | -0.05326403 |\n",
      "|    std                | 4.95e+12    |\n",
      "|    value_loss         | 7.25e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 125300      |\n",
      "|    time_elapsed       | 6021        |\n",
      "|    total_timesteps    | 626500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -889        |\n",
      "|    explained_variance | 0.316       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 125299      |\n",
      "|    policy_loss        | 3.44        |\n",
      "|    reward             | 0.017594265 |\n",
      "|    std                | 5.1e+12     |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 125400      |\n",
      "|    time_elapsed       | 6026        |\n",
      "|    total_timesteps    | 627000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -890        |\n",
      "|    explained_variance | 0.156       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 125399      |\n",
      "|    policy_loss        | 130         |\n",
      "|    reward             | 0.029798323 |\n",
      "|    std                | 5.23e+12    |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 125500     |\n",
      "|    time_elapsed       | 6031       |\n",
      "|    total_timesteps    | 627500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -890       |\n",
      "|    explained_variance | 0.502      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 125499     |\n",
      "|    policy_loss        | -76.6      |\n",
      "|    reward             | 0.07625419 |\n",
      "|    std                | 5.34e+12   |\n",
      "|    value_loss         | 0.0158     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 125600      |\n",
      "|    time_elapsed       | 6036        |\n",
      "|    total_timesteps    | 628000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -891        |\n",
      "|    explained_variance | 0.476       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 125599      |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | 0.004881711 |\n",
      "|    std                | 5.41e+12    |\n",
      "|    value_loss         | 0.000194    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 125700      |\n",
      "|    time_elapsed       | 6041        |\n",
      "|    total_timesteps    | 628500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -891        |\n",
      "|    explained_variance | -0.259      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 125699      |\n",
      "|    policy_loss        | 67.1        |\n",
      "|    reward             | 0.024012735 |\n",
      "|    std                | 5.54e+12    |\n",
      "|    value_loss         | 0.00642     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 125800        |\n",
      "|    time_elapsed       | 6045          |\n",
      "|    total_timesteps    | 629000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -892          |\n",
      "|    explained_variance | 0.885         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 125799        |\n",
      "|    policy_loss        | 8.39          |\n",
      "|    reward             | -0.0128939105 |\n",
      "|    std                | 5.71e+12      |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 125900      |\n",
      "|    time_elapsed       | 6050        |\n",
      "|    total_timesteps    | 629500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -893        |\n",
      "|    explained_variance | 0.757       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 125899      |\n",
      "|    policy_loss        | 0.466       |\n",
      "|    reward             | -0.04093806 |\n",
      "|    std                | 5.88e+12    |\n",
      "|    value_loss         | 0.000334    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 126000       |\n",
      "|    time_elapsed       | 6055         |\n",
      "|    total_timesteps    | 630000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -894         |\n",
      "|    explained_variance | -0.123       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 125999       |\n",
      "|    policy_loss        | 34.2         |\n",
      "|    reward             | -0.059055578 |\n",
      "|    std                | 6.05e+12     |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 126100      |\n",
      "|    time_elapsed       | 6060        |\n",
      "|    total_timesteps    | 630500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -894        |\n",
      "|    explained_variance | 0.536       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 126099      |\n",
      "|    policy_loss        | 198         |\n",
      "|    reward             | -0.06461849 |\n",
      "|    std                | 6.16e+12    |\n",
      "|    value_loss         | 0.0555      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 126200        |\n",
      "|    time_elapsed       | 6065          |\n",
      "|    total_timesteps    | 631000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -895          |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 126199        |\n",
      "|    policy_loss        | 12.3          |\n",
      "|    reward             | -0.0030163308 |\n",
      "|    std                | 6.26e+12      |\n",
      "|    value_loss         | 0.000192      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 126300      |\n",
      "|    time_elapsed       | 6069        |\n",
      "|    total_timesteps    | 631500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -896        |\n",
      "|    explained_variance | 0.401       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 126299      |\n",
      "|    policy_loss        | -6.27       |\n",
      "|    reward             | -0.04185439 |\n",
      "|    std                | 6.41e+12    |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 126400      |\n",
      "|    time_elapsed       | 6074        |\n",
      "|    total_timesteps    | 632000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -896        |\n",
      "|    explained_variance | 0.368       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 126399      |\n",
      "|    policy_loss        | 0.222       |\n",
      "|    reward             | -0.09805473 |\n",
      "|    std                | 6.6e+12     |\n",
      "|    value_loss         | 0.000882    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 126500     |\n",
      "|    time_elapsed       | 6079       |\n",
      "|    total_timesteps    | 632500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -897       |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 126499     |\n",
      "|    policy_loss        | -13.5      |\n",
      "|    reward             | 0.06676067 |\n",
      "|    std                | 6.81e+12   |\n",
      "|    value_loss         | 0.000253   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 126600      |\n",
      "|    time_elapsed       | 6084        |\n",
      "|    total_timesteps    | 633000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -898        |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 126599      |\n",
      "|    policy_loss        | -160        |\n",
      "|    reward             | -0.29074246 |\n",
      "|    std                | 6.95e+12    |\n",
      "|    value_loss         | 0.0399      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 126700    |\n",
      "|    time_elapsed       | 6089      |\n",
      "|    total_timesteps    | 633500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -898      |\n",
      "|    explained_variance | 0.978     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 126699    |\n",
      "|    policy_loss        | 49.9      |\n",
      "|    reward             | 1.1178689 |\n",
      "|    std                | 7.05e+12  |\n",
      "|    value_loss         | 0.0253    |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16989847.20\n",
      "total_reward: 6989847.20\n",
      "total_cost: 559663.59\n",
      "total_trades: 82476\n",
      "Sharpe: 0.448\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 126800        |\n",
      "|    time_elapsed       | 6093          |\n",
      "|    total_timesteps    | 634000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -899          |\n",
      "|    explained_variance | 0.953         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 126799        |\n",
      "|    policy_loss        | 9.12          |\n",
      "|    reward             | -0.0045088753 |\n",
      "|    std                | 7.16e+12      |\n",
      "|    value_loss         | 0.000109      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 126900      |\n",
      "|    time_elapsed       | 6098        |\n",
      "|    total_timesteps    | 634500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -899        |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 126899      |\n",
      "|    policy_loss        | -3.62       |\n",
      "|    reward             | 0.008254721 |\n",
      "|    std                | 7.32e+12    |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 127000      |\n",
      "|    time_elapsed       | 6103        |\n",
      "|    total_timesteps    | 635000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -900        |\n",
      "|    explained_variance | 0.177       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 126999      |\n",
      "|    policy_loss        | -10.2       |\n",
      "|    reward             | -0.01646839 |\n",
      "|    std                | 7.53e+12    |\n",
      "|    value_loss         | 0.000201    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 127100       |\n",
      "|    time_elapsed       | 6108         |\n",
      "|    total_timesteps    | 635500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -901         |\n",
      "|    explained_variance | -0.00956     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 127099       |\n",
      "|    policy_loss        | 23.5         |\n",
      "|    reward             | 0.0019609088 |\n",
      "|    std                | 7.75e+12     |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 127200       |\n",
      "|    time_elapsed       | 6113         |\n",
      "|    total_timesteps    | 636000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -902         |\n",
      "|    explained_variance | 0.715        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 127199       |\n",
      "|    policy_loss        | 52.5         |\n",
      "|    reward             | -0.022767862 |\n",
      "|    std                | 7.95e+12     |\n",
      "|    value_loss         | 0.00367      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 127300        |\n",
      "|    time_elapsed       | 6118          |\n",
      "|    total_timesteps    | 636500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -902          |\n",
      "|    explained_variance | 0.19          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 127299        |\n",
      "|    policy_loss        | -9.01         |\n",
      "|    reward             | -0.0024743504 |\n",
      "|    std                | 8.08e+12      |\n",
      "|    value_loss         | 0.000185      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 127400       |\n",
      "|    time_elapsed       | 6122         |\n",
      "|    total_timesteps    | 637000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -903         |\n",
      "|    explained_variance | -0.785       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 127399       |\n",
      "|    policy_loss        | 8.84         |\n",
      "|    reward             | 0.0025689236 |\n",
      "|    std                | 8.26e+12     |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 127500      |\n",
      "|    time_elapsed       | 6127        |\n",
      "|    total_timesteps    | 637500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -904        |\n",
      "|    explained_variance | 0.525       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 127499      |\n",
      "|    policy_loss        | 0.923       |\n",
      "|    reward             | -0.02218482 |\n",
      "|    std                | 8.49e+12    |\n",
      "|    value_loss         | 3.96e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 127600       |\n",
      "|    time_elapsed       | 6132         |\n",
      "|    total_timesteps    | 638000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -905         |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 127599       |\n",
      "|    policy_loss        | 1.63         |\n",
      "|    reward             | 0.0014505498 |\n",
      "|    std                | 8.78e+12     |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 127700     |\n",
      "|    time_elapsed       | 6137       |\n",
      "|    total_timesteps    | 638500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -906       |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 127699     |\n",
      "|    policy_loss        | -9.04      |\n",
      "|    reward             | 0.04930223 |\n",
      "|    std                | 9.04e+12   |\n",
      "|    value_loss         | 0.000128   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 127800        |\n",
      "|    time_elapsed       | 6142          |\n",
      "|    total_timesteps    | 639000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -906          |\n",
      "|    explained_variance | 0.405         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 127799        |\n",
      "|    policy_loss        | -73.2         |\n",
      "|    reward             | -0.0049141333 |\n",
      "|    std                | 9.23e+12      |\n",
      "|    value_loss         | 0.00826       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 127900       |\n",
      "|    time_elapsed       | 6146         |\n",
      "|    total_timesteps    | 639500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -907         |\n",
      "|    explained_variance | 0.0379       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 127899       |\n",
      "|    policy_loss        | 8.53         |\n",
      "|    reward             | 0.0035119408 |\n",
      "|    std                | 9.35e+12     |\n",
      "|    value_loss         | 0.000177     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 128000       |\n",
      "|    time_elapsed       | 6151         |\n",
      "|    total_timesteps    | 640000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -907         |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 127999       |\n",
      "|    policy_loss        | 11.5         |\n",
      "|    reward             | 0.0007875771 |\n",
      "|    std                | 9.55e+12     |\n",
      "|    value_loss         | 0.000187     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 128100      |\n",
      "|    time_elapsed       | 6156        |\n",
      "|    total_timesteps    | 640500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -908        |\n",
      "|    explained_variance | 0.392       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 128099      |\n",
      "|    policy_loss        | 15          |\n",
      "|    reward             | 0.025064794 |\n",
      "|    std                | 9.81e+12    |\n",
      "|    value_loss         | 0.000354    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 128200       |\n",
      "|    time_elapsed       | 6161         |\n",
      "|    total_timesteps    | 641000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -909         |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 128199       |\n",
      "|    policy_loss        | 4.88         |\n",
      "|    reward             | -0.052296504 |\n",
      "|    std                | 1.01e+13     |\n",
      "|    value_loss         | 0.000284     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 128300     |\n",
      "|    time_elapsed       | 6165       |\n",
      "|    total_timesteps    | 641500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -910       |\n",
      "|    explained_variance | -0.0403    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 128299     |\n",
      "|    policy_loss        | 63.1       |\n",
      "|    reward             | 0.03973417 |\n",
      "|    std                | 1.04e+13   |\n",
      "|    value_loss         | 0.00579    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 128400     |\n",
      "|    time_elapsed       | 6170       |\n",
      "|    total_timesteps    | 642000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -910       |\n",
      "|    explained_variance | 0.923      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 128399     |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | 0.13457024 |\n",
      "|    std                | 1.07e+13   |\n",
      "|    value_loss         | 0.00935    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 128500        |\n",
      "|    time_elapsed       | 6175          |\n",
      "|    total_timesteps    | 642500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -911          |\n",
      "|    explained_variance | 0.767         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 128499        |\n",
      "|    policy_loss        | 7.06          |\n",
      "|    reward             | -0.0013235458 |\n",
      "|    std                | 1.08e+13      |\n",
      "|    value_loss         | 6.32e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 128600      |\n",
      "|    time_elapsed       | 6180        |\n",
      "|    total_timesteps    | 643000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -911        |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 128599      |\n",
      "|    policy_loss        | 43.9        |\n",
      "|    reward             | 0.035799325 |\n",
      "|    std                | 1.11e+13    |\n",
      "|    value_loss         | 0.00234     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 128700     |\n",
      "|    time_elapsed       | 6185       |\n",
      "|    total_timesteps    | 643500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -912       |\n",
      "|    explained_variance | 0.57       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 128699     |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | 0.05533314 |\n",
      "|    std                | 1.14e+13   |\n",
      "|    value_loss         | 0.000569   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 128800      |\n",
      "|    time_elapsed       | 6189        |\n",
      "|    total_timesteps    | 644000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -913        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 128799      |\n",
      "|    policy_loss        | 43.9        |\n",
      "|    reward             | 0.082081154 |\n",
      "|    std                | 1.17e+13    |\n",
      "|    value_loss         | 0.00284     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 128900      |\n",
      "|    time_elapsed       | 6194        |\n",
      "|    total_timesteps    | 644500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -914        |\n",
      "|    explained_variance | 0.709       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 128899      |\n",
      "|    policy_loss        | -21         |\n",
      "|    reward             | -0.10293308 |\n",
      "|    std                | 1.2e+13     |\n",
      "|    value_loss         | 0.00229     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 129000      |\n",
      "|    time_elapsed       | 6199        |\n",
      "|    total_timesteps    | 645000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -914        |\n",
      "|    explained_variance | 0.655       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 128999      |\n",
      "|    policy_loss        | -178        |\n",
      "|    reward             | 0.021335458 |\n",
      "|    std                | 1.22e+13    |\n",
      "|    value_loss         | 0.0619      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 129100    |\n",
      "|    time_elapsed       | 6204      |\n",
      "|    total_timesteps    | 645500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -915      |\n",
      "|    explained_variance | 0.613     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 129099    |\n",
      "|    policy_loss        | -16.6     |\n",
      "|    reward             | 0.0400283 |\n",
      "|    std                | 1.23e+13  |\n",
      "|    value_loss         | 0.000467  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 129200      |\n",
      "|    time_elapsed       | 6209        |\n",
      "|    total_timesteps    | 646000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -915        |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 129199      |\n",
      "|    policy_loss        | 1.96        |\n",
      "|    reward             | -0.00980923 |\n",
      "|    std                | 1.26e+13    |\n",
      "|    value_loss         | 5.82e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 129300      |\n",
      "|    time_elapsed       | 6213        |\n",
      "|    total_timesteps    | 646500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -916        |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 129299      |\n",
      "|    policy_loss        | 4.06        |\n",
      "|    reward             | 0.009180338 |\n",
      "|    std                | 1.29e+13    |\n",
      "|    value_loss         | 0.000197    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 129400    |\n",
      "|    time_elapsed       | 6218      |\n",
      "|    total_timesteps    | 647000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -917      |\n",
      "|    explained_variance | 0.839     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 129399    |\n",
      "|    policy_loss        | -29.2     |\n",
      "|    reward             | 0.1097443 |\n",
      "|    std                | 1.32e+13  |\n",
      "|    value_loss         | 0.00212   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 129500     |\n",
      "|    time_elapsed       | 6223       |\n",
      "|    total_timesteps    | 647500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -917       |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 129499     |\n",
      "|    policy_loss        | -80.8      |\n",
      "|    reward             | 0.30126452 |\n",
      "|    std                | 1.35e+13   |\n",
      "|    value_loss         | 0.00966    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 129600     |\n",
      "|    time_elapsed       | 6228       |\n",
      "|    total_timesteps    | 648000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -918       |\n",
      "|    explained_variance | 0.18       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 129599     |\n",
      "|    policy_loss        | -224       |\n",
      "|    reward             | 0.10338291 |\n",
      "|    std                | 1.37e+13   |\n",
      "|    value_loss         | 0.066      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 129700       |\n",
      "|    time_elapsed       | 6233         |\n",
      "|    total_timesteps    | 648500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -918         |\n",
      "|    explained_variance | 0.188        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 129699       |\n",
      "|    policy_loss        | -21.2        |\n",
      "|    reward             | 0.0103518665 |\n",
      "|    std                | 1.39e+13     |\n",
      "|    value_loss         | 0.000575     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 129800     |\n",
      "|    time_elapsed       | 6237       |\n",
      "|    total_timesteps    | 649000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -919       |\n",
      "|    explained_variance | 0.582      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 129799     |\n",
      "|    policy_loss        | 27.8       |\n",
      "|    reward             | 0.03366274 |\n",
      "|    std                | 1.42e+13   |\n",
      "|    value_loss         | 0.00135    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 129900      |\n",
      "|    time_elapsed       | 6242        |\n",
      "|    total_timesteps    | 649500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -920        |\n",
      "|    explained_variance | 0.391       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 129899      |\n",
      "|    policy_loss        | -58.6       |\n",
      "|    reward             | 0.076751605 |\n",
      "|    std                | 1.46e+13    |\n",
      "|    value_loss         | 0.00483     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 130000       |\n",
      "|    time_elapsed       | 6247         |\n",
      "|    total_timesteps    | 650000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -920         |\n",
      "|    explained_variance | 0.774        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 129999       |\n",
      "|    policy_loss        | -5.97        |\n",
      "|    reward             | 0.0032749362 |\n",
      "|    std                | 1.5e+13      |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 130100      |\n",
      "|    time_elapsed       | 6252        |\n",
      "|    total_timesteps    | 650500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -921        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 130099      |\n",
      "|    policy_loss        | -126        |\n",
      "|    reward             | -0.07390768 |\n",
      "|    std                | 1.53e+13    |\n",
      "|    value_loss         | 0.0233      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 130200       |\n",
      "|    time_elapsed       | 6257         |\n",
      "|    total_timesteps    | 651000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -921         |\n",
      "|    explained_variance | 0.23         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 130199       |\n",
      "|    policy_loss        | -3.86        |\n",
      "|    reward             | -0.006272328 |\n",
      "|    std                | 1.56e+13     |\n",
      "|    value_loss         | 0.000156     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 130300       |\n",
      "|    time_elapsed       | 6261         |\n",
      "|    total_timesteps    | 651500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -922         |\n",
      "|    explained_variance | -0.148       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 130299       |\n",
      "|    policy_loss        | -14.3        |\n",
      "|    reward             | -0.018001994 |\n",
      "|    std                | 1.6e+13      |\n",
      "|    value_loss         | 0.000329     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 130400      |\n",
      "|    time_elapsed       | 6266        |\n",
      "|    total_timesteps    | 652000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -923        |\n",
      "|    explained_variance | 0.503       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 130399      |\n",
      "|    policy_loss        | 10.5        |\n",
      "|    reward             | 0.016679123 |\n",
      "|    std                | 1.64e+13    |\n",
      "|    value_loss         | 0.000491    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 130500      |\n",
      "|    time_elapsed       | 6271        |\n",
      "|    total_timesteps    | 652500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -924        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 130499      |\n",
      "|    policy_loss        | 25.9        |\n",
      "|    reward             | 0.042314652 |\n",
      "|    std                | 1.68e+13    |\n",
      "|    value_loss         | 0.00175     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 130600      |\n",
      "|    time_elapsed       | 6276        |\n",
      "|    total_timesteps    | 653000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -924        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 130599      |\n",
      "|    policy_loss        | -57.6       |\n",
      "|    reward             | -0.03860806 |\n",
      "|    std                | 1.72e+13    |\n",
      "|    value_loss         | 0.00459     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 130700     |\n",
      "|    time_elapsed       | 6281       |\n",
      "|    total_timesteps    | 653500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -925       |\n",
      "|    explained_variance | 0.877      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 130699     |\n",
      "|    policy_loss        | 116        |\n",
      "|    reward             | 0.08885092 |\n",
      "|    std                | 1.75e+13   |\n",
      "|    value_loss         | 0.0162     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 130800      |\n",
      "|    time_elapsed       | 6285        |\n",
      "|    total_timesteps    | 654000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -925        |\n",
      "|    explained_variance | 0.218       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 130799      |\n",
      "|    policy_loss        | -13.1       |\n",
      "|    reward             | -0.01563398 |\n",
      "|    std                | 1.78e+13    |\n",
      "|    value_loss         | 0.000328    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 130900      |\n",
      "|    time_elapsed       | 6290        |\n",
      "|    total_timesteps    | 654500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -926        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 130899      |\n",
      "|    policy_loss        | -35.1       |\n",
      "|    reward             | 0.018844828 |\n",
      "|    std                | 1.82e+13    |\n",
      "|    value_loss         | 0.00147     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 131000     |\n",
      "|    time_elapsed       | 6295       |\n",
      "|    total_timesteps    | 655000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -927       |\n",
      "|    explained_variance | -1.9       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 130999     |\n",
      "|    policy_loss        | 34.6       |\n",
      "|    reward             | 0.02773363 |\n",
      "|    std                | 1.86e+13   |\n",
      "|    value_loss         | 0.00413    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 131100       |\n",
      "|    time_elapsed       | 6300         |\n",
      "|    total_timesteps    | 655500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -927         |\n",
      "|    explained_variance | 0.954        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 131099       |\n",
      "|    policy_loss        | -53.8        |\n",
      "|    reward             | -0.089922756 |\n",
      "|    std                | 1.91e+13     |\n",
      "|    value_loss         | 0.00427      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 131200      |\n",
      "|    time_elapsed       | 6304        |\n",
      "|    total_timesteps    | 656000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -928        |\n",
      "|    explained_variance | 0.507       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 131199      |\n",
      "|    policy_loss        | 15          |\n",
      "|    reward             | 0.020676104 |\n",
      "|    std                | 1.96e+13    |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 131300     |\n",
      "|    time_elapsed       | 6309       |\n",
      "|    total_timesteps    | 656500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -929       |\n",
      "|    explained_variance | 0.87       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 131299     |\n",
      "|    policy_loss        | 29.6       |\n",
      "|    reward             | 0.20538352 |\n",
      "|    std                | 2e+13      |\n",
      "|    value_loss         | 0.00343    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 131400       |\n",
      "|    time_elapsed       | 6314         |\n",
      "|    total_timesteps    | 657000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -929         |\n",
      "|    explained_variance | 0.0384       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 131399       |\n",
      "|    policy_loss        | -15.6        |\n",
      "|    reward             | 0.0019431399 |\n",
      "|    std                | 2.03e+13     |\n",
      "|    value_loss         | 0.000478     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 131500      |\n",
      "|    time_elapsed       | 6319        |\n",
      "|    total_timesteps    | 657500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -930        |\n",
      "|    explained_variance | -3.5        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 131499      |\n",
      "|    policy_loss        | -4.55       |\n",
      "|    reward             | 0.001938334 |\n",
      "|    std                | 2.08e+13    |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 131600        |\n",
      "|    time_elapsed       | 6324          |\n",
      "|    total_timesteps    | 658000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -930          |\n",
      "|    explained_variance | -2.22         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 131599        |\n",
      "|    policy_loss        | -187          |\n",
      "|    reward             | -0.0033722634 |\n",
      "|    std                | 2.13e+13      |\n",
      "|    value_loss         | 0.0521        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 131700      |\n",
      "|    time_elapsed       | 6329        |\n",
      "|    total_timesteps    | 658500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -931        |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 131699      |\n",
      "|    policy_loss        | 2.87        |\n",
      "|    reward             | -0.12540975 |\n",
      "|    std                | 2.19e+13    |\n",
      "|    value_loss         | 0.000815    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 131800     |\n",
      "|    time_elapsed       | 6333       |\n",
      "|    total_timesteps    | 659000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -932       |\n",
      "|    explained_variance | 0.312      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 131799     |\n",
      "|    policy_loss        | -97.7      |\n",
      "|    reward             | 0.26106006 |\n",
      "|    std                | 2.25e+13   |\n",
      "|    value_loss         | 0.0162     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 131900     |\n",
      "|    time_elapsed       | 6338       |\n",
      "|    total_timesteps    | 659500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -933       |\n",
      "|    explained_variance | -3.97      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 131899     |\n",
      "|    policy_loss        | -109       |\n",
      "|    reward             | 0.08394379 |\n",
      "|    std                | 2.29e+13   |\n",
      "|    value_loss         | 0.0346     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 132000       |\n",
      "|    time_elapsed       | 6343         |\n",
      "|    total_timesteps    | 660000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -933         |\n",
      "|    explained_variance | 0.555        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 131999       |\n",
      "|    policy_loss        | 24           |\n",
      "|    reward             | 0.0033168881 |\n",
      "|    std                | 2.33e+13     |\n",
      "|    value_loss         | 0.000756     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 132100       |\n",
      "|    time_elapsed       | 6348         |\n",
      "|    total_timesteps    | 660500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -934         |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 132099       |\n",
      "|    policy_loss        | -4.7         |\n",
      "|    reward             | -0.015150587 |\n",
      "|    std                | 2.39e+13     |\n",
      "|    value_loss         | 8.38e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 132200      |\n",
      "|    time_elapsed       | 6353        |\n",
      "|    total_timesteps    | 661000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -935        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 132199      |\n",
      "|    policy_loss        | -2.5        |\n",
      "|    reward             | 0.026885517 |\n",
      "|    std                | 2.46e+13    |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 132300       |\n",
      "|    time_elapsed       | 6358         |\n",
      "|    total_timesteps    | 661500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -935         |\n",
      "|    explained_variance | 0.431        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 132299       |\n",
      "|    policy_loss        | 0.826        |\n",
      "|    reward             | -0.006557359 |\n",
      "|    std                | 2.53e+13     |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 132400       |\n",
      "|    time_elapsed       | 6362         |\n",
      "|    total_timesteps    | 662000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -936         |\n",
      "|    explained_variance | 0.69         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 132399       |\n",
      "|    policy_loss        | -93.7        |\n",
      "|    reward             | -0.097142465 |\n",
      "|    std                | 2.6e+13      |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17840874.61\n",
      "total_reward: 7840874.61\n",
      "total_cost: 561365.70\n",
      "total_trades: 82738\n",
      "Sharpe: 0.463\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 132500        |\n",
      "|    time_elapsed       | 6367          |\n",
      "|    total_timesteps    | 662500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -937          |\n",
      "|    explained_variance | 0.726         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 132499        |\n",
      "|    policy_loss        | 0.299         |\n",
      "|    reward             | -0.0025747733 |\n",
      "|    std                | 2.64e+13      |\n",
      "|    value_loss         | 0.0419        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 132600       |\n",
      "|    time_elapsed       | 6372         |\n",
      "|    total_timesteps    | 663000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -937         |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 132599       |\n",
      "|    policy_loss        | 8.4          |\n",
      "|    reward             | 0.0016853369 |\n",
      "|    std                | 2.69e+13     |\n",
      "|    value_loss         | 9.68e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 132700       |\n",
      "|    time_elapsed       | 6377         |\n",
      "|    total_timesteps    | 663500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -938         |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 132699       |\n",
      "|    policy_loss        | 7.65         |\n",
      "|    reward             | -0.005097299 |\n",
      "|    std                | 2.76e+13     |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 132800      |\n",
      "|    time_elapsed       | 6382        |\n",
      "|    total_timesteps    | 664000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -939        |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 132799      |\n",
      "|    policy_loss        | -17.8       |\n",
      "|    reward             | 0.022442516 |\n",
      "|    std                | 2.84e+13    |\n",
      "|    value_loss         | 0.000669    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 132900     |\n",
      "|    time_elapsed       | 6386       |\n",
      "|    total_timesteps    | 664500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -939       |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 132899     |\n",
      "|    policy_loss        | -31.6      |\n",
      "|    reward             | 0.05834811 |\n",
      "|    std                | 2.91e+13   |\n",
      "|    value_loss         | 0.00121    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 133000     |\n",
      "|    time_elapsed       | 6391       |\n",
      "|    total_timesteps    | 665000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -940       |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 132999     |\n",
      "|    policy_loss        | -69.3      |\n",
      "|    reward             | 0.16739592 |\n",
      "|    std                | 2.97e+13   |\n",
      "|    value_loss         | 0.0121     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 133100       |\n",
      "|    time_elapsed       | 6396         |\n",
      "|    total_timesteps    | 665500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -940         |\n",
      "|    explained_variance | -2.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 133099       |\n",
      "|    policy_loss        | 15.7         |\n",
      "|    reward             | -0.008674465 |\n",
      "|    std                | 3.01e+13     |\n",
      "|    value_loss         | 0.000483     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 133200       |\n",
      "|    time_elapsed       | 6401         |\n",
      "|    total_timesteps    | 666000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -941         |\n",
      "|    explained_variance | 0.792        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 133199       |\n",
      "|    policy_loss        | -2.42        |\n",
      "|    reward             | -0.009206311 |\n",
      "|    std                | 3.07e+13     |\n",
      "|    value_loss         | 1.6e-05      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 133300     |\n",
      "|    time_elapsed       | 6405       |\n",
      "|    total_timesteps    | 666500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -942       |\n",
      "|    explained_variance | -0.147     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 133299     |\n",
      "|    policy_loss        | -41.1      |\n",
      "|    reward             | 0.03162221 |\n",
      "|    std                | 3.15e+13   |\n",
      "|    value_loss         | 0.00226    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 133400       |\n",
      "|    time_elapsed       | 6410         |\n",
      "|    total_timesteps    | 667000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -943         |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 133399       |\n",
      "|    policy_loss        | -30.3        |\n",
      "|    reward             | -0.029271513 |\n",
      "|    std                | 3.25e+13     |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 133500      |\n",
      "|    time_elapsed       | 6415        |\n",
      "|    total_timesteps    | 667500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -943        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 133499      |\n",
      "|    policy_loss        | 29          |\n",
      "|    reward             | 0.040047254 |\n",
      "|    std                | 3.34e+13    |\n",
      "|    value_loss         | 0.000964    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 133600      |\n",
      "|    time_elapsed       | 6420        |\n",
      "|    total_timesteps    | 668000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -944        |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 133599      |\n",
      "|    policy_loss        | -28.7       |\n",
      "|    reward             | -0.08820015 |\n",
      "|    std                | 3.42e+13    |\n",
      "|    value_loss         | 0.00671     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 133700       |\n",
      "|    time_elapsed       | 6425         |\n",
      "|    total_timesteps    | 668500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -944         |\n",
      "|    explained_variance | 0.605        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 133699       |\n",
      "|    policy_loss        | -3.36        |\n",
      "|    reward             | 0.0043345224 |\n",
      "|    std                | 3.47e+13     |\n",
      "|    value_loss         | 7.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 133800       |\n",
      "|    time_elapsed       | 6429         |\n",
      "|    total_timesteps    | 669000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -945         |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 133799       |\n",
      "|    policy_loss        | -9.74        |\n",
      "|    reward             | -0.012985764 |\n",
      "|    std                | 3.55e+13     |\n",
      "|    value_loss         | 0.000175     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 133900      |\n",
      "|    time_elapsed       | 6434        |\n",
      "|    total_timesteps    | 669500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -946        |\n",
      "|    explained_variance | -0.536      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 133899      |\n",
      "|    policy_loss        | -7.66       |\n",
      "|    reward             | 0.021930723 |\n",
      "|    std                | 3.65e+13    |\n",
      "|    value_loss         | 0.000687    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 134000      |\n",
      "|    time_elapsed       | 6439        |\n",
      "|    total_timesteps    | 670000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -947        |\n",
      "|    explained_variance | 0.494       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 133999      |\n",
      "|    policy_loss        | 10.2        |\n",
      "|    reward             | 0.056918796 |\n",
      "|    std                | 3.75e+13    |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 134100       |\n",
      "|    time_elapsed       | 6444         |\n",
      "|    total_timesteps    | 670500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -947         |\n",
      "|    explained_variance | -1.32        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 134099       |\n",
      "|    policy_loss        | 45.3         |\n",
      "|    reward             | -0.028621431 |\n",
      "|    std                | 3.84e+13     |\n",
      "|    value_loss         | 0.0034       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 134200      |\n",
      "|    time_elapsed       | 6449        |\n",
      "|    total_timesteps    | 671000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -948        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 134199      |\n",
      "|    policy_loss        | 51.8        |\n",
      "|    reward             | -0.33873197 |\n",
      "|    std                | 3.9e+13     |\n",
      "|    value_loss         | 0.00364     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 134300      |\n",
      "|    time_elapsed       | 6454        |\n",
      "|    total_timesteps    | 671500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -948        |\n",
      "|    explained_variance | -4.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 134299      |\n",
      "|    policy_loss        | 7.53        |\n",
      "|    reward             | 0.016556323 |\n",
      "|    std                | 3.95e+13    |\n",
      "|    value_loss         | 0.000484    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 134400      |\n",
      "|    time_elapsed       | 6459        |\n",
      "|    total_timesteps    | 672000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -949        |\n",
      "|    explained_variance | 0.0166      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 134399      |\n",
      "|    policy_loss        | 9.03        |\n",
      "|    reward             | 0.023857532 |\n",
      "|    std                | 4.03e+13    |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 134500       |\n",
      "|    time_elapsed       | 6463         |\n",
      "|    total_timesteps    | 672500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -950         |\n",
      "|    explained_variance | 0.711        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 134499       |\n",
      "|    policy_loss        | -0.675       |\n",
      "|    reward             | 9.423516e-05 |\n",
      "|    std                | 4.15e+13     |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 134600      |\n",
      "|    time_elapsed       | 6468        |\n",
      "|    total_timesteps    | 673000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -950        |\n",
      "|    explained_variance | 0.622       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 134599      |\n",
      "|    policy_loss        | -1.12       |\n",
      "|    reward             | -0.02287686 |\n",
      "|    std                | 4.25e+13    |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 134700       |\n",
      "|    time_elapsed       | 6473         |\n",
      "|    total_timesteps    | 673500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -951         |\n",
      "|    explained_variance | 0.35         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 134699       |\n",
      "|    policy_loss        | -54.8        |\n",
      "|    reward             | 0.0051670047 |\n",
      "|    std                | 4.35e+13     |\n",
      "|    value_loss         | 0.00566      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 134800    |\n",
      "|    time_elapsed       | 6478      |\n",
      "|    total_timesteps    | 674000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -952      |\n",
      "|    explained_variance | 0.806     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 134799    |\n",
      "|    policy_loss        | 174       |\n",
      "|    reward             | 1.3207966 |\n",
      "|    std                | 4.44e+13  |\n",
      "|    value_loss         | 0.249     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 134900      |\n",
      "|    time_elapsed       | 6483        |\n",
      "|    total_timesteps    | 674500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -952        |\n",
      "|    explained_variance | 0.384       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 134899      |\n",
      "|    policy_loss        | -11         |\n",
      "|    reward             | 0.034495376 |\n",
      "|    std                | 4.53e+13    |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 135000      |\n",
      "|    time_elapsed       | 6488        |\n",
      "|    total_timesteps    | 675000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -953        |\n",
      "|    explained_variance | 0.429       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 134999      |\n",
      "|    policy_loss        | 15.6        |\n",
      "|    reward             | 0.021521965 |\n",
      "|    std                | 4.66e+13    |\n",
      "|    value_loss         | 0.000356    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 135100      |\n",
      "|    time_elapsed       | 6492        |\n",
      "|    total_timesteps    | 675500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -954        |\n",
      "|    explained_variance | 0.276       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 135099      |\n",
      "|    policy_loss        | -19.4       |\n",
      "|    reward             | 0.034558255 |\n",
      "|    std                | 4.8e+13     |\n",
      "|    value_loss         | 0.00049     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 135200      |\n",
      "|    time_elapsed       | 6497        |\n",
      "|    total_timesteps    | 676000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -955        |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 135199      |\n",
      "|    policy_loss        | -12.1       |\n",
      "|    reward             | 0.034903746 |\n",
      "|    std                | 4.94e+13    |\n",
      "|    value_loss         | 0.000237    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 135300     |\n",
      "|    time_elapsed       | 6502       |\n",
      "|    total_timesteps    | 676500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -956       |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 135299     |\n",
      "|    policy_loss        | -37.4      |\n",
      "|    reward             | 0.04697308 |\n",
      "|    std                | 5.08e+13   |\n",
      "|    value_loss         | 0.00198    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 135400        |\n",
      "|    time_elapsed       | 6507          |\n",
      "|    total_timesteps    | 677000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -956          |\n",
      "|    explained_variance | 0.61          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 135399        |\n",
      "|    policy_loss        | -9.35         |\n",
      "|    reward             | -0.0043284167 |\n",
      "|    std                | 5.16e+13      |\n",
      "|    value_loss         | 0.000145      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 135500       |\n",
      "|    time_elapsed       | 6512         |\n",
      "|    total_timesteps    | 677500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -957         |\n",
      "|    explained_variance | -3.06        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 135499       |\n",
      "|    policy_loss        | 23.8         |\n",
      "|    reward             | -0.051809046 |\n",
      "|    std                | 5.26e+13     |\n",
      "|    value_loss         | 0.000901     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 135600      |\n",
      "|    time_elapsed       | 6516        |\n",
      "|    total_timesteps    | 678000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -958        |\n",
      "|    explained_variance | 0.546       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 135599      |\n",
      "|    policy_loss        | 6.75        |\n",
      "|    reward             | 0.015402725 |\n",
      "|    std                | 5.41e+13    |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 135700      |\n",
      "|    time_elapsed       | 6521        |\n",
      "|    total_timesteps    | 678500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -958        |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 135699      |\n",
      "|    policy_loss        | 2.42        |\n",
      "|    reward             | 0.028036175 |\n",
      "|    std                | 5.6e+13     |\n",
      "|    value_loss         | 0.0004      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 135800      |\n",
      "|    time_elapsed       | 6526        |\n",
      "|    total_timesteps    | 679000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -959        |\n",
      "|    explained_variance | 0.665       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 135799      |\n",
      "|    policy_loss        | -91.1       |\n",
      "|    reward             | 0.043452725 |\n",
      "|    std                | 5.76e+13    |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 135900     |\n",
      "|    time_elapsed       | 6531       |\n",
      "|    total_timesteps    | 679500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -960       |\n",
      "|    explained_variance | 0.527      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 135899     |\n",
      "|    policy_loss        | -131       |\n",
      "|    reward             | 0.23468243 |\n",
      "|    std                | 5.87e+13   |\n",
      "|    value_loss         | 0.0255     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 136000        |\n",
      "|    time_elapsed       | 6536          |\n",
      "|    total_timesteps    | 680000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -960          |\n",
      "|    explained_variance | 0.0353        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 135999        |\n",
      "|    policy_loss        | 21.8          |\n",
      "|    reward             | -0.0003099028 |\n",
      "|    std                | 5.95e+13      |\n",
      "|    value_loss         | 0.000689      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 136100      |\n",
      "|    time_elapsed       | 6541        |\n",
      "|    total_timesteps    | 680500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -961        |\n",
      "|    explained_variance | 0.318       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 136099      |\n",
      "|    policy_loss        | -29.1       |\n",
      "|    reward             | -0.02952837 |\n",
      "|    std                | 6.06e+13    |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 136200        |\n",
      "|    time_elapsed       | 6545          |\n",
      "|    total_timesteps    | 681000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -962          |\n",
      "|    explained_variance | 0.89          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 136199        |\n",
      "|    policy_loss        | 0.0861        |\n",
      "|    reward             | -0.0017701201 |\n",
      "|    std                | 6.21e+13      |\n",
      "|    value_loss         | 0.00014       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 136300       |\n",
      "|    time_elapsed       | 6550         |\n",
      "|    total_timesteps    | 681500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -962         |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 136299       |\n",
      "|    policy_loss        | 12.4         |\n",
      "|    reward             | -0.016016118 |\n",
      "|    std                | 6.38e+13     |\n",
      "|    value_loss         | 0.000396     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 136400     |\n",
      "|    time_elapsed       | 6555       |\n",
      "|    total_timesteps    | 682000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -963       |\n",
      "|    explained_variance | 0.823      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 136399     |\n",
      "|    policy_loss        | 33.1       |\n",
      "|    reward             | 0.07274182 |\n",
      "|    std                | 6.56e+13   |\n",
      "|    value_loss         | 0.00169    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 136500      |\n",
      "|    time_elapsed       | 6560        |\n",
      "|    total_timesteps    | 682500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -963        |\n",
      "|    explained_variance | 0.257       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 136499      |\n",
      "|    policy_loss        | -131        |\n",
      "|    reward             | 0.014440039 |\n",
      "|    std                | 6.65e+13    |\n",
      "|    value_loss         | 0.0263      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 136600     |\n",
      "|    time_elapsed       | 6565       |\n",
      "|    total_timesteps    | 683000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -964       |\n",
      "|    explained_variance | 0.631      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 136599     |\n",
      "|    policy_loss        | 3.39       |\n",
      "|    reward             | 0.02477613 |\n",
      "|    std                | 6.74e+13   |\n",
      "|    value_loss         | 3.49e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 136700        |\n",
      "|    time_elapsed       | 6569          |\n",
      "|    total_timesteps    | 683500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -964          |\n",
      "|    explained_variance | 0.667         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 136699        |\n",
      "|    policy_loss        | -12.6         |\n",
      "|    reward             | -0.0059129237 |\n",
      "|    std                | 6.88e+13      |\n",
      "|    value_loss         | 0.000251      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 136800      |\n",
      "|    time_elapsed       | 6574        |\n",
      "|    total_timesteps    | 684000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -965        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 136799      |\n",
      "|    policy_loss        | -29         |\n",
      "|    reward             | 0.008693263 |\n",
      "|    std                | 7.07e+13    |\n",
      "|    value_loss         | 0.00114     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 136900      |\n",
      "|    time_elapsed       | 6579        |\n",
      "|    total_timesteps    | 684500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -966        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 136899      |\n",
      "|    policy_loss        | -8.49       |\n",
      "|    reward             | -0.14980602 |\n",
      "|    std                | 7.28e+13    |\n",
      "|    value_loss         | 0.000259    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 137000     |\n",
      "|    time_elapsed       | 6584       |\n",
      "|    total_timesteps    | 685000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -967       |\n",
      "|    explained_variance | 0.63       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 136999     |\n",
      "|    policy_loss        | 158        |\n",
      "|    reward             | 0.08518579 |\n",
      "|    std                | 7.48e+13   |\n",
      "|    value_loss         | 0.0313     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 137100       |\n",
      "|    time_elapsed       | 6589         |\n",
      "|    total_timesteps    | 685500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -968         |\n",
      "|    explained_variance | 0.7          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 137099       |\n",
      "|    policy_loss        | -43.4        |\n",
      "|    reward             | -0.060783535 |\n",
      "|    std                | 7.63e+13     |\n",
      "|    value_loss         | 0.00396      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 137200      |\n",
      "|    time_elapsed       | 6593        |\n",
      "|    total_timesteps    | 686000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -968        |\n",
      "|    explained_variance | 0.151       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 137199      |\n",
      "|    policy_loss        | -5.38       |\n",
      "|    reward             | 0.010395962 |\n",
      "|    std                | 7.75e+13    |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 104            |\n",
      "|    iterations         | 137300         |\n",
      "|    time_elapsed       | 6598           |\n",
      "|    total_timesteps    | 686500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -969           |\n",
      "|    explained_variance | 0.71           |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 137299         |\n",
      "|    policy_loss        | 1.89           |\n",
      "|    reward             | -0.00078365416 |\n",
      "|    std                | 7.94e+13       |\n",
      "|    value_loss         | 0.000296       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 137400      |\n",
      "|    time_elapsed       | 6603        |\n",
      "|    total_timesteps    | 687000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -969        |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 137399      |\n",
      "|    policy_loss        | 3.05        |\n",
      "|    reward             | 0.033374745 |\n",
      "|    std                | 8.16e+13    |\n",
      "|    value_loss         | 0.000286    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 137500       |\n",
      "|    time_elapsed       | 6608         |\n",
      "|    total_timesteps    | 687500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -970         |\n",
      "|    explained_variance | 0.74         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 137499       |\n",
      "|    policy_loss        | -85.6        |\n",
      "|    reward             | -0.005199619 |\n",
      "|    std                | 8.38e+13     |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 137600       |\n",
      "|    time_elapsed       | 6613         |\n",
      "|    total_timesteps    | 688000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -971         |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 137599       |\n",
      "|    policy_loss        | 65.1         |\n",
      "|    reward             | 0.0014797165 |\n",
      "|    std                | 8.58e+13     |\n",
      "|    value_loss         | 0.00476      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 137700     |\n",
      "|    time_elapsed       | 6617       |\n",
      "|    total_timesteps    | 688500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -971       |\n",
      "|    explained_variance | 0.893      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 137699     |\n",
      "|    policy_loss        | -395       |\n",
      "|    reward             | -0.5237343 |\n",
      "|    std                | 8.69e+13   |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 137800       |\n",
      "|    time_elapsed       | 6622         |\n",
      "|    total_timesteps    | 689000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -972         |\n",
      "|    explained_variance | -121         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 137799       |\n",
      "|    policy_loss        | 22.2         |\n",
      "|    reward             | -0.010557505 |\n",
      "|    std                | 8.85e+13     |\n",
      "|    value_loss         | 0.00071      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 137900       |\n",
      "|    time_elapsed       | 6627         |\n",
      "|    total_timesteps    | 689500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -972         |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 137899       |\n",
      "|    policy_loss        | -9.47        |\n",
      "|    reward             | -0.038534857 |\n",
      "|    std                | 9.06e+13     |\n",
      "|    value_loss         | 0.000139     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 104            |\n",
      "|    iterations         | 138000         |\n",
      "|    time_elapsed       | 6632           |\n",
      "|    total_timesteps    | 690000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -973           |\n",
      "|    explained_variance | 0.975          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 137999         |\n",
      "|    policy_loss        | -28.4          |\n",
      "|    reward             | -6.3031526e-05 |\n",
      "|    std                | 9.31e+13       |\n",
      "|    value_loss         | 0.00128        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 138100      |\n",
      "|    time_elapsed       | 6637        |\n",
      "|    total_timesteps    | 690500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -974        |\n",
      "|    explained_variance | 0.00402     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 138099      |\n",
      "|    policy_loss        | 66.1        |\n",
      "|    reward             | 0.050402954 |\n",
      "|    std                | 9.51e+13    |\n",
      "|    value_loss         | 0.00892     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 138200     |\n",
      "|    time_elapsed       | 6641       |\n",
      "|    total_timesteps    | 691000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -975       |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 138199     |\n",
      "|    policy_loss        | -107       |\n",
      "|    reward             | -0.2940172 |\n",
      "|    std                | 9.71e+13   |\n",
      "|    value_loss         | 0.017      |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17908783.44\n",
      "total_reward: 7908783.44\n",
      "total_cost: 562098.72\n",
      "total_trades: 82881\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 138300       |\n",
      "|    time_elapsed       | 6646         |\n",
      "|    total_timesteps    | 691500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -975         |\n",
      "|    explained_variance | 0.479        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 138299       |\n",
      "|    policy_loss        | -6.7         |\n",
      "|    reward             | -0.021215605 |\n",
      "|    std                | 9.84e+13     |\n",
      "|    value_loss         | 7.92e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 138400       |\n",
      "|    time_elapsed       | 6651         |\n",
      "|    total_timesteps    | 692000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -975         |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 138399       |\n",
      "|    policy_loss        | -1.53        |\n",
      "|    reward             | -0.021675546 |\n",
      "|    std                | 1e+14        |\n",
      "|    value_loss         | 6.82e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 138500      |\n",
      "|    time_elapsed       | 6656        |\n",
      "|    total_timesteps    | 692500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -976        |\n",
      "|    explained_variance | -0.373      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 138499      |\n",
      "|    policy_loss        | 24.7        |\n",
      "|    reward             | 0.058858957 |\n",
      "|    std                | 1.03e+14    |\n",
      "|    value_loss         | 0.00143     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 138600      |\n",
      "|    time_elapsed       | 6661        |\n",
      "|    total_timesteps    | 693000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -977        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 138599      |\n",
      "|    policy_loss        | 14.6        |\n",
      "|    reward             | 0.043745026 |\n",
      "|    std                | 1.06e+14    |\n",
      "|    value_loss         | 0.00032     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 138700      |\n",
      "|    time_elapsed       | 6665        |\n",
      "|    total_timesteps    | 693500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -978        |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 138699      |\n",
      "|    policy_loss        | 11.3        |\n",
      "|    reward             | -0.06269876 |\n",
      "|    std                | 1.09e+14    |\n",
      "|    value_loss         | 0.00262     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 138800     |\n",
      "|    time_elapsed       | 6670       |\n",
      "|    total_timesteps    | 694000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -978       |\n",
      "|    explained_variance | 0.874      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 138799     |\n",
      "|    policy_loss        | 58.8       |\n",
      "|    reward             | 0.08316738 |\n",
      "|    std                | 1.11e+14   |\n",
      "|    value_loss         | 0.00467    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 138900       |\n",
      "|    time_elapsed       | 6675         |\n",
      "|    total_timesteps    | 694500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -979         |\n",
      "|    explained_variance | 0.817        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 138899       |\n",
      "|    policy_loss        | 21.3         |\n",
      "|    reward             | -0.011906282 |\n",
      "|    std                | 1.12e+14     |\n",
      "|    value_loss         | 0.000518     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139000      |\n",
      "|    time_elapsed       | 6680        |\n",
      "|    total_timesteps    | 695000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -979        |\n",
      "|    explained_variance | 0.317       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 138999      |\n",
      "|    policy_loss        | -18.3       |\n",
      "|    reward             | 0.036156725 |\n",
      "|    std                | 1.15e+14    |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 139100     |\n",
      "|    time_elapsed       | 6685       |\n",
      "|    total_timesteps    | 695500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -980       |\n",
      "|    explained_variance | 0.773      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 139099     |\n",
      "|    policy_loss        | -65.4      |\n",
      "|    reward             | 0.03344344 |\n",
      "|    std                | 1.18e+14   |\n",
      "|    value_loss         | 0.00455    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139200      |\n",
      "|    time_elapsed       | 6690        |\n",
      "|    total_timesteps    | 696000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -981        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 139199      |\n",
      "|    policy_loss        | -5.81       |\n",
      "|    reward             | -0.14914168 |\n",
      "|    std                | 1.21e+14    |\n",
      "|    value_loss         | 0.00117     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139300      |\n",
      "|    time_elapsed       | 6694        |\n",
      "|    total_timesteps    | 696500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -982        |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 139299      |\n",
      "|    policy_loss        | -7.37       |\n",
      "|    reward             | 0.021866148 |\n",
      "|    std                | 1.25e+14    |\n",
      "|    value_loss         | 0.000693    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139400      |\n",
      "|    time_elapsed       | 6699        |\n",
      "|    total_timesteps    | 697000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -982        |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 139399      |\n",
      "|    policy_loss        | 58.5        |\n",
      "|    reward             | -0.14491415 |\n",
      "|    std                | 1.27e+14    |\n",
      "|    value_loss         | 0.00833     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139500      |\n",
      "|    time_elapsed       | 6704        |\n",
      "|    total_timesteps    | 697500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -983        |\n",
      "|    explained_variance | 0.621       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 139499      |\n",
      "|    policy_loss        | -18         |\n",
      "|    reward             | 0.015234459 |\n",
      "|    std                | 1.28e+14    |\n",
      "|    value_loss         | 0.000383    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 139600     |\n",
      "|    time_elapsed       | 6709       |\n",
      "|    total_timesteps    | 698000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -983       |\n",
      "|    explained_variance | 0.601      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 139599     |\n",
      "|    policy_loss        | 8.06       |\n",
      "|    reward             | 0.02949873 |\n",
      "|    std                | 1.31e+14   |\n",
      "|    value_loss         | 0.000226   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 139700   |\n",
      "|    time_elapsed       | 6714     |\n",
      "|    total_timesteps    | 698500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -984     |\n",
      "|    explained_variance | 0.72     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 139699   |\n",
      "|    policy_loss        | 79.5     |\n",
      "|    reward             | 0.04245  |\n",
      "|    std                | 1.35e+14 |\n",
      "|    value_loss         | 0.00928  |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139800      |\n",
      "|    time_elapsed       | 6719        |\n",
      "|    total_timesteps    | 699000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -985        |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 139799      |\n",
      "|    policy_loss        | -84.2       |\n",
      "|    reward             | 0.056929342 |\n",
      "|    std                | 1.38e+14    |\n",
      "|    value_loss         | 0.00955     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 139900      |\n",
      "|    time_elapsed       | 6724        |\n",
      "|    total_timesteps    | 699500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -985        |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 139899      |\n",
      "|    policy_loss        | 137         |\n",
      "|    reward             | -0.39342165 |\n",
      "|    std                | 1.41e+14    |\n",
      "|    value_loss         | 0.02        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 140000    |\n",
      "|    time_elapsed       | 6729      |\n",
      "|    total_timesteps    | 700000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -986      |\n",
      "|    explained_variance | -0.0751   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 139999    |\n",
      "|    policy_loss        | -89.6     |\n",
      "|    reward             | 0.0971805 |\n",
      "|    std                | 1.43e+14  |\n",
      "|    value_loss         | 0.0182    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 140100       |\n",
      "|    time_elapsed       | 6733         |\n",
      "|    total_timesteps    | 700500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -986         |\n",
      "|    explained_variance | 0.238        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 140099       |\n",
      "|    policy_loss        | -4.21        |\n",
      "|    reward             | -0.008571606 |\n",
      "|    std                | 1.46e+14     |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 140200       |\n",
      "|    time_elapsed       | 6738         |\n",
      "|    total_timesteps    | 701000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -987         |\n",
      "|    explained_variance | 0.851        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 140199       |\n",
      "|    policy_loss        | -20.3        |\n",
      "|    reward             | -0.034660354 |\n",
      "|    std                | 1.49e+14     |\n",
      "|    value_loss         | 0.000565     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 140300      |\n",
      "|    time_elapsed       | 6743        |\n",
      "|    total_timesteps    | 701500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -988        |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 140299      |\n",
      "|    policy_loss        | -8.44       |\n",
      "|    reward             | 0.062324293 |\n",
      "|    std                | 1.54e+14    |\n",
      "|    value_loss         | 0.000297    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 140400      |\n",
      "|    time_elapsed       | 6749        |\n",
      "|    total_timesteps    | 702000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -989        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 140399      |\n",
      "|    policy_loss        | 4.47        |\n",
      "|    reward             | 0.008012646 |\n",
      "|    std                | 1.58e+14    |\n",
      "|    value_loss         | 7.69e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 140500     |\n",
      "|    time_elapsed       | 6754       |\n",
      "|    total_timesteps    | 702500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -989       |\n",
      "|    explained_variance | 0.649      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 140499     |\n",
      "|    policy_loss        | -80.3      |\n",
      "|    reward             | 0.18908928 |\n",
      "|    std                | 1.61e+14   |\n",
      "|    value_loss         | 0.0103     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 140600        |\n",
      "|    time_elapsed       | 6759          |\n",
      "|    total_timesteps    | 703000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -990          |\n",
      "|    explained_variance | 0.777         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 140599        |\n",
      "|    policy_loss        | -155          |\n",
      "|    reward             | 0.00027019926 |\n",
      "|    std                | 1.64e+14      |\n",
      "|    value_loss         | 0.0298        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 140700        |\n",
      "|    time_elapsed       | 6764          |\n",
      "|    total_timesteps    | 703500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -990          |\n",
      "|    explained_variance | 0.986         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 140699        |\n",
      "|    policy_loss        | 14.1          |\n",
      "|    reward             | -0.0013216842 |\n",
      "|    std                | 1.67e+14      |\n",
      "|    value_loss         | 0.000205      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 140800       |\n",
      "|    time_elapsed       | 6769         |\n",
      "|    total_timesteps    | 704000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -991         |\n",
      "|    explained_variance | 0.47         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 140799       |\n",
      "|    policy_loss        | 26.5         |\n",
      "|    reward             | -0.023527673 |\n",
      "|    std                | 1.71e+14     |\n",
      "|    value_loss         | 0.000995     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 140900     |\n",
      "|    time_elapsed       | 6773       |\n",
      "|    total_timesteps    | 704500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -992       |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 140899     |\n",
      "|    policy_loss        | -65.7      |\n",
      "|    reward             | 0.24847983 |\n",
      "|    std                | 1.76e+14   |\n",
      "|    value_loss         | 0.00469    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 141000      |\n",
      "|    time_elapsed       | 6778        |\n",
      "|    total_timesteps    | 705000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -993        |\n",
      "|    explained_variance | 0.208       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 140999      |\n",
      "|    policy_loss        | 40.8        |\n",
      "|    reward             | 0.077183634 |\n",
      "|    std                | 1.8e+14     |\n",
      "|    value_loss         | 0.00193     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 141100      |\n",
      "|    time_elapsed       | 6783        |\n",
      "|    total_timesteps    | 705500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -993        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 141099      |\n",
      "|    policy_loss        | -38.9       |\n",
      "|    reward             | 0.054049727 |\n",
      "|    std                | 1.84e+14    |\n",
      "|    value_loss         | 0.0028      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 141200       |\n",
      "|    time_elapsed       | 6788         |\n",
      "|    total_timesteps    | 706000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -993         |\n",
      "|    explained_variance | -0.0364      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 141199       |\n",
      "|    policy_loss        | 18.8         |\n",
      "|    reward             | 0.0060622296 |\n",
      "|    std                | 1.86e+14     |\n",
      "|    value_loss         | 0.000547     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 141300       |\n",
      "|    time_elapsed       | 6793         |\n",
      "|    total_timesteps    | 706500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -994         |\n",
      "|    explained_variance | 0.749        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 141299       |\n",
      "|    policy_loss        | -25.9        |\n",
      "|    reward             | -0.009113764 |\n",
      "|    std                | 1.9e+14      |\n",
      "|    value_loss         | 0.000791     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 141400      |\n",
      "|    time_elapsed       | 6797        |\n",
      "|    total_timesteps    | 707000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -995        |\n",
      "|    explained_variance | -0.0937     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 141399      |\n",
      "|    policy_loss        | -45.6       |\n",
      "|    reward             | 0.015560878 |\n",
      "|    std                | 1.96e+14    |\n",
      "|    value_loss         | 0.00255     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 141500      |\n",
      "|    time_elapsed       | 6802        |\n",
      "|    total_timesteps    | 707500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -996        |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 141499      |\n",
      "|    policy_loss        | 23.3        |\n",
      "|    reward             | -0.10571261 |\n",
      "|    std                | 2.02e+14    |\n",
      "|    value_loss         | 0.000862    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 141600     |\n",
      "|    time_elapsed       | 6807       |\n",
      "|    total_timesteps    | 708000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -997       |\n",
      "|    explained_variance | 0.437      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 141599     |\n",
      "|    policy_loss        | 21.1       |\n",
      "|    reward             | 0.04311597 |\n",
      "|    std                | 2.07e+14   |\n",
      "|    value_loss         | 0.00139    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 141700     |\n",
      "|    time_elapsed       | 6812       |\n",
      "|    total_timesteps    | 708500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -997       |\n",
      "|    explained_variance | 0.597      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 141699     |\n",
      "|    policy_loss        | -118       |\n",
      "|    reward             | 0.08104208 |\n",
      "|    std                | 2.11e+14   |\n",
      "|    value_loss         | 0.025      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 141800     |\n",
      "|    time_elapsed       | 6817       |\n",
      "|    total_timesteps    | 709000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -997       |\n",
      "|    explained_variance | 0.481      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 141799     |\n",
      "|    policy_loss        | -2.4       |\n",
      "|    reward             | 0.02477699 |\n",
      "|    std                | 2.13e+14   |\n",
      "|    value_loss         | 0.000107   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 141900     |\n",
      "|    time_elapsed       | 6822       |\n",
      "|    total_timesteps    | 709500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -998       |\n",
      "|    explained_variance | 0.818      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 141899     |\n",
      "|    policy_loss        | -28.3      |\n",
      "|    reward             | 0.04191855 |\n",
      "|    std                | 2.18e+14   |\n",
      "|    value_loss         | 0.00106    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 142000       |\n",
      "|    time_elapsed       | 6826         |\n",
      "|    total_timesteps    | 710000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -999         |\n",
      "|    explained_variance | -4.12        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 141999       |\n",
      "|    policy_loss        | 22.4         |\n",
      "|    reward             | -0.026760247 |\n",
      "|    std                | 2.24e+14     |\n",
      "|    value_loss         | 0.00143      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 142100       |\n",
      "|    time_elapsed       | 6831         |\n",
      "|    total_timesteps    | 710500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1e+03       |\n",
      "|    explained_variance | 0.391        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 142099       |\n",
      "|    policy_loss        | 49           |\n",
      "|    reward             | -0.008339588 |\n",
      "|    std                | 2.31e+14     |\n",
      "|    value_loss         | 0.00405      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 142200     |\n",
      "|    time_elapsed       | 6836       |\n",
      "|    total_timesteps    | 711000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1e+03     |\n",
      "|    explained_variance | 0.218      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 142199     |\n",
      "|    policy_loss        | 30         |\n",
      "|    reward             | 0.03207899 |\n",
      "|    std                | 2.38e+14   |\n",
      "|    value_loss         | 0.00109    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 142300      |\n",
      "|    time_elapsed       | 6841        |\n",
      "|    total_timesteps    | 711500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1e+03      |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 142299      |\n",
      "|    policy_loss        | 119         |\n",
      "|    reward             | -0.06554783 |\n",
      "|    std                | 2.42e+14    |\n",
      "|    value_loss         | 0.0157      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 142400       |\n",
      "|    time_elapsed       | 6846         |\n",
      "|    total_timesteps    | 712000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1e+03       |\n",
      "|    explained_variance | 0.325        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 142399       |\n",
      "|    policy_loss        | 19.3         |\n",
      "|    reward             | 0.0029329972 |\n",
      "|    std                | 2.46e+14     |\n",
      "|    value_loss         | 0.000404     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 142500       |\n",
      "|    time_elapsed       | 6851         |\n",
      "|    total_timesteps    | 712500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1e+03       |\n",
      "|    explained_variance | 0.0103       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 142499       |\n",
      "|    policy_loss        | -42.3        |\n",
      "|    reward             | -0.043486968 |\n",
      "|    std                | 2.52e+14     |\n",
      "|    value_loss         | 0.00223      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 142600      |\n",
      "|    time_elapsed       | 6855        |\n",
      "|    total_timesteps    | 713000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1e+03      |\n",
      "|    explained_variance | 0.649       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 142599      |\n",
      "|    policy_loss        | -0.85       |\n",
      "|    reward             | -0.07692077 |\n",
      "|    std                | 2.59e+14    |\n",
      "|    value_loss         | 0.000163    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 142700       |\n",
      "|    time_elapsed       | 6860         |\n",
      "|    total_timesteps    | 713500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1e+03       |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 142699       |\n",
      "|    policy_loss        | 9.19         |\n",
      "|    reward             | -0.016033418 |\n",
      "|    std                | 2.66e+14     |\n",
      "|    value_loss         | 0.000312     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 142800    |\n",
      "|    time_elapsed       | 6865      |\n",
      "|    total_timesteps    | 714000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1e+03    |\n",
      "|    explained_variance | 0.846     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 142799    |\n",
      "|    policy_loss        | -54.7     |\n",
      "|    reward             | 0.5026568 |\n",
      "|    std                | 2.74e+14  |\n",
      "|    value_loss         | 0.00471   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 142900     |\n",
      "|    time_elapsed       | 6870       |\n",
      "|    total_timesteps    | 714500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1e+03     |\n",
      "|    explained_variance | 0.887      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 142899     |\n",
      "|    policy_loss        | -511       |\n",
      "|    reward             | -0.5393672 |\n",
      "|    std                | 2.77e+14   |\n",
      "|    value_loss         | 0.419      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 143000       |\n",
      "|    time_elapsed       | 6875         |\n",
      "|    total_timesteps    | 715000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | -0.276       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 142999       |\n",
      "|    policy_loss        | 7.62         |\n",
      "|    reward             | 0.0015457516 |\n",
      "|    std                | 2.82e+14     |\n",
      "|    value_loss         | 0.000355     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 143100       |\n",
      "|    time_elapsed       | 6879         |\n",
      "|    total_timesteps    | 715500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 143099       |\n",
      "|    policy_loss        | 5.2          |\n",
      "|    reward             | -0.029265873 |\n",
      "|    std                | 2.89e+14     |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 143200      |\n",
      "|    time_elapsed       | 6884        |\n",
      "|    total_timesteps    | 716000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.01e+03   |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 143199      |\n",
      "|    policy_loss        | 8.88        |\n",
      "|    reward             | 0.009386413 |\n",
      "|    std                | 2.97e+14    |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 143300       |\n",
      "|    time_elapsed       | 6889         |\n",
      "|    total_timesteps    | 716500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.0911       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 143299       |\n",
      "|    policy_loss        | -24.7        |\n",
      "|    reward             | -0.022126602 |\n",
      "|    std                | 3.06e+14     |\n",
      "|    value_loss         | 0.000758     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 143400     |\n",
      "|    time_elapsed       | 6894       |\n",
      "|    total_timesteps    | 717000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.01e+03  |\n",
      "|    explained_variance | 0.705      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 143399     |\n",
      "|    policy_loss        | -64.9      |\n",
      "|    reward             | 0.20243882 |\n",
      "|    std                | 3.14e+14   |\n",
      "|    value_loss         | 0.00737    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 143500      |\n",
      "|    time_elapsed       | 6899        |\n",
      "|    total_timesteps    | 717500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.01e+03   |\n",
      "|    explained_variance | 0.529       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 143499      |\n",
      "|    policy_loss        | -14.8       |\n",
      "|    reward             | -0.00877376 |\n",
      "|    std                | 3.18e+14    |\n",
      "|    value_loss         | 0.000264    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 143600        |\n",
      "|    time_elapsed       | 6903          |\n",
      "|    total_timesteps    | 718000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.01e+03     |\n",
      "|    explained_variance | 0.659         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 143599        |\n",
      "|    policy_loss        | -14.8         |\n",
      "|    reward             | -0.0065590767 |\n",
      "|    std                | 3.24e+14      |\n",
      "|    value_loss         | 0.000294      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 143700      |\n",
      "|    time_elapsed       | 6908        |\n",
      "|    total_timesteps    | 718500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.01e+03   |\n",
      "|    explained_variance | 0.519       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 143699      |\n",
      "|    policy_loss        | -21.4       |\n",
      "|    reward             | 0.012558246 |\n",
      "|    std                | 3.32e+14    |\n",
      "|    value_loss         | 0.000858    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 143800     |\n",
      "|    time_elapsed       | 6913       |\n",
      "|    total_timesteps    | 719000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.01e+03  |\n",
      "|    explained_variance | 0.885      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 143799     |\n",
      "|    policy_loss        | -49        |\n",
      "|    reward             | 0.09348709 |\n",
      "|    std                | 3.4e+14    |\n",
      "|    value_loss         | 0.00295    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 143900     |\n",
      "|    time_elapsed       | 6918       |\n",
      "|    total_timesteps    | 719500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.01e+03  |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 143899     |\n",
      "|    policy_loss        | 58.6       |\n",
      "|    reward             | 0.15775286 |\n",
      "|    std                | 3.49e+14   |\n",
      "|    value_loss         | 0.00348    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 144000       |\n",
      "|    time_elapsed       | 6922         |\n",
      "|    total_timesteps    | 720000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 143999       |\n",
      "|    policy_loss        | 135          |\n",
      "|    reward             | 0.0037705929 |\n",
      "|    std                | 3.56e+14     |\n",
      "|    value_loss         | 0.0182       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 250\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19520255.28\n",
      "total_reward: 9520255.28\n",
      "total_cost: 563041.65\n",
      "total_trades: 82798\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 144100       |\n",
      "|    time_elapsed       | 6927         |\n",
      "|    total_timesteps    | 720500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.171        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144099       |\n",
      "|    policy_loss        | 9.39         |\n",
      "|    reward             | -0.003361856 |\n",
      "|    std                | 3.61e+14     |\n",
      "|    value_loss         | 0.000159     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 144200       |\n",
      "|    time_elapsed       | 6932         |\n",
      "|    total_timesteps    | 721000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144199       |\n",
      "|    policy_loss        | 15.3         |\n",
      "|    reward             | -0.025587603 |\n",
      "|    std                | 3.69e+14     |\n",
      "|    value_loss         | 0.000301     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 144300       |\n",
      "|    time_elapsed       | 6937         |\n",
      "|    total_timesteps    | 721500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.738        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144299       |\n",
      "|    policy_loss        | -24.8        |\n",
      "|    reward             | -0.019210178 |\n",
      "|    std                | 3.79e+14     |\n",
      "|    value_loss         | 0.000938     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 144400       |\n",
      "|    time_elapsed       | 6942         |\n",
      "|    total_timesteps    | 722000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.01e+03    |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144399       |\n",
      "|    policy_loss        | -45.4        |\n",
      "|    reward             | -0.005992409 |\n",
      "|    std                | 3.91e+14     |\n",
      "|    value_loss         | 0.00206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 144500       |\n",
      "|    time_elapsed       | 6947         |\n",
      "|    total_timesteps    | 722500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.02e+03    |\n",
      "|    explained_variance | 0.81         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144499       |\n",
      "|    policy_loss        | -9.1         |\n",
      "|    reward             | -0.002734246 |\n",
      "|    std                | 4.01e+14     |\n",
      "|    value_loss         | 0.000788     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 144600       |\n",
      "|    time_elapsed       | 6951         |\n",
      "|    total_timesteps    | 723000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.02e+03    |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144599       |\n",
      "|    policy_loss        | -105         |\n",
      "|    reward             | -0.038098913 |\n",
      "|    std                | 4.08e+14     |\n",
      "|    value_loss         | 0.0132       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 144700       |\n",
      "|    time_elapsed       | 6956         |\n",
      "|    total_timesteps    | 723500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.02e+03    |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 144699       |\n",
      "|    policy_loss        | 0.511        |\n",
      "|    reward             | 0.0029465125 |\n",
      "|    std                | 4.13e+14     |\n",
      "|    value_loss         | 1.24e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 144800      |\n",
      "|    time_elapsed       | 6961        |\n",
      "|    total_timesteps    | 724000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 144799      |\n",
      "|    policy_loss        | -25.5       |\n",
      "|    reward             | 0.023872627 |\n",
      "|    std                | 4.24e+14    |\n",
      "|    value_loss         | 0.000934    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 144900      |\n",
      "|    time_elapsed       | 6966        |\n",
      "|    total_timesteps    | 724500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 144899      |\n",
      "|    policy_loss        | 6.82        |\n",
      "|    reward             | 0.014297584 |\n",
      "|    std                | 4.34e+14    |\n",
      "|    value_loss         | 0.000121    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 145000     |\n",
      "|    time_elapsed       | 6971       |\n",
      "|    total_timesteps    | 725000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.02e+03  |\n",
      "|    explained_variance | 0.875      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 144999     |\n",
      "|    policy_loss        | -67.3      |\n",
      "|    reward             | 0.11026465 |\n",
      "|    std                | 4.45e+14   |\n",
      "|    value_loss         | 0.00545    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145100      |\n",
      "|    time_elapsed       | 6976        |\n",
      "|    total_timesteps    | 725500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145099      |\n",
      "|    policy_loss        | -9.42       |\n",
      "|    reward             | 0.055669498 |\n",
      "|    std                | 4.55e+14    |\n",
      "|    value_loss         | 0.00425     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 145200     |\n",
      "|    time_elapsed       | 6980       |\n",
      "|    total_timesteps    | 726000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.02e+03  |\n",
      "|    explained_variance | 0.866      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 145199     |\n",
      "|    policy_loss        | 43.9       |\n",
      "|    reward             | 0.04496441 |\n",
      "|    std                | 4.63e+14   |\n",
      "|    value_loss         | 0.00354    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145300      |\n",
      "|    time_elapsed       | 6985        |\n",
      "|    total_timesteps    | 726500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.322       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145299      |\n",
      "|    policy_loss        | 34.2        |\n",
      "|    reward             | -0.07026124 |\n",
      "|    std                | 4.7e+14     |\n",
      "|    value_loss         | 0.00126     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 145400     |\n",
      "|    time_elapsed       | 6990       |\n",
      "|    total_timesteps    | 727000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.02e+03  |\n",
      "|    explained_variance | 0.895      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 145399     |\n",
      "|    policy_loss        | 14.5       |\n",
      "|    reward             | 0.05097086 |\n",
      "|    std                | 4.8e+14    |\n",
      "|    value_loss         | 0.000626   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145500      |\n",
      "|    time_elapsed       | 6995        |\n",
      "|    total_timesteps    | 727500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145499      |\n",
      "|    policy_loss        | -1.69       |\n",
      "|    reward             | 0.041519642 |\n",
      "|    std                | 4.93e+14    |\n",
      "|    value_loss         | 7.55e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145600      |\n",
      "|    time_elapsed       | 7000        |\n",
      "|    total_timesteps    | 728000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.662       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145599      |\n",
      "|    policy_loss        | 26.8        |\n",
      "|    reward             | -0.07859476 |\n",
      "|    std                | 5.05e+14    |\n",
      "|    value_loss         | 0.00162     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145700      |\n",
      "|    time_elapsed       | 7004        |\n",
      "|    total_timesteps    | 728500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145699      |\n",
      "|    policy_loss        | 12.4        |\n",
      "|    reward             | -0.16531374 |\n",
      "|    std                | 5.16e+14    |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145800      |\n",
      "|    time_elapsed       | 7009        |\n",
      "|    total_timesteps    | 729000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | 0.785       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145799      |\n",
      "|    policy_loss        | 75          |\n",
      "|    reward             | -0.09490248 |\n",
      "|    std                | 5.19e+14    |\n",
      "|    value_loss         | 0.0202      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 145900      |\n",
      "|    time_elapsed       | 7014        |\n",
      "|    total_timesteps    | 729500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.02e+03   |\n",
      "|    explained_variance | -0.126      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 145899      |\n",
      "|    policy_loss        | 3.04        |\n",
      "|    reward             | 0.034817904 |\n",
      "|    std                | 5.29e+14    |\n",
      "|    value_loss         | 3.93e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 103            |\n",
      "|    iterations         | 146000         |\n",
      "|    time_elapsed       | 7019           |\n",
      "|    total_timesteps    | 730000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.02e+03      |\n",
      "|    explained_variance | 0.658          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 145999         |\n",
      "|    policy_loss        | -19.4          |\n",
      "|    reward             | -0.00044830074 |\n",
      "|    std                | 5.41e+14       |\n",
      "|    value_loss         | 0.000803       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 146100      |\n",
      "|    time_elapsed       | 7024        |\n",
      "|    total_timesteps    | 730500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.03e+03   |\n",
      "|    explained_variance | -0.723      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 146099      |\n",
      "|    policy_loss        | -137        |\n",
      "|    reward             | 0.014560814 |\n",
      "|    std                | 5.56e+14    |\n",
      "|    value_loss         | 0.0268      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 146200       |\n",
      "|    time_elapsed       | 7028         |\n",
      "|    total_timesteps    | 731000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.03e+03    |\n",
      "|    explained_variance | 0.589        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 146199       |\n",
      "|    policy_loss        | -29          |\n",
      "|    reward             | -0.040623393 |\n",
      "|    std                | 5.71e+14     |\n",
      "|    value_loss         | 0.00388      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 146300    |\n",
      "|    time_elapsed       | 7033      |\n",
      "|    total_timesteps    | 731500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03e+03 |\n",
      "|    explained_variance | 0.845     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 146299    |\n",
      "|    policy_loss        | -168      |\n",
      "|    reward             | 0.5476883 |\n",
      "|    std                | 5.81e+14  |\n",
      "|    value_loss         | 0.0305    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 146400       |\n",
      "|    time_elapsed       | 7038         |\n",
      "|    total_timesteps    | 732000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.03e+03    |\n",
      "|    explained_variance | -0.0749      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 146399       |\n",
      "|    policy_loss        | -4.04        |\n",
      "|    reward             | 0.0043075876 |\n",
      "|    std                | 5.87e+14     |\n",
      "|    value_loss         | 7.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 146500       |\n",
      "|    time_elapsed       | 7043         |\n",
      "|    total_timesteps    | 732500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.03e+03    |\n",
      "|    explained_variance | 0.825        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 146499       |\n",
      "|    policy_loss        | 14.7         |\n",
      "|    reward             | -0.008549103 |\n",
      "|    std                | 5.98e+14     |\n",
      "|    value_loss         | 0.000249     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 146600     |\n",
      "|    time_elapsed       | 7048       |\n",
      "|    total_timesteps    | 733000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.03e+03  |\n",
      "|    explained_variance | 0.718      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 146599     |\n",
      "|    policy_loss        | 20.1       |\n",
      "|    reward             | 0.02973275 |\n",
      "|    std                | 6.13e+14   |\n",
      "|    value_loss         | 0.000518   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 146700      |\n",
      "|    time_elapsed       | 7052        |\n",
      "|    total_timesteps    | 733500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.03e+03   |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 146699      |\n",
      "|    policy_loss        | 31.3        |\n",
      "|    reward             | -0.06194952 |\n",
      "|    std                | 6.3e+14     |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 146800      |\n",
      "|    time_elapsed       | 7057        |\n",
      "|    total_timesteps    | 734000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.03e+03   |\n",
      "|    explained_variance | 0.512       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 146799      |\n",
      "|    policy_loss        | -21.5       |\n",
      "|    reward             | -0.04707816 |\n",
      "|    std                | 6.47e+14    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 146900     |\n",
      "|    time_elapsed       | 7062       |\n",
      "|    total_timesteps    | 734500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.03e+03  |\n",
      "|    explained_variance | 0.758      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 146899     |\n",
      "|    policy_loss        | 159        |\n",
      "|    reward             | -0.4227704 |\n",
      "|    std                | 6.59e+14   |\n",
      "|    value_loss         | 0.0273     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 147000      |\n",
      "|    time_elapsed       | 7067        |\n",
      "|    total_timesteps    | 735000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.03e+03   |\n",
      "|    explained_variance | 0.332       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 146999      |\n",
      "|    policy_loss        | 27.3        |\n",
      "|    reward             | 0.004801562 |\n",
      "|    std                | 6.68e+14    |\n",
      "|    value_loss         | 0.000943    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 147100      |\n",
      "|    time_elapsed       | 7072        |\n",
      "|    total_timesteps    | 735500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.03e+03   |\n",
      "|    explained_variance | 0.687       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 147099      |\n",
      "|    policy_loss        | 3.61        |\n",
      "|    reward             | 0.028449966 |\n",
      "|    std                | 6.83e+14    |\n",
      "|    value_loss         | 0.000272    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 147200     |\n",
      "|    time_elapsed       | 7076       |\n",
      "|    total_timesteps    | 736000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.03e+03  |\n",
      "|    explained_variance | 0.917      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 147199     |\n",
      "|    policy_loss        | -0.736     |\n",
      "|    reward             | 0.06809594 |\n",
      "|    std                | 7e+14      |\n",
      "|    value_loss         | 0.000179   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 147300    |\n",
      "|    time_elapsed       | 7081      |\n",
      "|    total_timesteps    | 736500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03e+03 |\n",
      "|    explained_variance | 0.85      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 147299    |\n",
      "|    policy_loss        | 143       |\n",
      "|    reward             | 0.1861727 |\n",
      "|    std                | 7.21e+14  |\n",
      "|    value_loss         | 0.0423    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 147400       |\n",
      "|    time_elapsed       | 7086         |\n",
      "|    total_timesteps    | 737000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.03e+03    |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 147399       |\n",
      "|    policy_loss        | 23.7         |\n",
      "|    reward             | -0.012197787 |\n",
      "|    std                | 7.37e+14     |\n",
      "|    value_loss         | 0.00077      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 147500      |\n",
      "|    time_elapsed       | 7091        |\n",
      "|    total_timesteps    | 737500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.03e+03   |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 147499      |\n",
      "|    policy_loss        | -124        |\n",
      "|    reward             | -0.38097158 |\n",
      "|    std                | 7.49e+14    |\n",
      "|    value_loss         | 0.0191      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 104            |\n",
      "|    iterations         | 147600         |\n",
      "|    time_elapsed       | 7096           |\n",
      "|    total_timesteps    | 738000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.03e+03      |\n",
      "|    explained_variance | -0.367         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 147599         |\n",
      "|    policy_loss        | -11.4          |\n",
      "|    reward             | -1.4942665e-05 |\n",
      "|    std                | 7.59e+14       |\n",
      "|    value_loss         | 0.000223       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 104           |\n",
      "|    iterations         | 147700        |\n",
      "|    time_elapsed       | 7100          |\n",
      "|    total_timesteps    | 738500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.03e+03     |\n",
      "|    explained_variance | 0.156         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 147699        |\n",
      "|    policy_loss        | -68.3         |\n",
      "|    reward             | -0.0017363356 |\n",
      "|    std                | 7.76e+14      |\n",
      "|    value_loss         | 0.0047        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 147800     |\n",
      "|    time_elapsed       | 7105       |\n",
      "|    total_timesteps    | 739000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.529      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 147799     |\n",
      "|    policy_loss        | -4.96      |\n",
      "|    reward             | 0.05921035 |\n",
      "|    std                | 7.97e+14   |\n",
      "|    value_loss         | 0.00183    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 147900      |\n",
      "|    time_elapsed       | 7110        |\n",
      "|    total_timesteps    | 739500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.04e+03   |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 147899      |\n",
      "|    policy_loss        | -34.8       |\n",
      "|    reward             | -0.21687518 |\n",
      "|    std                | 8.2e+14     |\n",
      "|    value_loss         | 0.00118     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 148000     |\n",
      "|    time_elapsed       | 7115       |\n",
      "|    total_timesteps    | 740000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | -1.4       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 147999     |\n",
      "|    policy_loss        | 18.7       |\n",
      "|    reward             | 0.06408089 |\n",
      "|    std                | 8.42e+14   |\n",
      "|    value_loss         | 0.00409    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 148100     |\n",
      "|    time_elapsed       | 7120       |\n",
      "|    total_timesteps    | 740500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 148099     |\n",
      "|    policy_loss        | -73.4      |\n",
      "|    reward             | 0.13133071 |\n",
      "|    std                | 8.55e+14   |\n",
      "|    value_loss         | 0.00562    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 148200      |\n",
      "|    time_elapsed       | 7124        |\n",
      "|    total_timesteps    | 741000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.04e+03   |\n",
      "|    explained_variance | 0.639       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 148199      |\n",
      "|    policy_loss        | -14.5       |\n",
      "|    reward             | 0.013769279 |\n",
      "|    std                | 8.71e+14    |\n",
      "|    value_loss         | 0.000296    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 148300      |\n",
      "|    time_elapsed       | 7129        |\n",
      "|    total_timesteps    | 741500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.04e+03   |\n",
      "|    explained_variance | 0.8         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 148299      |\n",
      "|    policy_loss        | -20.4       |\n",
      "|    reward             | 0.052049167 |\n",
      "|    std                | 8.93e+14    |\n",
      "|    value_loss         | 0.000585    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 148400      |\n",
      "|    time_elapsed       | 7134        |\n",
      "|    total_timesteps    | 742000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.04e+03   |\n",
      "|    explained_variance | 0.811       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 148399      |\n",
      "|    policy_loss        | -11         |\n",
      "|    reward             | 0.046676062 |\n",
      "|    std                | 9.21e+14    |\n",
      "|    value_loss         | 0.000412    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 148500     |\n",
      "|    time_elapsed       | 7139       |\n",
      "|    total_timesteps    | 742500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 148499     |\n",
      "|    policy_loss        | -7.97      |\n",
      "|    reward             | 0.03694792 |\n",
      "|    std                | 9.46e+14   |\n",
      "|    value_loss         | 0.000437   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 148600     |\n",
      "|    time_elapsed       | 7144       |\n",
      "|    total_timesteps    | 743000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 148599     |\n",
      "|    policy_loss        | -82.6      |\n",
      "|    reward             | 0.12566473 |\n",
      "|    std                | 9.7e+14    |\n",
      "|    value_loss         | 0.00699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 148700     |\n",
      "|    time_elapsed       | 7149       |\n",
      "|    total_timesteps    | 743500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.463      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 148699     |\n",
      "|    policy_loss        | 7.29       |\n",
      "|    reward             | 0.10909675 |\n",
      "|    std                | 9.87e+14   |\n",
      "|    value_loss         | 0.00492    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 148800        |\n",
      "|    time_elapsed       | 7154          |\n",
      "|    total_timesteps    | 744000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.04e+03     |\n",
      "|    explained_variance | -0.091        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 148799        |\n",
      "|    policy_loss        | 5.77          |\n",
      "|    reward             | -0.0021285391 |\n",
      "|    std                | 1.01e+15      |\n",
      "|    value_loss         | 7.52e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 148900     |\n",
      "|    time_elapsed       | 7159       |\n",
      "|    total_timesteps    | 744500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | -0.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 148899     |\n",
      "|    policy_loss        | -4.67      |\n",
      "|    reward             | 0.02693224 |\n",
      "|    std                | 1.04e+15   |\n",
      "|    value_loss         | 0.000605   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 149000     |\n",
      "|    time_elapsed       | 7164       |\n",
      "|    total_timesteps    | 745000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.643      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 148999     |\n",
      "|    policy_loss        | -17.6      |\n",
      "|    reward             | -0.0475027 |\n",
      "|    std                | 1.07e+15   |\n",
      "|    value_loss         | 0.000368   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 149100     |\n",
      "|    time_elapsed       | 7168       |\n",
      "|    total_timesteps    | 745500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.04e+03  |\n",
      "|    explained_variance | 0.436      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 149099     |\n",
      "|    policy_loss        | 17         |\n",
      "|    reward             | 0.08247222 |\n",
      "|    std                | 1.1e+15    |\n",
      "|    value_loss         | 0.000487   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 149200       |\n",
      "|    time_elapsed       | 7173         |\n",
      "|    total_timesteps    | 746000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.05e+03    |\n",
      "|    explained_variance | 0.686        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 149199       |\n",
      "|    policy_loss        | -173         |\n",
      "|    reward             | -0.011049491 |\n",
      "|    std                | 1.12e+15     |\n",
      "|    value_loss         | 0.0319       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 149300       |\n",
      "|    time_elapsed       | 7178         |\n",
      "|    total_timesteps    | 746500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.05e+03    |\n",
      "|    explained_variance | 0.305        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 149299       |\n",
      "|    policy_loss        | 12.3         |\n",
      "|    reward             | 0.0054777856 |\n",
      "|    std                | 1.14e+15     |\n",
      "|    value_loss         | 0.000172     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 149400     |\n",
      "|    time_elapsed       | 7183       |\n",
      "|    total_timesteps    | 747000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.05e+03  |\n",
      "|    explained_variance | 0.414      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 149399     |\n",
      "|    policy_loss        | -12.7      |\n",
      "|    reward             | 0.03642986 |\n",
      "|    std                | 1.16e+15   |\n",
      "|    value_loss         | 0.00032    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 149500     |\n",
      "|    time_elapsed       | 7188       |\n",
      "|    total_timesteps    | 747500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.05e+03  |\n",
      "|    explained_variance | 0.676      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 149499     |\n",
      "|    policy_loss        | -40.4      |\n",
      "|    reward             | 0.04183275 |\n",
      "|    std                | 1.19e+15   |\n",
      "|    value_loss         | 0.0019     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 149600      |\n",
      "|    time_elapsed       | 7192        |\n",
      "|    total_timesteps    | 748000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 149599      |\n",
      "|    policy_loss        | -28.5       |\n",
      "|    reward             | 0.009995283 |\n",
      "|    std                | 1.23e+15    |\n",
      "|    value_loss         | 0.000968    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 149700      |\n",
      "|    time_elapsed       | 7197        |\n",
      "|    total_timesteps    | 748500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | -9.94       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 149699      |\n",
      "|    policy_loss        | 38.9        |\n",
      "|    reward             | 0.030223101 |\n",
      "|    std                | 1.26e+15    |\n",
      "|    value_loss         | 0.00371     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 149800     |\n",
      "|    time_elapsed       | 7202       |\n",
      "|    total_timesteps    | 749000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.05e+03  |\n",
      "|    explained_variance | 0.295      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 149799     |\n",
      "|    policy_loss        | 55.5       |\n",
      "|    reward             | -0.4193683 |\n",
      "|    std                | 1.29e+15   |\n",
      "|    value_loss         | 0.0119     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 260\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18534927.14\n",
      "total_reward: 8534927.14\n",
      "total_cost: 563669.53\n",
      "total_trades: 82949\n",
      "Sharpe: 0.525\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 149900     |\n",
      "|    time_elapsed       | 7207       |\n",
      "|    total_timesteps    | 749500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.05e+03  |\n",
      "|    explained_variance | 0.0908     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 149899     |\n",
      "|    policy_loss        | 25.9       |\n",
      "|    reward             | 0.02680361 |\n",
      "|    std                | 1.31e+15   |\n",
      "|    value_loss         | 0.000922   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150000      |\n",
      "|    time_elapsed       | 7212        |\n",
      "|    total_timesteps    | 750000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | 0.466       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 149999      |\n",
      "|    policy_loss        | -22.1       |\n",
      "|    reward             | -0.07159256 |\n",
      "|    std                | 1.34e+15    |\n",
      "|    value_loss         | 0.00172     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150100      |\n",
      "|    time_elapsed       | 7217        |\n",
      "|    total_timesteps    | 750500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 150099      |\n",
      "|    policy_loss        | 16.9        |\n",
      "|    reward             | 0.009212881 |\n",
      "|    std                | 1.37e+15    |\n",
      "|    value_loss         | 0.000469    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 150200    |\n",
      "|    time_elapsed       | 7221      |\n",
      "|    total_timesteps    | 751000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.05e+03 |\n",
      "|    explained_variance | 0.963     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 150199    |\n",
      "|    policy_loss        | 77.5      |\n",
      "|    reward             | 0.1659188 |\n",
      "|    std                | 1.41e+15  |\n",
      "|    value_loss         | 0.00551   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150300      |\n",
      "|    time_elapsed       | 7226        |\n",
      "|    total_timesteps    | 751500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | -0.00516    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 150299      |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.005801356 |\n",
      "|    std                | 1.45e+15    |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150400      |\n",
      "|    time_elapsed       | 7231        |\n",
      "|    total_timesteps    | 752000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 150399      |\n",
      "|    policy_loss        | 25.7        |\n",
      "|    reward             | 0.014812042 |\n",
      "|    std                | 1.48e+15    |\n",
      "|    value_loss         | 0.00196     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150500      |\n",
      "|    time_elapsed       | 7236        |\n",
      "|    total_timesteps    | 752500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | 0.0428      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 150499      |\n",
      "|    policy_loss        | 8.45        |\n",
      "|    reward             | 0.009075683 |\n",
      "|    std                | 1.51e+15    |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150600      |\n",
      "|    time_elapsed       | 7241        |\n",
      "|    total_timesteps    | 753000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.05e+03   |\n",
      "|    explained_variance | 0.395       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 150599      |\n",
      "|    policy_loss        | -8.38       |\n",
      "|    reward             | -0.06333204 |\n",
      "|    std                | 1.55e+15    |\n",
      "|    value_loss         | 0.000819    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 150700        |\n",
      "|    time_elapsed       | 7245          |\n",
      "|    total_timesteps    | 753500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.06e+03     |\n",
      "|    explained_variance | 0.219         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 150699        |\n",
      "|    policy_loss        | -12.5         |\n",
      "|    reward             | -0.0031567388 |\n",
      "|    std                | 1.59e+15      |\n",
      "|    value_loss         | 0.000508      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 150800     |\n",
      "|    time_elapsed       | 7250       |\n",
      "|    total_timesteps    | 754000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.06e+03  |\n",
      "|    explained_variance | 0.624      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 150799     |\n",
      "|    policy_loss        | 81.5       |\n",
      "|    reward             | 0.05986267 |\n",
      "|    std                | 1.63e+15   |\n",
      "|    value_loss         | 0.00828    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 150900      |\n",
      "|    time_elapsed       | 7255        |\n",
      "|    total_timesteps    | 754500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.06e+03   |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 150899      |\n",
      "|    policy_loss        | 80.7        |\n",
      "|    reward             | -0.60722965 |\n",
      "|    std                | 1.67e+15    |\n",
      "|    value_loss         | 0.00721     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 151000     |\n",
      "|    time_elapsed       | 7260       |\n",
      "|    total_timesteps    | 755000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.06e+03  |\n",
      "|    explained_variance | 0.786      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 150999     |\n",
      "|    policy_loss        | -490       |\n",
      "|    reward             | -1.3827102 |\n",
      "|    std                | 1.69e+15   |\n",
      "|    value_loss         | 0.424      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 151100        |\n",
      "|    time_elapsed       | 7264          |\n",
      "|    total_timesteps    | 755500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.06e+03     |\n",
      "|    explained_variance | 0.845         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 151099        |\n",
      "|    policy_loss        | 1.1           |\n",
      "|    reward             | -0.0033819836 |\n",
      "|    std                | 1.72e+15      |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 151200      |\n",
      "|    time_elapsed       | 7269        |\n",
      "|    total_timesteps    | 756000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.06e+03   |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 151199      |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | 0.095572576 |\n",
      "|    std                | 1.77e+15    |\n",
      "|    value_loss         | 4.03e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 151300       |\n",
      "|    time_elapsed       | 7274         |\n",
      "|    total_timesteps    | 756500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.06e+03    |\n",
      "|    explained_variance | 0.449        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 151299       |\n",
      "|    policy_loss        | -36.4        |\n",
      "|    reward             | -0.019153034 |\n",
      "|    std                | 1.81e+15     |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 151400     |\n",
      "|    time_elapsed       | 7279       |\n",
      "|    total_timesteps    | 757000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.06e+03  |\n",
      "|    explained_variance | 0.422      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 151399     |\n",
      "|    policy_loss        | -23.1      |\n",
      "|    reward             | 0.04486131 |\n",
      "|    std                | 1.86e+15   |\n",
      "|    value_loss         | 0.000822   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 151500       |\n",
      "|    time_elapsed       | 7284         |\n",
      "|    total_timesteps    | 757500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.06e+03    |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 151499       |\n",
      "|    policy_loss        | -11.1        |\n",
      "|    reward             | -0.019820021 |\n",
      "|    std                | 1.9e+15      |\n",
      "|    value_loss         | 0.000491     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 151600       |\n",
      "|    time_elapsed       | 7289         |\n",
      "|    total_timesteps    | 758000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.06e+03    |\n",
      "|    explained_variance | -0.747       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 151599       |\n",
      "|    policy_loss        | -20.5        |\n",
      "|    reward             | -0.010995788 |\n",
      "|    std                | 1.93e+15     |\n",
      "|    value_loss         | 0.000495     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 151700        |\n",
      "|    time_elapsed       | 7293          |\n",
      "|    total_timesteps    | 758500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.06e+03     |\n",
      "|    explained_variance | 0.295         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 151699        |\n",
      "|    policy_loss        | -15.1         |\n",
      "|    reward             | -0.0048710746 |\n",
      "|    std                | 1.97e+15      |\n",
      "|    value_loss         | 0.000239      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 151800      |\n",
      "|    time_elapsed       | 7298        |\n",
      "|    total_timesteps    | 759000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.06e+03   |\n",
      "|    explained_variance | 0.744       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 151799      |\n",
      "|    policy_loss        | -10.1       |\n",
      "|    reward             | 0.014289325 |\n",
      "|    std                | 2.02e+15    |\n",
      "|    value_loss         | 0.000232    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 151900       |\n",
      "|    time_elapsed       | 7303         |\n",
      "|    total_timesteps    | 759500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.06e+03    |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 151899       |\n",
      "|    policy_loss        | 62           |\n",
      "|    reward             | -0.033331484 |\n",
      "|    std                | 2.07e+15     |\n",
      "|    value_loss         | 0.00382      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 152000        |\n",
      "|    time_elapsed       | 7308          |\n",
      "|    total_timesteps    | 760000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.06e+03     |\n",
      "|    explained_variance | 0.637         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 151999        |\n",
      "|    policy_loss        | -10.2         |\n",
      "|    reward             | 0.00017311587 |\n",
      "|    std                | 2.13e+15      |\n",
      "|    value_loss         | 0.000279      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 152100      |\n",
      "|    time_elapsed       | 7312        |\n",
      "|    total_timesteps    | 760500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.06e+03   |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 152099      |\n",
      "|    policy_loss        | 79.5        |\n",
      "|    reward             | 0.021748688 |\n",
      "|    std                | 2.17e+15    |\n",
      "|    value_loss         | 0.00634     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 152200        |\n",
      "|    time_elapsed       | 7317          |\n",
      "|    total_timesteps    | 761000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.07e+03     |\n",
      "|    explained_variance | 0.321         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 152199        |\n",
      "|    policy_loss        | 26.9          |\n",
      "|    reward             | -0.0023022883 |\n",
      "|    std                | 2.2e+15       |\n",
      "|    value_loss         | 0.000806      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 152300       |\n",
      "|    time_elapsed       | 7322         |\n",
      "|    total_timesteps    | 761500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.07e+03    |\n",
      "|    explained_variance | 0.27         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 152299       |\n",
      "|    policy_loss        | 24           |\n",
      "|    reward             | 0.0073161703 |\n",
      "|    std                | 2.25e+15     |\n",
      "|    value_loss         | 0.000893     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 152400      |\n",
      "|    time_elapsed       | 7327        |\n",
      "|    total_timesteps    | 762000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.07e+03   |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 152399      |\n",
      "|    policy_loss        | -19.7       |\n",
      "|    reward             | 0.005979088 |\n",
      "|    std                | 2.31e+15    |\n",
      "|    value_loss         | 0.00051     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 152500      |\n",
      "|    time_elapsed       | 7332        |\n",
      "|    total_timesteps    | 762500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.07e+03   |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 152499      |\n",
      "|    policy_loss        | -5.75       |\n",
      "|    reward             | 0.083953336 |\n",
      "|    std                | 2.38e+15    |\n",
      "|    value_loss         | 8.15e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 152600       |\n",
      "|    time_elapsed       | 7337         |\n",
      "|    total_timesteps    | 763000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.07e+03    |\n",
      "|    explained_variance | 0.69         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 152599       |\n",
      "|    policy_loss        | 22.6         |\n",
      "|    reward             | -0.058660623 |\n",
      "|    std                | 2.45e+15     |\n",
      "|    value_loss         | 0.000694     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 152700     |\n",
      "|    time_elapsed       | 7341       |\n",
      "|    total_timesteps    | 763500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.07e+03  |\n",
      "|    explained_variance | 0.562      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 152699     |\n",
      "|    policy_loss        | 29.4       |\n",
      "|    reward             | 0.04382551 |\n",
      "|    std                | 2.52e+15   |\n",
      "|    value_loss         | 0.00249    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 152800       |\n",
      "|    time_elapsed       | 7346         |\n",
      "|    total_timesteps    | 764000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.07e+03    |\n",
      "|    explained_variance | 0.626        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 152799       |\n",
      "|    policy_loss        | -16.5        |\n",
      "|    reward             | 0.0016019332 |\n",
      "|    std                | 2.56e+15     |\n",
      "|    value_loss         | 0.000316     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 152900     |\n",
      "|    time_elapsed       | 7351       |\n",
      "|    total_timesteps    | 764500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.07e+03  |\n",
      "|    explained_variance | 0.894      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 152899     |\n",
      "|    policy_loss        | -4.76      |\n",
      "|    reward             | 0.08635143 |\n",
      "|    std                | 2.62e+15   |\n",
      "|    value_loss         | 7.21e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 153000       |\n",
      "|    time_elapsed       | 7356         |\n",
      "|    total_timesteps    | 765000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.07e+03    |\n",
      "|    explained_variance | 0.303        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 152999       |\n",
      "|    policy_loss        | -67.6        |\n",
      "|    reward             | 0.0041774097 |\n",
      "|    std                | 2.7e+15      |\n",
      "|    value_loss         | 0.00445      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 153100      |\n",
      "|    time_elapsed       | 7361        |\n",
      "|    total_timesteps    | 765500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.07e+03   |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 153099      |\n",
      "|    policy_loss        | 61.4        |\n",
      "|    reward             | -0.17102489 |\n",
      "|    std                | 2.77e+15    |\n",
      "|    value_loss         | 0.00418     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 153200       |\n",
      "|    time_elapsed       | 7365         |\n",
      "|    total_timesteps    | 766000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.07e+03    |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 153199       |\n",
      "|    policy_loss        | -122         |\n",
      "|    reward             | 0.0025084883 |\n",
      "|    std                | 2.83e+15     |\n",
      "|    value_loss         | 0.0133       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 153300      |\n",
      "|    time_elapsed       | 7370        |\n",
      "|    total_timesteps    | 766500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.07e+03   |\n",
      "|    explained_variance | -0.762      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 153299      |\n",
      "|    policy_loss        | 114         |\n",
      "|    reward             | -0.20836075 |\n",
      "|    std                | 2.87e+15    |\n",
      "|    value_loss         | 0.0154      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 153400     |\n",
      "|    time_elapsed       | 7375       |\n",
      "|    total_timesteps    | 767000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.07e+03  |\n",
      "|    explained_variance | 0.634      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 153399     |\n",
      "|    policy_loss        | -6.88      |\n",
      "|    reward             | 0.03761553 |\n",
      "|    std                | 2.9e+15    |\n",
      "|    value_loss         | 0.000254   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 153500      |\n",
      "|    time_elapsed       | 7380        |\n",
      "|    total_timesteps    | 767500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.07e+03   |\n",
      "|    explained_variance | 0.764       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 153499      |\n",
      "|    policy_loss        | -16.5       |\n",
      "|    reward             | 0.005502909 |\n",
      "|    std                | 2.97e+15    |\n",
      "|    value_loss         | 0.000413    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 153600      |\n",
      "|    time_elapsed       | 7385        |\n",
      "|    total_timesteps    | 768000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.07e+03   |\n",
      "|    explained_variance | 0.74        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 153599      |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | 0.016388884 |\n",
      "|    std                | 3.06e+15    |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 153700      |\n",
      "|    time_elapsed       | 7390        |\n",
      "|    total_timesteps    | 768500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.08e+03   |\n",
      "|    explained_variance | -0.981      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 153699      |\n",
      "|    policy_loss        | -29.3       |\n",
      "|    reward             | -0.07618664 |\n",
      "|    std                | 3.17e+15    |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 153800      |\n",
      "|    time_elapsed       | 7394        |\n",
      "|    total_timesteps    | 769000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.08e+03   |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 153799      |\n",
      "|    policy_loss        | -7.48       |\n",
      "|    reward             | 0.049381476 |\n",
      "|    std                | 3.26e+15    |\n",
      "|    value_loss         | 0.000275    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 153900     |\n",
      "|    time_elapsed       | 7399       |\n",
      "|    total_timesteps    | 769500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.08e+03  |\n",
      "|    explained_variance | 0.55       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 153899     |\n",
      "|    policy_loss        | 216        |\n",
      "|    reward             | 0.23415136 |\n",
      "|    std                | 3.32e+15   |\n",
      "|    value_loss         | 0.0632     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 154000     |\n",
      "|    time_elapsed       | 7404       |\n",
      "|    total_timesteps    | 770000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.08e+03  |\n",
      "|    explained_variance | 0.245      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 153999     |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | 0.01382037 |\n",
      "|    std                | 3.39e+15   |\n",
      "|    value_loss         | 0.000485   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 154100        |\n",
      "|    time_elapsed       | 7409          |\n",
      "|    total_timesteps    | 770500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.08e+03     |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 154099        |\n",
      "|    policy_loss        | -10.2         |\n",
      "|    reward             | -0.0040184865 |\n",
      "|    std                | 3.47e+15      |\n",
      "|    value_loss         | 0.00031       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 154200     |\n",
      "|    time_elapsed       | 7414       |\n",
      "|    total_timesteps    | 771000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.08e+03  |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 154199     |\n",
      "|    policy_loss        | -8.26      |\n",
      "|    reward             | 0.12141451 |\n",
      "|    std                | 3.57e+15   |\n",
      "|    value_loss         | 0.000322   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 154300     |\n",
      "|    time_elapsed       | 7418       |\n",
      "|    total_timesteps    | 771500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.08e+03  |\n",
      "|    explained_variance | 0.246      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 154299     |\n",
      "|    policy_loss        | -75.1      |\n",
      "|    reward             | 0.04787944 |\n",
      "|    std                | 3.66e+15   |\n",
      "|    value_loss         | 0.00587    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 154400     |\n",
      "|    time_elapsed       | 7423       |\n",
      "|    total_timesteps    | 772000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.08e+03  |\n",
      "|    explained_variance | 0.706      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 154399     |\n",
      "|    policy_loss        | -77.4      |\n",
      "|    reward             | 0.18906045 |\n",
      "|    std                | 3.75e+15   |\n",
      "|    value_loss         | 0.0062     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 154500       |\n",
      "|    time_elapsed       | 7428         |\n",
      "|    total_timesteps    | 772500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.08e+03    |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 154499       |\n",
      "|    policy_loss        | 2.74         |\n",
      "|    reward             | -0.019520337 |\n",
      "|    std                | 3.8e+15      |\n",
      "|    value_loss         | 2.92e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 154600      |\n",
      "|    time_elapsed       | 7433        |\n",
      "|    total_timesteps    | 773000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.08e+03   |\n",
      "|    explained_variance | -0.0899     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 154599      |\n",
      "|    policy_loss        | 9.65        |\n",
      "|    reward             | 0.009830618 |\n",
      "|    std                | 3.88e+15    |\n",
      "|    value_loss         | 0.000165    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 154700      |\n",
      "|    time_elapsed       | 7438        |\n",
      "|    total_timesteps    | 773500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.08e+03   |\n",
      "|    explained_variance | 0.715       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 154699      |\n",
      "|    policy_loss        | 45.4        |\n",
      "|    reward             | 0.025455775 |\n",
      "|    std                | 3.99e+15    |\n",
      "|    value_loss         | 0.00205     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 154800     |\n",
      "|    time_elapsed       | 7443       |\n",
      "|    total_timesteps    | 774000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.08e+03  |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 154799     |\n",
      "|    policy_loss        | -25.9      |\n",
      "|    reward             | 0.08523008 |\n",
      "|    std                | 4.11e+15   |\n",
      "|    value_loss         | 0.000728   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 154900      |\n",
      "|    time_elapsed       | 7448        |\n",
      "|    total_timesteps    | 774500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.08e+03   |\n",
      "|    explained_variance | 0.442       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 154899      |\n",
      "|    policy_loss        | 1.26        |\n",
      "|    reward             | -0.01660983 |\n",
      "|    std                | 4.23e+15    |\n",
      "|    value_loss         | 0.000339    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 155000       |\n",
      "|    time_elapsed       | 7452         |\n",
      "|    total_timesteps    | 775000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.08e+03    |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 154999       |\n",
      "|    policy_loss        | 30.9         |\n",
      "|    reward             | -0.058405757 |\n",
      "|    std                | 4.33e+15     |\n",
      "|    value_loss         | 0.000915     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 155100      |\n",
      "|    time_elapsed       | 7457        |\n",
      "|    total_timesteps    | 775500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.09e+03   |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 155099      |\n",
      "|    policy_loss        | 9.16        |\n",
      "|    reward             | 0.005773112 |\n",
      "|    std                | 4.4e+15     |\n",
      "|    value_loss         | 8.71e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 155200       |\n",
      "|    time_elapsed       | 7462         |\n",
      "|    total_timesteps    | 776000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.09e+03    |\n",
      "|    explained_variance | 0.68         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 155199       |\n",
      "|    policy_loss        | -4.83        |\n",
      "|    reward             | -0.036748957 |\n",
      "|    std                | 4.5e+15      |\n",
      "|    value_loss         | 0.000473     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 155300       |\n",
      "|    time_elapsed       | 7467         |\n",
      "|    total_timesteps    | 776500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.09e+03    |\n",
      "|    explained_variance | 0.827        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 155299       |\n",
      "|    policy_loss        | 5.77         |\n",
      "|    reward             | 0.0046009994 |\n",
      "|    std                | 4.63e+15     |\n",
      "|    value_loss         | 0.000283     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 155400       |\n",
      "|    time_elapsed       | 7472         |\n",
      "|    total_timesteps    | 777000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.09e+03    |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 155399       |\n",
      "|    policy_loss        | -368         |\n",
      "|    reward             | -0.059276946 |\n",
      "|    std                | 4.78e+15     |\n",
      "|    value_loss         | 0.119        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 155500        |\n",
      "|    time_elapsed       | 7476          |\n",
      "|    total_timesteps    | 777500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.09e+03     |\n",
      "|    explained_variance | 0.868         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 155499        |\n",
      "|    policy_loss        | 5.42          |\n",
      "|    reward             | -0.0015986514 |\n",
      "|    std                | 4.91e+15      |\n",
      "|    value_loss         | 0.000408      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 155600     |\n",
      "|    time_elapsed       | 7481       |\n",
      "|    total_timesteps    | 778000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.09e+03  |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 155599     |\n",
      "|    policy_loss        | -56.6      |\n",
      "|    reward             | 0.20252684 |\n",
      "|    std                | 5.02e+15   |\n",
      "|    value_loss         | 0.00385    |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17567592.04\n",
      "total_reward: 7567592.04\n",
      "total_cost: 561822.22\n",
      "total_trades: 82647\n",
      "Sharpe: 0.518\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 155700      |\n",
      "|    time_elapsed       | 7486        |\n",
      "|    total_timesteps    | 778500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.09e+03   |\n",
      "|    explained_variance | 0.655       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 155699      |\n",
      "|    policy_loss        | -15.1       |\n",
      "|    reward             | 0.012784079 |\n",
      "|    std                | 5.1e+15     |\n",
      "|    value_loss         | 0.000354    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 155800       |\n",
      "|    time_elapsed       | 7491         |\n",
      "|    total_timesteps    | 779000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.09e+03    |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 155799       |\n",
      "|    policy_loss        | 11.2         |\n",
      "|    reward             | -0.009211672 |\n",
      "|    std                | 5.22e+15     |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 155900      |\n",
      "|    time_elapsed       | 7496        |\n",
      "|    total_timesteps    | 779500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.09e+03   |\n",
      "|    explained_variance | 0.45        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 155899      |\n",
      "|    policy_loss        | -114        |\n",
      "|    reward             | 0.080750085 |\n",
      "|    std                | 5.38e+15    |\n",
      "|    value_loss         | 0.0114      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 156000     |\n",
      "|    time_elapsed       | 7501       |\n",
      "|    total_timesteps    | 780000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.09e+03  |\n",
      "|    explained_variance | 0.856      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 155999     |\n",
      "|    policy_loss        | 0.717      |\n",
      "|    reward             | 0.07898206 |\n",
      "|    std                | 5.53e+15   |\n",
      "|    value_loss         | 0.000203   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 156100      |\n",
      "|    time_elapsed       | 7505        |\n",
      "|    total_timesteps    | 780500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.09e+03   |\n",
      "|    explained_variance | 0.771       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 156099      |\n",
      "|    policy_loss        | 107         |\n",
      "|    reward             | -0.06640346 |\n",
      "|    std                | 5.69e+15    |\n",
      "|    value_loss         | 0.0108      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 156200      |\n",
      "|    time_elapsed       | 7510        |\n",
      "|    total_timesteps    | 781000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.09e+03   |\n",
      "|    explained_variance | 0.0311      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 156199      |\n",
      "|    policy_loss        | 258         |\n",
      "|    reward             | -0.11131101 |\n",
      "|    std                | 5.81e+15    |\n",
      "|    value_loss         | 0.0587      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 156300     |\n",
      "|    time_elapsed       | 7515       |\n",
      "|    total_timesteps    | 781500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.09e+03  |\n",
      "|    explained_variance | 0.0283     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 156299     |\n",
      "|    policy_loss        | 25.8       |\n",
      "|    reward             | 0.03853991 |\n",
      "|    std                | 5.92e+15   |\n",
      "|    value_loss         | 0.000935   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 156400       |\n",
      "|    time_elapsed       | 7520         |\n",
      "|    total_timesteps    | 782000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.09e+03    |\n",
      "|    explained_variance | 0.27         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 156399       |\n",
      "|    policy_loss        | -47.8        |\n",
      "|    reward             | -0.018683692 |\n",
      "|    std                | 6.08e+15     |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 156500      |\n",
      "|    time_elapsed       | 7525        |\n",
      "|    total_timesteps    | 782500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.1e+03    |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 156499      |\n",
      "|    policy_loss        | -4.3        |\n",
      "|    reward             | 0.037195474 |\n",
      "|    std                | 6.24e+15    |\n",
      "|    value_loss         | 7.23e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 156600       |\n",
      "|    time_elapsed       | 7529         |\n",
      "|    total_timesteps    | 783000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.1e+03     |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 156599       |\n",
      "|    policy_loss        | 61.1         |\n",
      "|    reward             | -0.012550261 |\n",
      "|    std                | 6.4e+15      |\n",
      "|    value_loss         | 0.00368      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 156700      |\n",
      "|    time_elapsed       | 7534        |\n",
      "|    total_timesteps    | 783500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.1e+03    |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 156699      |\n",
      "|    policy_loss        | -12.6       |\n",
      "|    reward             | 0.026644878 |\n",
      "|    std                | 6.55e+15    |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 156800      |\n",
      "|    time_elapsed       | 7539        |\n",
      "|    total_timesteps    | 784000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.1e+03    |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 156799      |\n",
      "|    policy_loss        | -48.3       |\n",
      "|    reward             | -0.43319583 |\n",
      "|    std                | 6.66e+15    |\n",
      "|    value_loss         | 0.00522     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 156900       |\n",
      "|    time_elapsed       | 7544         |\n",
      "|    total_timesteps    | 784500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.1e+03     |\n",
      "|    explained_variance | -8.85        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 156899       |\n",
      "|    policy_loss        | -27.8        |\n",
      "|    reward             | 0.0077160303 |\n",
      "|    std                | 6.79e+15     |\n",
      "|    value_loss         | 0.000748     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 157000     |\n",
      "|    time_elapsed       | 7549       |\n",
      "|    total_timesteps    | 785000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.1e+03   |\n",
      "|    explained_variance | -3.79      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 156999     |\n",
      "|    policy_loss        | 75.3       |\n",
      "|    reward             | 0.04423597 |\n",
      "|    std                | 6.98e+15   |\n",
      "|    value_loss         | 0.00836    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 157100      |\n",
      "|    time_elapsed       | 7553        |\n",
      "|    total_timesteps    | 785500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.1e+03    |\n",
      "|    explained_variance | -0.00869    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 157099      |\n",
      "|    policy_loss        | 19.6        |\n",
      "|    reward             | -0.15266123 |\n",
      "|    std                | 7.18e+15    |\n",
      "|    value_loss         | 0.000648    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 157200     |\n",
      "|    time_elapsed       | 7558       |\n",
      "|    total_timesteps    | 786000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.1e+03   |\n",
      "|    explained_variance | 0.0209     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 157199     |\n",
      "|    policy_loss        | 64.5       |\n",
      "|    reward             | 0.19099177 |\n",
      "|    std                | 7.38e+15   |\n",
      "|    value_loss         | 0.004      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 157300    |\n",
      "|    time_elapsed       | 7563      |\n",
      "|    total_timesteps    | 786500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.1e+03  |\n",
      "|    explained_variance | 0.994     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 157299    |\n",
      "|    policy_loss        | 142       |\n",
      "|    reward             | 0.1682227 |\n",
      "|    std                | 7.51e+15  |\n",
      "|    value_loss         | 0.0174    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 157400       |\n",
      "|    time_elapsed       | 7568         |\n",
      "|    total_timesteps    | 787000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.1e+03     |\n",
      "|    explained_variance | -0.032       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 157399       |\n",
      "|    policy_loss        | 13.5         |\n",
      "|    reward             | -0.001919121 |\n",
      "|    std                | 7.6e+15      |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 157500       |\n",
      "|    time_elapsed       | 7573         |\n",
      "|    total_timesteps    | 787500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.1e+03     |\n",
      "|    explained_variance | -0.714       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 157499       |\n",
      "|    policy_loss        | -14.7        |\n",
      "|    reward             | 0.0016605615 |\n",
      "|    std                | 7.74e+15     |\n",
      "|    value_loss         | 0.000615     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 157600       |\n",
      "|    time_elapsed       | 7577         |\n",
      "|    total_timesteps    | 788000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.1e+03     |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 157599       |\n",
      "|    policy_loss        | 7.46         |\n",
      "|    reward             | -0.010702709 |\n",
      "|    std                | 7.95e+15     |\n",
      "|    value_loss         | 0.00026      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 157700        |\n",
      "|    time_elapsed       | 7582          |\n",
      "|    total_timesteps    | 788500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.1e+03      |\n",
      "|    explained_variance | 0.982         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 157699        |\n",
      "|    policy_loss        | 26.8          |\n",
      "|    reward             | -0.0044725253 |\n",
      "|    std                | 8.17e+15      |\n",
      "|    value_loss         | 0.000657      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 157800      |\n",
      "|    time_elapsed       | 7587        |\n",
      "|    total_timesteps    | 789000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.1e+03    |\n",
      "|    explained_variance | 0.465       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 157799      |\n",
      "|    policy_loss        | -46.5       |\n",
      "|    reward             | 0.004826111 |\n",
      "|    std                | 8.37e+15    |\n",
      "|    value_loss         | 0.00239     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 157900     |\n",
      "|    time_elapsed       | 7592       |\n",
      "|    total_timesteps    | 789500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.1e+03   |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 157899     |\n",
      "|    policy_loss        | -32.9      |\n",
      "|    reward             | -0.1327274 |\n",
      "|    std                | 8.5e+15    |\n",
      "|    value_loss         | 0.00105    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 158000       |\n",
      "|    time_elapsed       | 7597         |\n",
      "|    total_timesteps    | 790000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.1e+03     |\n",
      "|    explained_variance | -0.732       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 157999       |\n",
      "|    policy_loss        | -9.18        |\n",
      "|    reward             | 0.0016919231 |\n",
      "|    std                | 8.6e+15      |\n",
      "|    value_loss         | 0.000299     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 158100     |\n",
      "|    time_elapsed       | 7601       |\n",
      "|    total_timesteps    | 790500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.887      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 158099     |\n",
      "|    policy_loss        | 35.8       |\n",
      "|    reward             | 0.10749663 |\n",
      "|    std                | 8.77e+15   |\n",
      "|    value_loss         | 0.00109    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 158200     |\n",
      "|    time_elapsed       | 7606       |\n",
      "|    total_timesteps    | 791000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.728      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 158199     |\n",
      "|    policy_loss        | 2.58       |\n",
      "|    reward             | 0.04341287 |\n",
      "|    std                | 8.99e+15   |\n",
      "|    value_loss         | 0.000359   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 158300     |\n",
      "|    time_elapsed       | 7611       |\n",
      "|    total_timesteps    | 791500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.923      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 158299     |\n",
      "|    policy_loss        | -20.8      |\n",
      "|    reward             | -0.0717858 |\n",
      "|    std                | 9.25e+15   |\n",
      "|    value_loss         | 0.00155    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 158400      |\n",
      "|    time_elapsed       | 7617        |\n",
      "|    total_timesteps    | 792000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.11e+03   |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 158399      |\n",
      "|    policy_loss        | -74.3       |\n",
      "|    reward             | 0.018109988 |\n",
      "|    std                | 9.45e+15    |\n",
      "|    value_loss         | 0.00505     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 158500     |\n",
      "|    time_elapsed       | 7622       |\n",
      "|    total_timesteps    | 792500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 158499     |\n",
      "|    policy_loss        | -139       |\n",
      "|    reward             | 0.10738976 |\n",
      "|    std                | 9.58e+15   |\n",
      "|    value_loss         | 0.0222     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 158600      |\n",
      "|    time_elapsed       | 7627        |\n",
      "|    total_timesteps    | 793000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.11e+03   |\n",
      "|    explained_variance | -2.53       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 158599      |\n",
      "|    policy_loss        | 7.51        |\n",
      "|    reward             | 0.011877947 |\n",
      "|    std                | 9.7e+15     |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 158700      |\n",
      "|    time_elapsed       | 7631        |\n",
      "|    total_timesteps    | 793500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.11e+03   |\n",
      "|    explained_variance | 0.613       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 158699      |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.019940034 |\n",
      "|    std                | 9.9e+15     |\n",
      "|    value_loss         | 0.00012     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 158800     |\n",
      "|    time_elapsed       | 7636       |\n",
      "|    total_timesteps    | 794000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.541      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 158799     |\n",
      "|    policy_loss        | -3.27      |\n",
      "|    reward             | 0.06269578 |\n",
      "|    std                | 1.02e+16   |\n",
      "|    value_loss         | 0.000221   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 158900      |\n",
      "|    time_elapsed       | 7641        |\n",
      "|    total_timesteps    | 794500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.11e+03   |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 158899      |\n",
      "|    policy_loss        | -37.4       |\n",
      "|    reward             | 0.013268715 |\n",
      "|    std                | 1.05e+16    |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 159000      |\n",
      "|    time_elapsed       | 7646        |\n",
      "|    total_timesteps    | 795000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.11e+03   |\n",
      "|    explained_variance | 0.803       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 158999      |\n",
      "|    policy_loss        | -8.63       |\n",
      "|    reward             | 0.051855765 |\n",
      "|    std                | 1.07e+16    |\n",
      "|    value_loss         | 0.00363     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 159100     |\n",
      "|    time_elapsed       | 7651       |\n",
      "|    total_timesteps    | 795500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.0837     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 159099     |\n",
      "|    policy_loss        | -766       |\n",
      "|    reward             | -1.7705833 |\n",
      "|    std                | 1.09e+16   |\n",
      "|    value_loss         | 0.558      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 159200       |\n",
      "|    time_elapsed       | 7656         |\n",
      "|    total_timesteps    | 796000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.11e+03    |\n",
      "|    explained_variance | -0.125       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 159199       |\n",
      "|    policy_loss        | -2.66        |\n",
      "|    reward             | 0.0074960557 |\n",
      "|    std                | 1.11e+16     |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 159300       |\n",
      "|    time_elapsed       | 7660         |\n",
      "|    total_timesteps    | 796500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.11e+03    |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 159299       |\n",
      "|    policy_loss        | -0.962       |\n",
      "|    reward             | -0.011283148 |\n",
      "|    std                | 1.14e+16     |\n",
      "|    value_loss         | 3.05e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 159400     |\n",
      "|    time_elapsed       | 7665       |\n",
      "|    total_timesteps    | 797000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11e+03  |\n",
      "|    explained_variance | 0.402      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 159399     |\n",
      "|    policy_loss        | -6.4       |\n",
      "|    reward             | -0.0163791 |\n",
      "|    std                | 1.18e+16   |\n",
      "|    value_loss         | 0.000241   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 159500       |\n",
      "|    time_elapsed       | 7670         |\n",
      "|    total_timesteps    | 797500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.11e+03    |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 159499       |\n",
      "|    policy_loss        | 11.3         |\n",
      "|    reward             | -0.002976681 |\n",
      "|    std                | 1.22e+16     |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 159600      |\n",
      "|    time_elapsed       | 7677        |\n",
      "|    total_timesteps    | 798000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 159599      |\n",
      "|    policy_loss        | -10.4       |\n",
      "|    reward             | 0.035102867 |\n",
      "|    std                | 1.25e+16    |\n",
      "|    value_loss         | 0.00106     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 159700        |\n",
      "|    time_elapsed       | 7681          |\n",
      "|    total_timesteps    | 798500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.12e+03     |\n",
      "|    explained_variance | 0.314         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 159699        |\n",
      "|    policy_loss        | -2.52         |\n",
      "|    reward             | -0.0027988597 |\n",
      "|    std                | 1.27e+16      |\n",
      "|    value_loss         | 4.78e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 159800      |\n",
      "|    time_elapsed       | 7686        |\n",
      "|    total_timesteps    | 799000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 159799      |\n",
      "|    policy_loss        | 18.1        |\n",
      "|    reward             | 0.013948278 |\n",
      "|    std                | 1.29e+16    |\n",
      "|    value_loss         | 0.000291    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 159900      |\n",
      "|    time_elapsed       | 7691        |\n",
      "|    total_timesteps    | 799500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | -0.149      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 159899      |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | 0.022392467 |\n",
      "|    std                | 1.33e+16    |\n",
      "|    value_loss         | 0.000324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 160000      |\n",
      "|    time_elapsed       | 7696        |\n",
      "|    total_timesteps    | 800000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 159999      |\n",
      "|    policy_loss        | -19.9       |\n",
      "|    reward             | 0.009159373 |\n",
      "|    std                | 1.37e+16    |\n",
      "|    value_loss         | 0.000572    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 160100      |\n",
      "|    time_elapsed       | 7701        |\n",
      "|    total_timesteps    | 800500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 160099      |\n",
      "|    policy_loss        | -2.27       |\n",
      "|    reward             | -0.08005761 |\n",
      "|    std                | 1.41e+16    |\n",
      "|    value_loss         | 0.000414    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 160200     |\n",
      "|    time_elapsed       | 7705       |\n",
      "|    total_timesteps    | 801000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.12e+03  |\n",
      "|    explained_variance | 0.756      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 160199     |\n",
      "|    policy_loss        | 85.8       |\n",
      "|    reward             | 0.18038002 |\n",
      "|    std                | 1.43e+16   |\n",
      "|    value_loss         | 0.00804    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 160300     |\n",
      "|    time_elapsed       | 7710       |\n",
      "|    total_timesteps    | 801500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.12e+03  |\n",
      "|    explained_variance | 0.568      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 160299     |\n",
      "|    policy_loss        | 17         |\n",
      "|    reward             | 0.01431613 |\n",
      "|    std                | 1.45e+16   |\n",
      "|    value_loss         | 0.000296   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 160400       |\n",
      "|    time_elapsed       | 7715         |\n",
      "|    total_timesteps    | 802000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.12e+03    |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 160399       |\n",
      "|    policy_loss        | 50           |\n",
      "|    reward             | -0.030408535 |\n",
      "|    std                | 1.48e+16     |\n",
      "|    value_loss         | 0.00202      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 160500       |\n",
      "|    time_elapsed       | 7720         |\n",
      "|    total_timesteps    | 802500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.12e+03    |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 160499       |\n",
      "|    policy_loss        | 8.34         |\n",
      "|    reward             | 0.0069423784 |\n",
      "|    std                | 1.52e+16     |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 160600      |\n",
      "|    time_elapsed       | 7725        |\n",
      "|    total_timesteps    | 803000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 160599      |\n",
      "|    policy_loss        | -1.75       |\n",
      "|    reward             | 0.026144171 |\n",
      "|    std                | 1.57e+16    |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 160700     |\n",
      "|    time_elapsed       | 7729       |\n",
      "|    total_timesteps    | 803500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.12e+03  |\n",
      "|    explained_variance | 0.782      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 160699     |\n",
      "|    policy_loss        | 9.83       |\n",
      "|    reward             | 0.07176452 |\n",
      "|    std                | 1.61e+16   |\n",
      "|    value_loss         | 0.000179   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 160800     |\n",
      "|    time_elapsed       | 7734       |\n",
      "|    total_timesteps    | 804000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.12e+03  |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 160799     |\n",
      "|    policy_loss        | -56.3      |\n",
      "|    reward             | 0.05417389 |\n",
      "|    std                | 1.64e+16   |\n",
      "|    value_loss         | 0.00452    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 160900      |\n",
      "|    time_elapsed       | 7739        |\n",
      "|    total_timesteps    | 804500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.12e+03   |\n",
      "|    explained_variance | 0.699       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 160899      |\n",
      "|    policy_loss        | -6.77       |\n",
      "|    reward             | 0.001241673 |\n",
      "|    std                | 1.67e+16    |\n",
      "|    value_loss         | 5.31e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 161000        |\n",
      "|    time_elapsed       | 7744          |\n",
      "|    total_timesteps    | 805000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.12e+03     |\n",
      "|    explained_variance | 0.821         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 160999        |\n",
      "|    policy_loss        | -23.8         |\n",
      "|    reward             | -0.0063201687 |\n",
      "|    std                | 1.71e+16      |\n",
      "|    value_loss         | 0.000546      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 161100       |\n",
      "|    time_elapsed       | 7749         |\n",
      "|    total_timesteps    | 805500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | 0.727        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 161099       |\n",
      "|    policy_loss        | -39.5        |\n",
      "|    reward             | 0.0039016416 |\n",
      "|    std                | 1.76e+16     |\n",
      "|    value_loss         | 0.0016       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 161200      |\n",
      "|    time_elapsed       | 7754        |\n",
      "|    total_timesteps    | 806000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.13e+03   |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 161199      |\n",
      "|    policy_loss        | -3.75       |\n",
      "|    reward             | -0.08208534 |\n",
      "|    std                | 1.81e+16    |\n",
      "|    value_loss         | 0.000127    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 161300    |\n",
      "|    time_elapsed       | 7758      |\n",
      "|    total_timesteps    | 806500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13e+03 |\n",
      "|    explained_variance | 0.337     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 161299    |\n",
      "|    policy_loss        | 42.3      |\n",
      "|    reward             | 0.1165232 |\n",
      "|    std                | 1.86e+16  |\n",
      "|    value_loss         | 0.00325   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 161400       |\n",
      "|    time_elapsed       | 7763         |\n",
      "|    total_timesteps    | 807000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | 0.155        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 161399       |\n",
      "|    policy_loss        | -149         |\n",
      "|    reward             | -0.059865445 |\n",
      "|    std                | 1.89e+16     |\n",
      "|    value_loss         | 0.0243       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15816874.94\n",
      "total_reward: 5816874.94\n",
      "total_cost: 561713.48\n",
      "total_trades: 82457\n",
      "Sharpe: 0.440\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 161500       |\n",
      "|    time_elapsed       | 7768         |\n",
      "|    total_timesteps    | 807500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 161499       |\n",
      "|    policy_loss        | -50.7        |\n",
      "|    reward             | -0.019498779 |\n",
      "|    std                | 1.92e+16     |\n",
      "|    value_loss         | 0.00239      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 161600       |\n",
      "|    time_elapsed       | 7773         |\n",
      "|    total_timesteps    | 808000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | 0.698        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 161599       |\n",
      "|    policy_loss        | 9.19         |\n",
      "|    reward             | 0.0069231614 |\n",
      "|    std                | 1.97e+16     |\n",
      "|    value_loss         | 0.000547     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 161700       |\n",
      "|    time_elapsed       | 7778         |\n",
      "|    total_timesteps    | 808500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 161699       |\n",
      "|    policy_loss        | 14.6         |\n",
      "|    reward             | -0.053740863 |\n",
      "|    std                | 2.02e+16     |\n",
      "|    value_loss         | 0.000501     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 161800      |\n",
      "|    time_elapsed       | 7783        |\n",
      "|    total_timesteps    | 809000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.13e+03   |\n",
      "|    explained_variance | 0.596       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 161799      |\n",
      "|    policy_loss        | -44.3       |\n",
      "|    reward             | -0.12276473 |\n",
      "|    std                | 2.07e+16    |\n",
      "|    value_loss         | 0.00493     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 161900     |\n",
      "|    time_elapsed       | 7787       |\n",
      "|    total_timesteps    | 809500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.13e+03  |\n",
      "|    explained_variance | 0.788      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 161899     |\n",
      "|    policy_loss        | -57.2      |\n",
      "|    reward             | 0.18477534 |\n",
      "|    std                | 2.11e+16   |\n",
      "|    value_loss         | 0.00594    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 162000     |\n",
      "|    time_elapsed       | 7792       |\n",
      "|    total_timesteps    | 810000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.13e+03  |\n",
      "|    explained_variance | 0.412      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 161999     |\n",
      "|    policy_loss        | 470        |\n",
      "|    reward             | 0.15231362 |\n",
      "|    std                | 2.13e+16   |\n",
      "|    value_loss         | 0.224      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 162100       |\n",
      "|    time_elapsed       | 7797         |\n",
      "|    total_timesteps    | 810500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | -1.17        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 162099       |\n",
      "|    policy_loss        | -9.8         |\n",
      "|    reward             | 0.0035002881 |\n",
      "|    std                | 2.17e+16     |\n",
      "|    value_loss         | 0.000413     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 162200       |\n",
      "|    time_elapsed       | 7802         |\n",
      "|    total_timesteps    | 811000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.13e+03    |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 162199       |\n",
      "|    policy_loss        | -45.9        |\n",
      "|    reward             | -0.077382185 |\n",
      "|    std                | 2.22e+16     |\n",
      "|    value_loss         | 0.00174      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 162300    |\n",
      "|    time_elapsed       | 7807      |\n",
      "|    total_timesteps    | 811500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13e+03 |\n",
      "|    explained_variance | 0.772     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 162299    |\n",
      "|    policy_loss        | 51.1      |\n",
      "|    reward             | 0.174822  |\n",
      "|    std                | 2.28e+16  |\n",
      "|    value_loss         | 0.00635   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 162400     |\n",
      "|    time_elapsed       | 7812       |\n",
      "|    total_timesteps    | 812000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.13e+03  |\n",
      "|    explained_variance | 0.896      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 162399     |\n",
      "|    policy_loss        | -25.5      |\n",
      "|    reward             | 0.02671769 |\n",
      "|    std                | 2.34e+16   |\n",
      "|    value_loss         | 0.000575   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 162500     |\n",
      "|    time_elapsed       | 7817       |\n",
      "|    total_timesteps    | 812500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.13e+03  |\n",
      "|    explained_variance | 0.127      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 162499     |\n",
      "|    policy_loss        | 329        |\n",
      "|    reward             | -0.8392931 |\n",
      "|    std                | 2.39e+16   |\n",
      "|    value_loss         | 0.113      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 162600      |\n",
      "|    time_elapsed       | 7821        |\n",
      "|    total_timesteps    | 813000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.13e+03   |\n",
      "|    explained_variance | -0.241      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 162599      |\n",
      "|    policy_loss        | 19.3        |\n",
      "|    reward             | 0.020059114 |\n",
      "|    std                | 2.41e+16    |\n",
      "|    value_loss         | 0.000435    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 162700      |\n",
      "|    time_elapsed       | 7826        |\n",
      "|    total_timesteps    | 813500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.13e+03   |\n",
      "|    explained_variance | -0.862      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 162699      |\n",
      "|    policy_loss        | 23.7        |\n",
      "|    reward             | 0.002692719 |\n",
      "|    std                | 2.45e+16    |\n",
      "|    value_loss         | 0.000728    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 162800    |\n",
      "|    time_elapsed       | 7831      |\n",
      "|    total_timesteps    | 814000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.14e+03 |\n",
      "|    explained_variance | 0.124     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 162799    |\n",
      "|    policy_loss        | 2.1       |\n",
      "|    reward             | 0.0529044 |\n",
      "|    std                | 2.51e+16  |\n",
      "|    value_loss         | 0.000255  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 162900       |\n",
      "|    time_elapsed       | 7836         |\n",
      "|    total_timesteps    | 814500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.14e+03    |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 162899       |\n",
      "|    policy_loss        | 5.2          |\n",
      "|    reward             | -0.024339171 |\n",
      "|    std                | 2.58e+16     |\n",
      "|    value_loss         | 0.000283     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 163000     |\n",
      "|    time_elapsed       | 7841       |\n",
      "|    total_timesteps    | 815000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.14e+03  |\n",
      "|    explained_variance | 0.445      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 162999     |\n",
      "|    policy_loss        | 29.1       |\n",
      "|    reward             | -0.1149876 |\n",
      "|    std                | 2.64e+16   |\n",
      "|    value_loss         | 0.000773   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 163100     |\n",
      "|    time_elapsed       | 7846       |\n",
      "|    total_timesteps    | 815500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.14e+03  |\n",
      "|    explained_variance | 0.568      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 163099     |\n",
      "|    policy_loss        | 90         |\n",
      "|    reward             | 0.04078873 |\n",
      "|    std                | 2.69e+16   |\n",
      "|    value_loss         | 0.0137     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 163200        |\n",
      "|    time_elapsed       | 7850          |\n",
      "|    total_timesteps    | 816000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.14e+03     |\n",
      "|    explained_variance | 0.673         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 163199        |\n",
      "|    policy_loss        | -13.7         |\n",
      "|    reward             | -0.0055850353 |\n",
      "|    std                | 2.72e+16      |\n",
      "|    value_loss         | 0.000261      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 163300       |\n",
      "|    time_elapsed       | 7855         |\n",
      "|    total_timesteps    | 816500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.14e+03    |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 163299       |\n",
      "|    policy_loss        | 33.4         |\n",
      "|    reward             | -0.025872856 |\n",
      "|    std                | 2.78e+16     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 163400      |\n",
      "|    time_elapsed       | 7860        |\n",
      "|    total_timesteps    | 817000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.14e+03   |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 163399      |\n",
      "|    policy_loss        | 4.68        |\n",
      "|    reward             | 0.027855627 |\n",
      "|    std                | 2.86e+16    |\n",
      "|    value_loss         | 7.16e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 163500     |\n",
      "|    time_elapsed       | 7865       |\n",
      "|    total_timesteps    | 817500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.14e+03  |\n",
      "|    explained_variance | 0.59       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 163499     |\n",
      "|    policy_loss        | 8.76       |\n",
      "|    reward             | 0.18095863 |\n",
      "|    std                | 2.94e+16   |\n",
      "|    value_loss         | 0.000502   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 163600     |\n",
      "|    time_elapsed       | 7869       |\n",
      "|    total_timesteps    | 818000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.14e+03  |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 163599     |\n",
      "|    policy_loss        | -22.8      |\n",
      "|    reward             | 0.10697064 |\n",
      "|    std                | 3.02e+16   |\n",
      "|    value_loss         | 0.000689   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 163700     |\n",
      "|    time_elapsed       | 7874       |\n",
      "|    total_timesteps    | 818500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.14e+03  |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 163699     |\n",
      "|    policy_loss        | -21.3      |\n",
      "|    reward             | 0.17701663 |\n",
      "|    std                | 3.08e+16   |\n",
      "|    value_loss         | 0.00182    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 163800    |\n",
      "|    time_elapsed       | 7879      |\n",
      "|    total_timesteps    | 819000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.14e+03 |\n",
      "|    explained_variance | 0.334     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 163799    |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    reward             | 0.0252507 |\n",
      "|    std                | 3.13e+16  |\n",
      "|    value_loss         | 0.000456  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 163900       |\n",
      "|    time_elapsed       | 7884         |\n",
      "|    total_timesteps    | 819500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.14e+03    |\n",
      "|    explained_variance | 0.636        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 163899       |\n",
      "|    policy_loss        | 13.6         |\n",
      "|    reward             | 0.0033449805 |\n",
      "|    std                | 3.2e+16      |\n",
      "|    value_loss         | 0.000202     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 164000      |\n",
      "|    time_elapsed       | 7889        |\n",
      "|    total_timesteps    | 820000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.14e+03   |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 163999      |\n",
      "|    policy_loss        | -113        |\n",
      "|    reward             | 0.005611287 |\n",
      "|    std                | 3.29e+16    |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 164100      |\n",
      "|    time_elapsed       | 7893        |\n",
      "|    total_timesteps    | 820500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.14e+03   |\n",
      "|    explained_variance | 0.425       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 164099      |\n",
      "|    policy_loss        | 16.8        |\n",
      "|    reward             | 0.019900642 |\n",
      "|    std                | 3.39e+16    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 164200     |\n",
      "|    time_elapsed       | 7898       |\n",
      "|    total_timesteps    | 821000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.15e+03  |\n",
      "|    explained_variance | 0.68       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 164199     |\n",
      "|    policy_loss        | 250        |\n",
      "|    reward             | 0.06504995 |\n",
      "|    std                | 3.48e+16   |\n",
      "|    value_loss         | 0.0599     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 164300       |\n",
      "|    time_elapsed       | 7903         |\n",
      "|    total_timesteps    | 821500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.15e+03    |\n",
      "|    explained_variance | 0.36         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 164299       |\n",
      "|    policy_loss        | -163         |\n",
      "|    reward             | -0.023998927 |\n",
      "|    std                | 3.53e+16     |\n",
      "|    value_loss         | 0.0273       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 164400      |\n",
      "|    time_elapsed       | 7908        |\n",
      "|    total_timesteps    | 822000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.15e+03   |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 164399      |\n",
      "|    policy_loss        | 20.8        |\n",
      "|    reward             | 0.019513333 |\n",
      "|    std                | 3.59e+16    |\n",
      "|    value_loss         | 0.000421    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 164500       |\n",
      "|    time_elapsed       | 7913         |\n",
      "|    total_timesteps    | 822500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.15e+03    |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 164499       |\n",
      "|    policy_loss        | -2.86        |\n",
      "|    reward             | -0.021513723 |\n",
      "|    std                | 3.67e+16     |\n",
      "|    value_loss         | 9.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 164600       |\n",
      "|    time_elapsed       | 7917         |\n",
      "|    total_timesteps    | 823000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.15e+03    |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 164599       |\n",
      "|    policy_loss        | 14.6         |\n",
      "|    reward             | -0.029668018 |\n",
      "|    std                | 3.77e+16     |\n",
      "|    value_loss         | 0.000244     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 164700      |\n",
      "|    time_elapsed       | 7922        |\n",
      "|    total_timesteps    | 823500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.15e+03   |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 164699      |\n",
      "|    policy_loss        | -50.8       |\n",
      "|    reward             | -0.04499319 |\n",
      "|    std                | 3.88e+16    |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 164800      |\n",
      "|    time_elapsed       | 7927        |\n",
      "|    total_timesteps    | 824000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.15e+03   |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 164799      |\n",
      "|    policy_loss        | -115        |\n",
      "|    reward             | 0.055944577 |\n",
      "|    std                | 3.98e+16    |\n",
      "|    value_loss         | 0.013       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 164900     |\n",
      "|    time_elapsed       | 7932       |\n",
      "|    total_timesteps    | 824500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.15e+03  |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 164899     |\n",
      "|    policy_loss        | -29.8      |\n",
      "|    reward             | -0.6135972 |\n",
      "|    std                | 4.03e+16   |\n",
      "|    value_loss         | 0.0163     |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 103            |\n",
      "|    iterations         | 165000         |\n",
      "|    time_elapsed       | 7937           |\n",
      "|    total_timesteps    | 825000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.15e+03      |\n",
      "|    explained_variance | 0.645          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 164999         |\n",
      "|    policy_loss        | 6.95           |\n",
      "|    reward             | -0.00026840702 |\n",
      "|    std                | 4.11e+16       |\n",
      "|    value_loss         | 4.96e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 165100       |\n",
      "|    time_elapsed       | 7942         |\n",
      "|    total_timesteps    | 825500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.15e+03    |\n",
      "|    explained_variance | -9.49        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 165099       |\n",
      "|    policy_loss        | 82.2         |\n",
      "|    reward             | -0.016224574 |\n",
      "|    std                | 4.22e+16     |\n",
      "|    value_loss         | 0.00702      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 165200      |\n",
      "|    time_elapsed       | 7946        |\n",
      "|    total_timesteps    | 826000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.15e+03   |\n",
      "|    explained_variance | -4.58       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 165199      |\n",
      "|    policy_loss        | -35.7       |\n",
      "|    reward             | -0.12765668 |\n",
      "|    std                | 4.35e+16    |\n",
      "|    value_loss         | 0.0033      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 165300     |\n",
      "|    time_elapsed       | 7951       |\n",
      "|    total_timesteps    | 826500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.15e+03  |\n",
      "|    explained_variance | -3.77      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 165299     |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | 0.05533448 |\n",
      "|    std                | 4.48e+16   |\n",
      "|    value_loss         | 0.000321   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 165400     |\n",
      "|    time_elapsed       | 7956       |\n",
      "|    total_timesteps    | 827000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.15e+03  |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 165399     |\n",
      "|    policy_loss        | -28.1      |\n",
      "|    reward             | 0.05061382 |\n",
      "|    std                | 4.59e+16   |\n",
      "|    value_loss         | 0.00284    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 165500      |\n",
      "|    time_elapsed       | 7961        |\n",
      "|    total_timesteps    | 827500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.15e+03   |\n",
      "|    explained_variance | 0.227       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 165499      |\n",
      "|    policy_loss        | -14.8       |\n",
      "|    reward             | 0.018270869 |\n",
      "|    std                | 4.67e+16    |\n",
      "|    value_loss         | 0.000217    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 165600        |\n",
      "|    time_elapsed       | 7966          |\n",
      "|    total_timesteps    | 828000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.15e+03     |\n",
      "|    explained_variance | 0.805         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 165599        |\n",
      "|    policy_loss        | -23.7         |\n",
      "|    reward             | -0.0024974917 |\n",
      "|    std                | 4.77e+16      |\n",
      "|    value_loss         | 0.000492      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 165700      |\n",
      "|    time_elapsed       | 7971        |\n",
      "|    total_timesteps    | 828500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.15e+03   |\n",
      "|    explained_variance | -3.71       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 165699      |\n",
      "|    policy_loss        | 12.9        |\n",
      "|    reward             | 0.030835323 |\n",
      "|    std                | 4.89e+16    |\n",
      "|    value_loss         | 0.000356    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 165800      |\n",
      "|    time_elapsed       | 7976        |\n",
      "|    total_timesteps    | 829000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.69        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 165799      |\n",
      "|    policy_loss        | -22.3       |\n",
      "|    reward             | 0.025640685 |\n",
      "|    std                | 5.04e+16    |\n",
      "|    value_loss         | 0.000546    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 103            |\n",
      "|    iterations         | 165900         |\n",
      "|    time_elapsed       | 7980           |\n",
      "|    total_timesteps    | 829500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.16e+03      |\n",
      "|    explained_variance | 0.663          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 165899         |\n",
      "|    policy_loss        | 8.49           |\n",
      "|    reward             | -0.00041102036 |\n",
      "|    std                | 5.19e+16       |\n",
      "|    value_loss         | 0.000132       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 166000      |\n",
      "|    time_elapsed       | 7985        |\n",
      "|    total_timesteps    | 830000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 165999      |\n",
      "|    policy_loss        | 42.5        |\n",
      "|    reward             | -0.30773485 |\n",
      "|    std                | 5.3e+16     |\n",
      "|    value_loss         | 0.00147     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 166100      |\n",
      "|    time_elapsed       | 7990        |\n",
      "|    total_timesteps    | 830500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.287       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 166099      |\n",
      "|    policy_loss        | -7.78       |\n",
      "|    reward             | -0.04510579 |\n",
      "|    std                | 5.39e+16    |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 166200      |\n",
      "|    time_elapsed       | 7995        |\n",
      "|    total_timesteps    | 831000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.45        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 166199      |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.05641251 |\n",
      "|    std                | 5.51e+16    |\n",
      "|    value_loss         | 0.000718    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 166300    |\n",
      "|    time_elapsed       | 8000      |\n",
      "|    total_timesteps    | 831500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.16e+03 |\n",
      "|    explained_variance | 0.704     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 166299    |\n",
      "|    policy_loss        | 20.4      |\n",
      "|    reward             | 0.0627115 |\n",
      "|    std                | 5.66e+16  |\n",
      "|    value_loss         | 0.00388   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 166400      |\n",
      "|    time_elapsed       | 8004        |\n",
      "|    total_timesteps    | 832000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 166399      |\n",
      "|    policy_loss        | 126         |\n",
      "|    reward             | 0.038334537 |\n",
      "|    std                | 5.81e+16    |\n",
      "|    value_loss         | 0.0148      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 166500      |\n",
      "|    time_elapsed       | 8009        |\n",
      "|    total_timesteps    | 832500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 166499      |\n",
      "|    policy_loss        | -21         |\n",
      "|    reward             | 0.017237483 |\n",
      "|    std                | 5.93e+16    |\n",
      "|    value_loss         | 0.000772    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 166600      |\n",
      "|    time_elapsed       | 8014        |\n",
      "|    total_timesteps    | 833000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 166599      |\n",
      "|    policy_loss        | 266         |\n",
      "|    reward             | -0.29894426 |\n",
      "|    std                | 6.02e+16    |\n",
      "|    value_loss         | 0.0527      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 166700       |\n",
      "|    time_elapsed       | 8019         |\n",
      "|    total_timesteps    | 833500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.16e+03    |\n",
      "|    explained_variance | 0.483        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 166699       |\n",
      "|    policy_loss        | 6.22         |\n",
      "|    reward             | -0.008871564 |\n",
      "|    std                | 6.1e+16      |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 166800       |\n",
      "|    time_elapsed       | 8024         |\n",
      "|    total_timesteps    | 834000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.16e+03    |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 166799       |\n",
      "|    policy_loss        | -49.1        |\n",
      "|    reward             | 0.0028095108 |\n",
      "|    std                | 6.24e+16     |\n",
      "|    value_loss         | 0.0018       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 166900       |\n",
      "|    time_elapsed       | 8029         |\n",
      "|    total_timesteps    | 834500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.16e+03    |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 166899       |\n",
      "|    policy_loss        | -18.4        |\n",
      "|    reward             | -0.009424509 |\n",
      "|    std                | 6.4e+16      |\n",
      "|    value_loss         | 0.000518     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 167000      |\n",
      "|    time_elapsed       | 8033        |\n",
      "|    total_timesteps    | 835000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 166999      |\n",
      "|    policy_loss        | 28.2        |\n",
      "|    reward             | -0.02224947 |\n",
      "|    std                | 6.6e+16     |\n",
      "|    value_loss         | 0.000791    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 167100      |\n",
      "|    time_elapsed       | 8038        |\n",
      "|    total_timesteps    | 835500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.16e+03   |\n",
      "|    explained_variance | 0.604       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 167099      |\n",
      "|    policy_loss        | -62.7       |\n",
      "|    reward             | 0.032153048 |\n",
      "|    std                | 6.77e+16    |\n",
      "|    value_loss         | 0.00505     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 167200     |\n",
      "|    time_elapsed       | 8043       |\n",
      "|    total_timesteps    | 836000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.16e+03  |\n",
      "|    explained_variance | 0.418      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 167199     |\n",
      "|    policy_loss        | -93.6      |\n",
      "|    reward             | -1.5515113 |\n",
      "|    std                | 6.89e+16   |\n",
      "|    value_loss         | 0.0809     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16577521.64\n",
      "total_reward: 6577521.64\n",
      "total_cost: 561355.60\n",
      "total_trades: 82727\n",
      "Sharpe: 0.539\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 167300      |\n",
      "|    time_elapsed       | 8048        |\n",
      "|    total_timesteps    | 836500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.17e+03   |\n",
      "|    explained_variance | 0.55        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 167299      |\n",
      "|    policy_loss        | -10.6       |\n",
      "|    reward             | 0.006052497 |\n",
      "|    std                | 7.01e+16    |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 167400       |\n",
      "|    time_elapsed       | 8053         |\n",
      "|    total_timesteps    | 837000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | 0.641        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 167399       |\n",
      "|    policy_loss        | -34          |\n",
      "|    reward             | -0.035676952 |\n",
      "|    std                | 7.2e+16      |\n",
      "|    value_loss         | 0.000933     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 167500       |\n",
      "|    time_elapsed       | 8058         |\n",
      "|    total_timesteps    | 837500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | 0.729        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 167499       |\n",
      "|    policy_loss        | 0.8          |\n",
      "|    reward             | -0.029404305 |\n",
      "|    std                | 7.39e+16     |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 167600      |\n",
      "|    time_elapsed       | 8062        |\n",
      "|    total_timesteps    | 838000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.17e+03   |\n",
      "|    explained_variance | 0.497       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 167599      |\n",
      "|    policy_loss        | 3.18        |\n",
      "|    reward             | 0.012858873 |\n",
      "|    std                | 7.6e+16     |\n",
      "|    value_loss         | 0.000332    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 167700      |\n",
      "|    time_elapsed       | 8067        |\n",
      "|    total_timesteps    | 838500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.17e+03   |\n",
      "|    explained_variance | 0.607       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 167699      |\n",
      "|    policy_loss        | 54.7        |\n",
      "|    reward             | 0.020683536 |\n",
      "|    std                | 7.78e+16    |\n",
      "|    value_loss         | 0.00335     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 167800       |\n",
      "|    time_elapsed       | 8072         |\n",
      "|    total_timesteps    | 839000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | 0.814        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 167799       |\n",
      "|    policy_loss        | -16.3        |\n",
      "|    reward             | -0.015763523 |\n",
      "|    std                | 7.88e+16     |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 167900        |\n",
      "|    time_elapsed       | 8077          |\n",
      "|    total_timesteps    | 839500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.17e+03     |\n",
      "|    explained_variance | -0.0169       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 167899        |\n",
      "|    policy_loss        | 25.8          |\n",
      "|    reward             | -0.0064021237 |\n",
      "|    std                | 8.04e+16      |\n",
      "|    value_loss         | 0.0009        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 168000       |\n",
      "|    time_elapsed       | 8082         |\n",
      "|    total_timesteps    | 840000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | 0.393        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 167999       |\n",
      "|    policy_loss        | 16.2         |\n",
      "|    reward             | 0.0036507181 |\n",
      "|    std                | 8.25e+16     |\n",
      "|    value_loss         | 0.000557     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 168100     |\n",
      "|    time_elapsed       | 8086       |\n",
      "|    total_timesteps    | 840500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.17e+03  |\n",
      "|    explained_variance | 0.822      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 168099     |\n",
      "|    policy_loss        | 27.9       |\n",
      "|    reward             | 0.13466752 |\n",
      "|    std                | 8.48e+16   |\n",
      "|    value_loss         | 0.00108    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 168200       |\n",
      "|    time_elapsed       | 8091         |\n",
      "|    total_timesteps    | 841000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | 0.523        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 168199       |\n",
      "|    policy_loss        | 44.2         |\n",
      "|    reward             | -0.008987799 |\n",
      "|    std                | 8.71e+16     |\n",
      "|    value_loss         | 0.00211      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 168300      |\n",
      "|    time_elapsed       | 8096        |\n",
      "|    total_timesteps    | 841500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.17e+03   |\n",
      "|    explained_variance | 0.348       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 168299      |\n",
      "|    policy_loss        | -171        |\n",
      "|    reward             | 0.122570686 |\n",
      "|    std                | 8.89e+16    |\n",
      "|    value_loss         | 0.0272      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 168400       |\n",
      "|    time_elapsed       | 8101         |\n",
      "|    total_timesteps    | 842000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | -0.281       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 168399       |\n",
      "|    policy_loss        | 15.4         |\n",
      "|    reward             | 0.0028669215 |\n",
      "|    std                | 8.99e+16     |\n",
      "|    value_loss         | 0.000241     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 168500       |\n",
      "|    time_elapsed       | 8106         |\n",
      "|    total_timesteps    | 842500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.17e+03    |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 168499       |\n",
      "|    policy_loss        | -2.98        |\n",
      "|    reward             | -0.014098897 |\n",
      "|    std                | 9.17e+16     |\n",
      "|    value_loss         | 0.000238     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 168600     |\n",
      "|    time_elapsed       | 8110       |\n",
      "|    total_timesteps    | 843000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.17e+03  |\n",
      "|    explained_variance | -0.129     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 168599     |\n",
      "|    policy_loss        | 37.2       |\n",
      "|    reward             | 0.07820671 |\n",
      "|    std                | 9.39e+16   |\n",
      "|    value_loss         | 0.00128    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 168700      |\n",
      "|    time_elapsed       | 8115        |\n",
      "|    total_timesteps    | 843500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.17e+03   |\n",
      "|    explained_variance | 0.425       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 168699      |\n",
      "|    policy_loss        | 21.3        |\n",
      "|    reward             | 0.058202814 |\n",
      "|    std                | 9.66e+16    |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 168800      |\n",
      "|    time_elapsed       | 8120        |\n",
      "|    total_timesteps    | 844000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.731       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 168799      |\n",
      "|    policy_loss        | -21.8       |\n",
      "|    reward             | -0.10393678 |\n",
      "|    std                | 9.91e+16    |\n",
      "|    value_loss         | 0.000724    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 168900      |\n",
      "|    time_elapsed       | 8125        |\n",
      "|    total_timesteps    | 844500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 168899      |\n",
      "|    policy_loss        | -143        |\n",
      "|    reward             | 0.006626089 |\n",
      "|    std                | 1.01e+17    |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 169000      |\n",
      "|    time_elapsed       | 8130        |\n",
      "|    total_timesteps    | 845000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.233       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 168999      |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | 0.012250408 |\n",
      "|    std                | 1.02e+17    |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 169100       |\n",
      "|    time_elapsed       | 8134         |\n",
      "|    total_timesteps    | 845500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.18e+03    |\n",
      "|    explained_variance | -0.292       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 169099       |\n",
      "|    policy_loss        | 15.8         |\n",
      "|    reward             | -0.034435496 |\n",
      "|    std                | 1.05e+17     |\n",
      "|    value_loss         | 0.00082      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 169200      |\n",
      "|    time_elapsed       | 8139        |\n",
      "|    total_timesteps    | 846000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 169199      |\n",
      "|    policy_loss        | 97.8        |\n",
      "|    reward             | -0.06290279 |\n",
      "|    std                | 1.07e+17    |\n",
      "|    value_loss         | 0.00716     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 169300      |\n",
      "|    time_elapsed       | 8144        |\n",
      "|    total_timesteps    | 846500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | -0.644      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 169299      |\n",
      "|    policy_loss        | -32.7       |\n",
      "|    reward             | -0.08622868 |\n",
      "|    std                | 1.11e+17    |\n",
      "|    value_loss         | 0.00126     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 169400     |\n",
      "|    time_elapsed       | 8149       |\n",
      "|    total_timesteps    | 847000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.18e+03  |\n",
      "|    explained_variance | 0.619      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 169399     |\n",
      "|    policy_loss        | -58.6      |\n",
      "|    reward             | 0.24615929 |\n",
      "|    std                | 1.13e+17   |\n",
      "|    value_loss         | 0.00358    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 169500    |\n",
      "|    time_elapsed       | 8154      |\n",
      "|    total_timesteps    | 847500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.18e+03 |\n",
      "|    explained_variance | 0.615     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 169499    |\n",
      "|    policy_loss        | 181       |\n",
      "|    reward             | 0.0199036 |\n",
      "|    std                | 1.15e+17  |\n",
      "|    value_loss         | 0.0364    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 169600       |\n",
      "|    time_elapsed       | 8159         |\n",
      "|    total_timesteps    | 848000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.18e+03    |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 169599       |\n",
      "|    policy_loss        | 36.4         |\n",
      "|    reward             | -0.022509476 |\n",
      "|    std                | 1.17e+17     |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 169700       |\n",
      "|    time_elapsed       | 8163         |\n",
      "|    total_timesteps    | 848500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.18e+03    |\n",
      "|    explained_variance | 0.304        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 169699       |\n",
      "|    policy_loss        | 21.6         |\n",
      "|    reward             | -0.017380571 |\n",
      "|    std                | 1.2e+17      |\n",
      "|    value_loss         | 0.000726     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 169800      |\n",
      "|    time_elapsed       | 8168        |\n",
      "|    total_timesteps    | 849000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.552       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 169799      |\n",
      "|    policy_loss        | -24.4       |\n",
      "|    reward             | 0.034223236 |\n",
      "|    std                | 1.23e+17    |\n",
      "|    value_loss         | 0.000662    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 169900      |\n",
      "|    time_elapsed       | 8173        |\n",
      "|    total_timesteps    | 849500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 169899      |\n",
      "|    policy_loss        | 17.6        |\n",
      "|    reward             | -0.12320624 |\n",
      "|    std                | 1.26e+17    |\n",
      "|    value_loss         | 0.000919    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 170000      |\n",
      "|    time_elapsed       | 8178        |\n",
      "|    total_timesteps    | 850000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.18e+03   |\n",
      "|    explained_variance | 0.403       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 169999      |\n",
      "|    policy_loss        | -189        |\n",
      "|    reward             | 0.085662976 |\n",
      "|    std                | 1.29e+17    |\n",
      "|    value_loss         | 0.0366      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 170100     |\n",
      "|    time_elapsed       | 8183       |\n",
      "|    total_timesteps    | 850500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.18e+03  |\n",
      "|    explained_variance | 0.728      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 170099     |\n",
      "|    policy_loss        | -205       |\n",
      "|    reward             | -0.6458863 |\n",
      "|    std                | 1.31e+17   |\n",
      "|    value_loss         | 0.0643     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 170200        |\n",
      "|    time_elapsed       | 8188          |\n",
      "|    total_timesteps    | 851000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.18e+03     |\n",
      "|    explained_variance | 0.662         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 170199        |\n",
      "|    policy_loss        | 15            |\n",
      "|    reward             | -0.0024221407 |\n",
      "|    std                | 1.33e+17      |\n",
      "|    value_loss         | 0.000194      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 170300       |\n",
      "|    time_elapsed       | 8193         |\n",
      "|    total_timesteps    | 851500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.18e+03    |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 170299       |\n",
      "|    policy_loss        | -4.14        |\n",
      "|    reward             | -0.088010535 |\n",
      "|    std                | 1.36e+17     |\n",
      "|    value_loss         | 0.000197     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 170400     |\n",
      "|    time_elapsed       | 8197       |\n",
      "|    total_timesteps    | 852000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.19e+03  |\n",
      "|    explained_variance | 0.753      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 170399     |\n",
      "|    policy_loss        | -118       |\n",
      "|    reward             | 0.16510968 |\n",
      "|    std                | 1.4e+17    |\n",
      "|    value_loss         | 0.012      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 170500       |\n",
      "|    time_elapsed       | 8202         |\n",
      "|    total_timesteps    | 852500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.19e+03    |\n",
      "|    explained_variance | 0.731        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 170499       |\n",
      "|    policy_loss        | 103          |\n",
      "|    reward             | 0.0052846307 |\n",
      "|    std                | 1.43e+17     |\n",
      "|    value_loss         | 0.0086       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 170600        |\n",
      "|    time_elapsed       | 8207          |\n",
      "|    total_timesteps    | 853000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.19e+03     |\n",
      "|    explained_variance | -1.54         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 170599        |\n",
      "|    policy_loss        | -20.9         |\n",
      "|    reward             | -0.0010552172 |\n",
      "|    std                | 1.46e+17      |\n",
      "|    value_loss         | 0.0028        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 170700       |\n",
      "|    time_elapsed       | 8212         |\n",
      "|    total_timesteps    | 853500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.19e+03    |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 170699       |\n",
      "|    policy_loss        | -15.2        |\n",
      "|    reward             | -0.011336037 |\n",
      "|    std                | 1.48e+17     |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 170800    |\n",
      "|    time_elapsed       | 8217      |\n",
      "|    total_timesteps    | 854000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.19e+03 |\n",
      "|    explained_variance | 0.364     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 170799    |\n",
      "|    policy_loss        | -22.2     |\n",
      "|    reward             | -0.01118  |\n",
      "|    std                | 1.51e+17  |\n",
      "|    value_loss         | 0.000722  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 170900      |\n",
      "|    time_elapsed       | 8221        |\n",
      "|    total_timesteps    | 854500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19e+03   |\n",
      "|    explained_variance | 0.796       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 170899      |\n",
      "|    policy_loss        | -24.6       |\n",
      "|    reward             | 0.017948093 |\n",
      "|    std                | 1.55e+17    |\n",
      "|    value_loss         | 0.000487    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 171000      |\n",
      "|    time_elapsed       | 8226        |\n",
      "|    total_timesteps    | 855000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19e+03   |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 170999      |\n",
      "|    policy_loss        | -21         |\n",
      "|    reward             | -0.05685768 |\n",
      "|    std                | 1.59e+17    |\n",
      "|    value_loss         | 0.000896    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 171100       |\n",
      "|    time_elapsed       | 8231         |\n",
      "|    total_timesteps    | 855500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.19e+03    |\n",
      "|    explained_variance | 0.607        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 171099       |\n",
      "|    policy_loss        | -33.8        |\n",
      "|    reward             | -0.061039414 |\n",
      "|    std                | 1.64e+17     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 171200     |\n",
      "|    time_elapsed       | 8236       |\n",
      "|    total_timesteps    | 856000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.19e+03  |\n",
      "|    explained_variance | 0.783      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 171199     |\n",
      "|    policy_loss        | 181        |\n",
      "|    reward             | 0.03983685 |\n",
      "|    std                | 1.67e+17   |\n",
      "|    value_loss         | 0.0246     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 171300      |\n",
      "|    time_elapsed       | 8241        |\n",
      "|    total_timesteps    | 856500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19e+03   |\n",
      "|    explained_variance | -0.359      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 171299      |\n",
      "|    policy_loss        | -16.4       |\n",
      "|    reward             | 0.014344948 |\n",
      "|    std                | 1.69e+17    |\n",
      "|    value_loss         | 0.000242    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 171400       |\n",
      "|    time_elapsed       | 8246         |\n",
      "|    total_timesteps    | 857000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.19e+03    |\n",
      "|    explained_variance | 0.479        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 171399       |\n",
      "|    policy_loss        | 10           |\n",
      "|    reward             | -0.048868217 |\n",
      "|    std                | 1.73e+17     |\n",
      "|    value_loss         | 0.00133      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 171500      |\n",
      "|    time_elapsed       | 8250        |\n",
      "|    total_timesteps    | 857500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19e+03   |\n",
      "|    explained_variance | 0.811       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 171499      |\n",
      "|    policy_loss        | 14          |\n",
      "|    reward             | 0.021661054 |\n",
      "|    std                | 1.77e+17    |\n",
      "|    value_loss         | 0.000264    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 171600      |\n",
      "|    time_elapsed       | 8255        |\n",
      "|    total_timesteps    | 858000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19e+03   |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 171599      |\n",
      "|    policy_loss        | 44.5        |\n",
      "|    reward             | -0.09043326 |\n",
      "|    std                | 1.82e+17    |\n",
      "|    value_loss         | 0.00146     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 171700       |\n",
      "|    time_elapsed       | 8260         |\n",
      "|    total_timesteps    | 858500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.19e+03    |\n",
      "|    explained_variance | 0.837        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 171699       |\n",
      "|    policy_loss        | -76.7        |\n",
      "|    reward             | -0.063029006 |\n",
      "|    std                | 1.87e+17     |\n",
      "|    value_loss         | 0.00529      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 171800     |\n",
      "|    time_elapsed       | 8265       |\n",
      "|    total_timesteps    | 859000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.19e+03  |\n",
      "|    explained_variance | 0.762      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 171799     |\n",
      "|    policy_loss        | -216       |\n",
      "|    reward             | 0.03947984 |\n",
      "|    std                | 1.9e+17    |\n",
      "|    value_loss         | 0.045      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 171900       |\n",
      "|    time_elapsed       | 8270         |\n",
      "|    total_timesteps    | 859500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.19e+03    |\n",
      "|    explained_variance | 0.615        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 171899       |\n",
      "|    policy_loss        | -20.7        |\n",
      "|    reward             | 0.0102877775 |\n",
      "|    std                | 1.93e+17     |\n",
      "|    value_loss         | 0.000317     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 172000       |\n",
      "|    time_elapsed       | 8275         |\n",
      "|    total_timesteps    | 860000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.2e+03     |\n",
      "|    explained_variance | 0.217        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 171999       |\n",
      "|    policy_loss        | 4.11         |\n",
      "|    reward             | -0.004733492 |\n",
      "|    std                | 1.97e+17     |\n",
      "|    value_loss         | 7.22e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 172100      |\n",
      "|    time_elapsed       | 8280        |\n",
      "|    total_timesteps    | 860500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2e+03    |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 172099      |\n",
      "|    policy_loss        | -20.9       |\n",
      "|    reward             | -0.14545545 |\n",
      "|    std                | 2.03e+17    |\n",
      "|    value_loss         | 0.000386    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 172200      |\n",
      "|    time_elapsed       | 8285        |\n",
      "|    total_timesteps    | 861000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2e+03    |\n",
      "|    explained_variance | 0.736       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 172199      |\n",
      "|    policy_loss        | 22.4        |\n",
      "|    reward             | 0.041341934 |\n",
      "|    std                | 2.1e+17     |\n",
      "|    value_loss         | 0.00301     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 172300      |\n",
      "|    time_elapsed       | 8289        |\n",
      "|    total_timesteps    | 861500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2e+03    |\n",
      "|    explained_variance | 0.652       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 172299      |\n",
      "|    policy_loss        | 113         |\n",
      "|    reward             | -0.08023595 |\n",
      "|    std                | 2.16e+17    |\n",
      "|    value_loss         | 0.0136      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 172400      |\n",
      "|    time_elapsed       | 8294        |\n",
      "|    total_timesteps    | 862000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2e+03    |\n",
      "|    explained_variance | 0.543       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 172399      |\n",
      "|    policy_loss        | -122        |\n",
      "|    reward             | 0.118982874 |\n",
      "|    std                | 2.19e+17    |\n",
      "|    value_loss         | 0.0176      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 172500       |\n",
      "|    time_elapsed       | 8299         |\n",
      "|    total_timesteps    | 862500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.2e+03     |\n",
      "|    explained_variance | 0.728        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 172499       |\n",
      "|    policy_loss        | -18.6        |\n",
      "|    reward             | -0.034183957 |\n",
      "|    std                | 2.22e+17     |\n",
      "|    value_loss         | 0.000397     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 172600       |\n",
      "|    time_elapsed       | 8304         |\n",
      "|    total_timesteps    | 863000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.2e+03     |\n",
      "|    explained_variance | 0.8          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 172599       |\n",
      "|    policy_loss        | 59.1         |\n",
      "|    reward             | -0.044733837 |\n",
      "|    std                | 2.27e+17     |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 172700       |\n",
      "|    time_elapsed       | 8309         |\n",
      "|    total_timesteps    | 863500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.2e+03     |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 172699       |\n",
      "|    policy_loss        | 8.99         |\n",
      "|    reward             | -0.096501954 |\n",
      "|    std                | 2.34e+17     |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 172800     |\n",
      "|    time_elapsed       | 8314       |\n",
      "|    total_timesteps    | 864000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.2e+03   |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 172799     |\n",
      "|    policy_loss        | 28.8       |\n",
      "|    reward             | 0.14993879 |\n",
      "|    std                | 2.4e+17    |\n",
      "|    value_loss         | 0.000616   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 172900      |\n",
      "|    time_elapsed       | 8318        |\n",
      "|    total_timesteps    | 864500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2e+03    |\n",
      "|    explained_variance | 0.418       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 172899      |\n",
      "|    policy_loss        | -300        |\n",
      "|    reward             | 0.032233488 |\n",
      "|    std                | 2.45e+17    |\n",
      "|    value_loss         | 0.0704      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 173000    |\n",
      "|    time_elapsed       | 8323      |\n",
      "|    total_timesteps    | 865000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.2e+03  |\n",
      "|    explained_variance | 0.926     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 172999    |\n",
      "|    policy_loss        | -442      |\n",
      "|    reward             | 0.0758657 |\n",
      "|    std                | 2.48e+17  |\n",
      "|    value_loss         | 0.203     |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17497678.72\n",
      "total_reward: 7497678.72\n",
      "total_cost: 563274.38\n",
      "total_trades: 82912\n",
      "Sharpe: 0.466\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 173100      |\n",
      "|    time_elapsed       | 8328        |\n",
      "|    total_timesteps    | 865500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2e+03    |\n",
      "|    explained_variance | 0.031       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 173099      |\n",
      "|    policy_loss        | 22.7        |\n",
      "|    reward             | 0.007367964 |\n",
      "|    std                | 2.52e+17    |\n",
      "|    value_loss         | 0.00043     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 173200        |\n",
      "|    time_elapsed       | 8333          |\n",
      "|    total_timesteps    | 866000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.2e+03      |\n",
      "|    explained_variance | 0.468         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 173199        |\n",
      "|    policy_loss        | 31.9          |\n",
      "|    reward             | -0.0069620246 |\n",
      "|    std                | 2.58e+17      |\n",
      "|    value_loss         | 0.000909      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 173300       |\n",
      "|    time_elapsed       | 8338         |\n",
      "|    total_timesteps    | 866500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.2e+03     |\n",
      "|    explained_variance | 0.766        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 173299       |\n",
      "|    policy_loss        | 16           |\n",
      "|    reward             | -0.028758692 |\n",
      "|    std                | 2.65e+17     |\n",
      "|    value_loss         | 0.000383     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 173400       |\n",
      "|    time_elapsed       | 8343         |\n",
      "|    total_timesteps    | 867000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.2e+03     |\n",
      "|    explained_variance | 0.786        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 173399       |\n",
      "|    policy_loss        | 22           |\n",
      "|    reward             | -0.010282188 |\n",
      "|    std                | 2.72e+17     |\n",
      "|    value_loss         | 0.000424     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 173500     |\n",
      "|    time_elapsed       | 8348       |\n",
      "|    total_timesteps    | 867500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21e+03  |\n",
      "|    explained_variance | 0.303      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 173499     |\n",
      "|    policy_loss        | 201        |\n",
      "|    reward             | 0.09122872 |\n",
      "|    std                | 2.77e+17   |\n",
      "|    value_loss         | 0.0342     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 173600       |\n",
      "|    time_elapsed       | 8352         |\n",
      "|    total_timesteps    | 868000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.21e+03    |\n",
      "|    explained_variance | 0.516        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 173599       |\n",
      "|    policy_loss        | 3.86         |\n",
      "|    reward             | 0.0126716215 |\n",
      "|    std                | 2.81e+17     |\n",
      "|    value_loss         | 6.93e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 173700       |\n",
      "|    time_elapsed       | 8357         |\n",
      "|    total_timesteps    | 868500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.21e+03    |\n",
      "|    explained_variance | -0.178       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 173699       |\n",
      "|    policy_loss        | 38.9         |\n",
      "|    reward             | -0.031764925 |\n",
      "|    std                | 2.87e+17     |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 173800     |\n",
      "|    time_elapsed       | 8362       |\n",
      "|    total_timesteps    | 869000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21e+03  |\n",
      "|    explained_variance | 0.892      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 173799     |\n",
      "|    policy_loss        | 23.6       |\n",
      "|    reward             | 0.07856704 |\n",
      "|    std                | 2.95e+17   |\n",
      "|    value_loss         | 0.00043    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 173900      |\n",
      "|    time_elapsed       | 8367        |\n",
      "|    total_timesteps    | 869500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.21e+03   |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 173899      |\n",
      "|    policy_loss        | -24.7       |\n",
      "|    reward             | 0.032943085 |\n",
      "|    std                | 3.03e+17    |\n",
      "|    value_loss         | 0.000559    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 174000        |\n",
      "|    time_elapsed       | 8372          |\n",
      "|    total_timesteps    | 870000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.21e+03     |\n",
      "|    explained_variance | 0.726         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 173999        |\n",
      "|    policy_loss        | -53.1         |\n",
      "|    reward             | -0.0078017865 |\n",
      "|    std                | 3.11e+17      |\n",
      "|    value_loss         | 0.00301       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 174100     |\n",
      "|    time_elapsed       | 8376       |\n",
      "|    total_timesteps    | 870500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21e+03  |\n",
      "|    explained_variance | -0.332     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 174099     |\n",
      "|    policy_loss        | 26         |\n",
      "|    reward             | 0.15436302 |\n",
      "|    std                | 3.17e+17   |\n",
      "|    value_loss         | 0.00197    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 174200       |\n",
      "|    time_elapsed       | 8381         |\n",
      "|    total_timesteps    | 871000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.21e+03    |\n",
      "|    explained_variance | -1.83        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 174199       |\n",
      "|    policy_loss        | -25.8        |\n",
      "|    reward             | -0.016621985 |\n",
      "|    std                | 3.21e+17     |\n",
      "|    value_loss         | 0.000484     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 174300     |\n",
      "|    time_elapsed       | 8386       |\n",
      "|    total_timesteps    | 871500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21e+03  |\n",
      "|    explained_variance | 0.12       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 174299     |\n",
      "|    policy_loss        | 74         |\n",
      "|    reward             | 0.09505766 |\n",
      "|    std                | 3.29e+17   |\n",
      "|    value_loss         | 0.00608    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 174400        |\n",
      "|    time_elapsed       | 8391          |\n",
      "|    total_timesteps    | 872000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.21e+03     |\n",
      "|    explained_variance | 0.91          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 174399        |\n",
      "|    policy_loss        | 2.13          |\n",
      "|    reward             | -0.0018872225 |\n",
      "|    std                | 3.38e+17      |\n",
      "|    value_loss         | 0.000481      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 174500      |\n",
      "|    time_elapsed       | 8396        |\n",
      "|    total_timesteps    | 872500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.21e+03   |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 174499      |\n",
      "|    policy_loss        | 179         |\n",
      "|    reward             | -0.11898614 |\n",
      "|    std                | 3.47e+17    |\n",
      "|    value_loss         | 0.024       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 174600       |\n",
      "|    time_elapsed       | 8400         |\n",
      "|    total_timesteps    | 873000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.21e+03    |\n",
      "|    explained_variance | -1.56        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 174599       |\n",
      "|    policy_loss        | 51.6         |\n",
      "|    reward             | -0.046525497 |\n",
      "|    std                | 3.56e+17     |\n",
      "|    value_loss         | 0.00489      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 174700     |\n",
      "|    time_elapsed       | 8405       |\n",
      "|    total_timesteps    | 873500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21e+03  |\n",
      "|    explained_variance | 0.0374     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 174699     |\n",
      "|    policy_loss        | -272       |\n",
      "|    reward             | 0.34236568 |\n",
      "|    std                | 3.6e+17    |\n",
      "|    value_loss         | 0.0774     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 174800      |\n",
      "|    time_elapsed       | 8410        |\n",
      "|    total_timesteps    | 874000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.21e+03   |\n",
      "|    explained_variance | -0.294      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 174799      |\n",
      "|    policy_loss        | -10.1       |\n",
      "|    reward             | 0.005923314 |\n",
      "|    std                | 3.65e+17    |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 174900       |\n",
      "|    time_elapsed       | 8415         |\n",
      "|    total_timesteps    | 874500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.21e+03    |\n",
      "|    explained_variance | -19.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 174899       |\n",
      "|    policy_loss        | 16.2         |\n",
      "|    reward             | -0.015574841 |\n",
      "|    std                | 3.73e+17     |\n",
      "|    value_loss         | 0.000935     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 175000      |\n",
      "|    time_elapsed       | 8420        |\n",
      "|    total_timesteps    | 875000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.21e+03   |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 174999      |\n",
      "|    policy_loss        | 2.37        |\n",
      "|    reward             | 0.031928845 |\n",
      "|    std                | 3.83e+17    |\n",
      "|    value_loss         | 0.000592    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 175100     |\n",
      "|    time_elapsed       | 8425       |\n",
      "|    total_timesteps    | 875500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.22e+03  |\n",
      "|    explained_variance | 0.581      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 175099     |\n",
      "|    policy_loss        | 80.1       |\n",
      "|    reward             | 0.07570428 |\n",
      "|    std                | 3.94e+17   |\n",
      "|    value_loss         | 0.00476    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 175200      |\n",
      "|    time_elapsed       | 8429        |\n",
      "|    total_timesteps    | 876000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.22e+03   |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 175199      |\n",
      "|    policy_loss        | 39.3        |\n",
      "|    reward             | -0.16098118 |\n",
      "|    std                | 4.02e+17    |\n",
      "|    value_loss         | 0.00519     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 175300    |\n",
      "|    time_elapsed       | 8434      |\n",
      "|    total_timesteps    | 876500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.22e+03 |\n",
      "|    explained_variance | 0.856     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 175299    |\n",
      "|    policy_loss        | -546      |\n",
      "|    reward             | 1.2809632 |\n",
      "|    std                | 4.07e+17  |\n",
      "|    value_loss         | 0.255     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 175400     |\n",
      "|    time_elapsed       | 8439       |\n",
      "|    total_timesteps    | 877000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.22e+03  |\n",
      "|    explained_variance | -0.0637    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 175399     |\n",
      "|    policy_loss        | -11.6      |\n",
      "|    reward             | 0.04422452 |\n",
      "|    std                | 4.14e+17   |\n",
      "|    value_loss         | 0.00119    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 175500       |\n",
      "|    time_elapsed       | 8444         |\n",
      "|    total_timesteps    | 877500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.22e+03    |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 175499       |\n",
      "|    policy_loss        | -14.3        |\n",
      "|    reward             | -0.004430648 |\n",
      "|    std                | 4.24e+17     |\n",
      "|    value_loss         | 0.000181     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 175600      |\n",
      "|    time_elapsed       | 8449        |\n",
      "|    total_timesteps    | 878000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.22e+03   |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 175599      |\n",
      "|    policy_loss        | 39          |\n",
      "|    reward             | 0.017243685 |\n",
      "|    std                | 4.35e+17    |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 175700        |\n",
      "|    time_elapsed       | 8454          |\n",
      "|    total_timesteps    | 878500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.22e+03     |\n",
      "|    explained_variance | 0.689         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 175699        |\n",
      "|    policy_loss        | 5.93          |\n",
      "|    reward             | -0.0053524515 |\n",
      "|    std                | 4.46e+17      |\n",
      "|    value_loss         | 0.000198      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 175800       |\n",
      "|    time_elapsed       | 8459         |\n",
      "|    total_timesteps    | 879000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.22e+03    |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 175799       |\n",
      "|    policy_loss        | -62          |\n",
      "|    reward             | -0.045341603 |\n",
      "|    std                | 4.56e+17     |\n",
      "|    value_loss         | 0.00339      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 175900        |\n",
      "|    time_elapsed       | 8463          |\n",
      "|    total_timesteps    | 879500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.22e+03     |\n",
      "|    explained_variance | -2.6          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 175899        |\n",
      "|    policy_loss        | 3.96          |\n",
      "|    reward             | 0.00032975696 |\n",
      "|    std                | 4.65e+17      |\n",
      "|    value_loss         | 7.13e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 176000      |\n",
      "|    time_elapsed       | 8468        |\n",
      "|    total_timesteps    | 880000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.22e+03   |\n",
      "|    explained_variance | 0.547       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 175999      |\n",
      "|    policy_loss        | -24.6       |\n",
      "|    reward             | 0.015609426 |\n",
      "|    std                | 4.74e+17    |\n",
      "|    value_loss         | 0.000613    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 176100      |\n",
      "|    time_elapsed       | 8473        |\n",
      "|    total_timesteps    | 880500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.22e+03   |\n",
      "|    explained_variance | 0.026       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 176099      |\n",
      "|    policy_loss        | 23          |\n",
      "|    reward             | -0.05921975 |\n",
      "|    std                | 4.88e+17    |\n",
      "|    value_loss         | 0.000577    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 176200     |\n",
      "|    time_elapsed       | 8478       |\n",
      "|    total_timesteps    | 881000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.22e+03  |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 176199     |\n",
      "|    policy_loss        | -32.1      |\n",
      "|    reward             | 0.14871074 |\n",
      "|    std                | 5.02e+17   |\n",
      "|    value_loss         | 0.000724   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 176300     |\n",
      "|    time_elapsed       | 8483       |\n",
      "|    total_timesteps    | 881500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.22e+03  |\n",
      "|    explained_variance | -0.0279    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 176299     |\n",
      "|    policy_loss        | -31.2      |\n",
      "|    reward             | 0.04780908 |\n",
      "|    std                | 5.15e+17   |\n",
      "|    value_loss         | 0.00108    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 176400     |\n",
      "|    time_elapsed       | 8488       |\n",
      "|    total_timesteps    | 882000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.22e+03  |\n",
      "|    explained_variance | 0.864      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 176399     |\n",
      "|    policy_loss        | 35.8       |\n",
      "|    reward             | 0.26957217 |\n",
      "|    std                | 5.25e+17   |\n",
      "|    value_loss         | 0.00656    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 176500       |\n",
      "|    time_elapsed       | 8493         |\n",
      "|    total_timesteps    | 882500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.22e+03    |\n",
      "|    explained_variance | 0.357        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 176499       |\n",
      "|    policy_loss        | -1.47        |\n",
      "|    reward             | 0.0008479182 |\n",
      "|    std                | 5.33e+17     |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 176600       |\n",
      "|    time_elapsed       | 8497         |\n",
      "|    total_timesteps    | 883000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.22e+03    |\n",
      "|    explained_variance | 0.752        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 176599       |\n",
      "|    policy_loss        | -30.7        |\n",
      "|    reward             | -0.012857367 |\n",
      "|    std                | 5.44e+17     |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 176700      |\n",
      "|    time_elapsed       | 8502        |\n",
      "|    total_timesteps    | 883500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.23e+03   |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 176699      |\n",
      "|    policy_loss        | 12.8        |\n",
      "|    reward             | 0.023436375 |\n",
      "|    std                | 5.59e+17    |\n",
      "|    value_loss         | 0.000663    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 176800       |\n",
      "|    time_elapsed       | 8507         |\n",
      "|    total_timesteps    | 884000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 176799       |\n",
      "|    policy_loss        | -2.41        |\n",
      "|    reward             | -0.019112622 |\n",
      "|    std                | 5.78e+17     |\n",
      "|    value_loss         | 7.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 176900       |\n",
      "|    time_elapsed       | 8512         |\n",
      "|    total_timesteps    | 884500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.651        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 176899       |\n",
      "|    policy_loss        | 14.8         |\n",
      "|    reward             | -0.046476223 |\n",
      "|    std                | 5.94e+17     |\n",
      "|    value_loss         | 0.000479     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 177000      |\n",
      "|    time_elapsed       | 8517        |\n",
      "|    total_timesteps    | 885000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.23e+03   |\n",
      "|    explained_variance | -1.15       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 176999      |\n",
      "|    policy_loss        | -8.19       |\n",
      "|    reward             | -0.02460662 |\n",
      "|    std                | 6.08e+17    |\n",
      "|    value_loss         | 0.00421     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 177100       |\n",
      "|    time_elapsed       | 8521         |\n",
      "|    total_timesteps    | 885500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.127        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 177099       |\n",
      "|    policy_loss        | 23.3         |\n",
      "|    reward             | -0.020027358 |\n",
      "|    std                | 6.17e+17     |\n",
      "|    value_loss         | 0.000381     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 177200       |\n",
      "|    time_elapsed       | 8526         |\n",
      "|    total_timesteps    | 886000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 177199       |\n",
      "|    policy_loss        | -21.6        |\n",
      "|    reward             | -0.044601005 |\n",
      "|    std                | 6.33e+17     |\n",
      "|    value_loss         | 0.000487     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 177300        |\n",
      "|    time_elapsed       | 8531          |\n",
      "|    total_timesteps    | 886500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.23e+03     |\n",
      "|    explained_variance | 0.865         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 177299        |\n",
      "|    policy_loss        | -11.5         |\n",
      "|    reward             | -0.0024541134 |\n",
      "|    std                | 6.52e+17      |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 177400      |\n",
      "|    time_elapsed       | 8536        |\n",
      "|    total_timesteps    | 887000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.23e+03   |\n",
      "|    explained_variance | -0.417      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 177399      |\n",
      "|    policy_loss        | 0.452       |\n",
      "|    reward             | -0.19153196 |\n",
      "|    std                | 6.7e+17     |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 177500    |\n",
      "|    time_elapsed       | 8541      |\n",
      "|    total_timesteps    | 887500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.23e+03 |\n",
      "|    explained_variance | -0.818    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 177499    |\n",
      "|    policy_loss        | -41.9     |\n",
      "|    reward             | 0.214824  |\n",
      "|    std                | 6.84e+17  |\n",
      "|    value_loss         | 0.00533   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 177600      |\n",
      "|    time_elapsed       | 8546        |\n",
      "|    total_timesteps    | 888000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.23e+03   |\n",
      "|    explained_variance | -7.32       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 177599      |\n",
      "|    policy_loss        | 98.1        |\n",
      "|    reward             | 0.123646915 |\n",
      "|    std                | 6.93e+17    |\n",
      "|    value_loss         | 0.0109      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 177700       |\n",
      "|    time_elapsed       | 8550         |\n",
      "|    total_timesteps    | 888500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.795        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 177699       |\n",
      "|    policy_loss        | 12           |\n",
      "|    reward             | -0.021903664 |\n",
      "|    std                | 7.05e+17     |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 177800       |\n",
      "|    time_elapsed       | 8555         |\n",
      "|    total_timesteps    | 889000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 177799       |\n",
      "|    policy_loss        | -3.79        |\n",
      "|    reward             | -0.009081345 |\n",
      "|    std                | 7.22e+17     |\n",
      "|    value_loss         | 3.86e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 177900       |\n",
      "|    time_elapsed       | 8560         |\n",
      "|    total_timesteps    | 889500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.505        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 177899       |\n",
      "|    policy_loss        | -16.8        |\n",
      "|    reward             | -0.032614384 |\n",
      "|    std                | 7.44e+17     |\n",
      "|    value_loss         | 0.000456     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 178000       |\n",
      "|    time_elapsed       | 8565         |\n",
      "|    total_timesteps    | 890000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23e+03    |\n",
      "|    explained_variance | 0.433        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 177999       |\n",
      "|    policy_loss        | 8.78         |\n",
      "|    reward             | -0.011172166 |\n",
      "|    std                | 7.62e+17     |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 178100      |\n",
      "|    time_elapsed       | 8570        |\n",
      "|    total_timesteps    | 890500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 178099      |\n",
      "|    policy_loss        | 123         |\n",
      "|    reward             | 0.036339466 |\n",
      "|    std                | 7.78e+17    |\n",
      "|    value_loss         | 0.0137      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 178200     |\n",
      "|    time_elapsed       | 8575       |\n",
      "|    total_timesteps    | 891000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.24e+03  |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 178199     |\n",
      "|    policy_loss        | 119        |\n",
      "|    reward             | 0.31367934 |\n",
      "|    std                | 7.86e+17   |\n",
      "|    value_loss         | 0.0156     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 178300     |\n",
      "|    time_elapsed       | 8580       |\n",
      "|    total_timesteps    | 891500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.24e+03  |\n",
      "|    explained_variance | -4.56      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 178299     |\n",
      "|    policy_loss        | 6.46       |\n",
      "|    reward             | 0.00914919 |\n",
      "|    std                | 7.99e+17   |\n",
      "|    value_loss         | 0.000289   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 178400       |\n",
      "|    time_elapsed       | 8584         |\n",
      "|    total_timesteps    | 892000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.24e+03    |\n",
      "|    explained_variance | 0.66         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 178399       |\n",
      "|    policy_loss        | -71.6        |\n",
      "|    reward             | -0.002577785 |\n",
      "|    std                | 8.18e+17     |\n",
      "|    value_loss         | 0.00346      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 178500      |\n",
      "|    time_elapsed       | 8589        |\n",
      "|    total_timesteps    | 892500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 178499      |\n",
      "|    policy_loss        | -37.5       |\n",
      "|    reward             | -0.09259376 |\n",
      "|    std                | 8.41e+17    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 178600      |\n",
      "|    time_elapsed       | 8594        |\n",
      "|    total_timesteps    | 893000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.715       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 178599      |\n",
      "|    policy_loss        | 40          |\n",
      "|    reward             | 0.057226624 |\n",
      "|    std                | 8.67e+17    |\n",
      "|    value_loss         | 0.00148     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 178700      |\n",
      "|    time_elapsed       | 8599        |\n",
      "|    total_timesteps    | 893500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | -9.78       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 178699      |\n",
      "|    policy_loss        | 113         |\n",
      "|    reward             | -0.18722673 |\n",
      "|    std                | 8.87e+17    |\n",
      "|    value_loss         | 0.0363      |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18394536.35\n",
      "total_reward: 8394536.35\n",
      "total_cost: 560347.95\n",
      "total_trades: 82542\n",
      "Sharpe: 0.536\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 103            |\n",
      "|    iterations         | 178800         |\n",
      "|    time_elapsed       | 8604           |\n",
      "|    total_timesteps    | 894000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -1.24e+03      |\n",
      "|    explained_variance | 0.724          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 178799         |\n",
      "|    policy_loss        | -1.59          |\n",
      "|    reward             | -2.1943133e-05 |\n",
      "|    std                | 8.97e+17       |\n",
      "|    value_loss         | 3.59e-05       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 178900     |\n",
      "|    time_elapsed       | 8609       |\n",
      "|    total_timesteps    | 894500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.24e+03  |\n",
      "|    explained_variance | 0.763      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 178899     |\n",
      "|    policy_loss        | 22.3       |\n",
      "|    reward             | 0.02660543 |\n",
      "|    std                | 9.15e+17   |\n",
      "|    value_loss         | 0.000472   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179000      |\n",
      "|    time_elapsed       | 8613        |\n",
      "|    total_timesteps    | 895000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.669       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 178999      |\n",
      "|    policy_loss        | 19.8        |\n",
      "|    reward             | 0.046894144 |\n",
      "|    std                | 9.4e+17     |\n",
      "|    value_loss         | 0.000316    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179100      |\n",
      "|    time_elapsed       | 8618        |\n",
      "|    total_timesteps    | 895500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.608       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179099      |\n",
      "|    policy_loss        | -10.8       |\n",
      "|    reward             | 0.097626396 |\n",
      "|    std                | 9.68e+17    |\n",
      "|    value_loss         | 0.00346     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 179200     |\n",
      "|    time_elapsed       | 8623       |\n",
      "|    total_timesteps    | 896000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.24e+03  |\n",
      "|    explained_variance | 0.9        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 179199     |\n",
      "|    policy_loss        | -18        |\n",
      "|    reward             | 0.08545259 |\n",
      "|    std                | 9.92e+17   |\n",
      "|    value_loss         | 0.000568   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 179300     |\n",
      "|    time_elapsed       | 8628       |\n",
      "|    total_timesteps    | 896500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.24e+03  |\n",
      "|    explained_variance | 0.444      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 179299     |\n",
      "|    policy_loss        | -220       |\n",
      "|    reward             | -0.1522045 |\n",
      "|    std                | 1.01e+18   |\n",
      "|    value_loss         | 0.0478     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179400      |\n",
      "|    time_elapsed       | 8633        |\n",
      "|    total_timesteps    | 897000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.548       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179399      |\n",
      "|    policy_loss        | 34.3        |\n",
      "|    reward             | 0.012577762 |\n",
      "|    std                | 1.02e+18    |\n",
      "|    value_loss         | 0.000774    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179500      |\n",
      "|    time_elapsed       | 8638        |\n",
      "|    total_timesteps    | 897500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.665       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179499      |\n",
      "|    policy_loss        | -87.2       |\n",
      "|    reward             | 0.010764067 |\n",
      "|    std                | 1.04e+18    |\n",
      "|    value_loss         | 0.00782     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179600      |\n",
      "|    time_elapsed       | 8643        |\n",
      "|    total_timesteps    | 898000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.24e+03   |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179599      |\n",
      "|    policy_loss        | -16.5       |\n",
      "|    reward             | -0.11868314 |\n",
      "|    std                | 1.07e+18    |\n",
      "|    value_loss         | 0.000315    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179700      |\n",
      "|    time_elapsed       | 8647        |\n",
      "|    total_timesteps    | 898500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.25e+03   |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179699      |\n",
      "|    policy_loss        | 30.6        |\n",
      "|    reward             | -0.30944228 |\n",
      "|    std                | 1.1e+18     |\n",
      "|    value_loss         | 0.000904    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 179800      |\n",
      "|    time_elapsed       | 8652        |\n",
      "|    total_timesteps    | 899000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.25e+03   |\n",
      "|    explained_variance | 0.25        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179799      |\n",
      "|    policy_loss        | 66.2        |\n",
      "|    reward             | 0.053553186 |\n",
      "|    std                | 1.12e+18    |\n",
      "|    value_loss         | 0.00338     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 179900     |\n",
      "|    time_elapsed       | 8657       |\n",
      "|    total_timesteps    | 899500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.25e+03  |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 179899     |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | 0.25398484 |\n",
      "|    std                | 1.14e+18   |\n",
      "|    value_loss         | 0.0212     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 180000      |\n",
      "|    time_elapsed       | 8662        |\n",
      "|    total_timesteps    | 900000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.25e+03   |\n",
      "|    explained_variance | -34.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 179999      |\n",
      "|    policy_loss        | 3.51        |\n",
      "|    reward             | 0.020142138 |\n",
      "|    std                | 1.15e+18    |\n",
      "|    value_loss         | 0.00231     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 180100        |\n",
      "|    time_elapsed       | 8666          |\n",
      "|    total_timesteps    | 900500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.25e+03     |\n",
      "|    explained_variance | 0.644         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 180099        |\n",
      "|    policy_loss        | -9.65         |\n",
      "|    reward             | -0.0019480817 |\n",
      "|    std                | 1.18e+18      |\n",
      "|    value_loss         | 8.66e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 180200     |\n",
      "|    time_elapsed       | 8671       |\n",
      "|    total_timesteps    | 901000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.25e+03  |\n",
      "|    explained_variance | 0.167      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 180199     |\n",
      "|    policy_loss        | 1.67       |\n",
      "|    reward             | 0.06284731 |\n",
      "|    std                | 1.21e+18   |\n",
      "|    value_loss         | 0.000246   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 180300      |\n",
      "|    time_elapsed       | 8676        |\n",
      "|    total_timesteps    | 901500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.25e+03   |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 180299      |\n",
      "|    policy_loss        | 6.82        |\n",
      "|    reward             | 0.108286284 |\n",
      "|    std                | 1.24e+18    |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 180400     |\n",
      "|    time_elapsed       | 8681       |\n",
      "|    total_timesteps    | 902000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.25e+03  |\n",
      "|    explained_variance | 0.86       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 180399     |\n",
      "|    policy_loss        | 39.9       |\n",
      "|    reward             | 0.13399775 |\n",
      "|    std                | 1.27e+18   |\n",
      "|    value_loss         | 0.00182    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 180500     |\n",
      "|    time_elapsed       | 8687       |\n",
      "|    total_timesteps    | 902500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.25e+03  |\n",
      "|    explained_variance | 0.456      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 180499     |\n",
      "|    policy_loss        | -65.6      |\n",
      "|    reward             | 0.15042658 |\n",
      "|    std                | 1.29e+18   |\n",
      "|    value_loss         | 0.00742    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 180600        |\n",
      "|    time_elapsed       | 8692          |\n",
      "|    total_timesteps    | 903000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.25e+03     |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 180599        |\n",
      "|    policy_loss        | 14.4          |\n",
      "|    reward             | -0.0006327024 |\n",
      "|    std                | 1.31e+18      |\n",
      "|    value_loss         | 0.000159      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 180700       |\n",
      "|    time_elapsed       | 8697         |\n",
      "|    total_timesteps    | 903500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.25e+03    |\n",
      "|    explained_variance | 0.707        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 180699       |\n",
      "|    policy_loss        | -11.6        |\n",
      "|    reward             | -0.058835544 |\n",
      "|    std                | 1.34e+18     |\n",
      "|    value_loss         | 0.000289     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 180800      |\n",
      "|    time_elapsed       | 8702        |\n",
      "|    total_timesteps    | 904000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.25e+03   |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 180799      |\n",
      "|    policy_loss        | -38.2       |\n",
      "|    reward             | 0.035860203 |\n",
      "|    std                | 1.37e+18    |\n",
      "|    value_loss         | 0.000992    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 180900     |\n",
      "|    time_elapsed       | 8707       |\n",
      "|    total_timesteps    | 904500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.25e+03  |\n",
      "|    explained_variance | 0.757      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 180899     |\n",
      "|    policy_loss        | 47.2       |\n",
      "|    reward             | 0.14176431 |\n",
      "|    std                | 1.41e+18   |\n",
      "|    value_loss         | 0.00149    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 181000       |\n",
      "|    time_elapsed       | 8711         |\n",
      "|    total_timesteps    | 905000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.25e+03    |\n",
      "|    explained_variance | 0.658        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 180999       |\n",
      "|    policy_loss        | -5.26        |\n",
      "|    reward             | -0.024786552 |\n",
      "|    std                | 1.44e+18     |\n",
      "|    value_loss         | 0.000382     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 181100     |\n",
      "|    time_elapsed       | 8716       |\n",
      "|    total_timesteps    | 905500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.25e+03  |\n",
      "|    explained_variance | 0.808      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 181099     |\n",
      "|    policy_loss        | -357       |\n",
      "|    reward             | 0.11036643 |\n",
      "|    std                | 1.46e+18   |\n",
      "|    value_loss         | 0.109      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 181200        |\n",
      "|    time_elapsed       | 8721          |\n",
      "|    total_timesteps    | 906000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.25e+03     |\n",
      "|    explained_variance | 0.723         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 181199        |\n",
      "|    policy_loss        | -0.467        |\n",
      "|    reward             | -0.0015402461 |\n",
      "|    std                | 1.49e+18      |\n",
      "|    value_loss         | 0.00031       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 181300      |\n",
      "|    time_elapsed       | 8726        |\n",
      "|    total_timesteps    | 906500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.25e+03   |\n",
      "|    explained_variance | -0.454      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 181299      |\n",
      "|    policy_loss        | -41.9       |\n",
      "|    reward             | 0.005965831 |\n",
      "|    std                | 1.52e+18    |\n",
      "|    value_loss         | 0.00154     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 181400       |\n",
      "|    time_elapsed       | 8731         |\n",
      "|    total_timesteps    | 907000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.26e+03    |\n",
      "|    explained_variance | 0.48         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 181399       |\n",
      "|    policy_loss        | 22           |\n",
      "|    reward             | -0.005364023 |\n",
      "|    std                | 1.56e+18     |\n",
      "|    value_loss         | 0.000541     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 181500     |\n",
      "|    time_elapsed       | 8735       |\n",
      "|    total_timesteps    | 907500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.26e+03  |\n",
      "|    explained_variance | 0.512      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 181499     |\n",
      "|    policy_loss        | 42.2       |\n",
      "|    reward             | 0.06668691 |\n",
      "|    std                | 1.61e+18   |\n",
      "|    value_loss         | 0.00146    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 181600     |\n",
      "|    time_elapsed       | 8740       |\n",
      "|    total_timesteps    | 908000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.26e+03  |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 181599     |\n",
      "|    policy_loss        | 140        |\n",
      "|    reward             | -0.0883729 |\n",
      "|    std                | 1.64e+18   |\n",
      "|    value_loss         | 0.0162     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 181700      |\n",
      "|    time_elapsed       | 8745        |\n",
      "|    total_timesteps    | 908500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.26e+03   |\n",
      "|    explained_variance | 0.267       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 181699      |\n",
      "|    policy_loss        | 21.3        |\n",
      "|    reward             | 0.023566337 |\n",
      "|    std                | 1.66e+18    |\n",
      "|    value_loss         | 0.000358    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 181800      |\n",
      "|    time_elapsed       | 8750        |\n",
      "|    total_timesteps    | 909000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.26e+03   |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 181799      |\n",
      "|    policy_loss        | -41.7       |\n",
      "|    reward             | 0.030649796 |\n",
      "|    std                | 1.7e+18     |\n",
      "|    value_loss         | 0.00111     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 181900      |\n",
      "|    time_elapsed       | 8755        |\n",
      "|    total_timesteps    | 909500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.26e+03   |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 181899      |\n",
      "|    policy_loss        | -4.56       |\n",
      "|    reward             | 0.020316701 |\n",
      "|    std                | 1.74e+18    |\n",
      "|    value_loss         | 7.27e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 182000      |\n",
      "|    time_elapsed       | 8759        |\n",
      "|    total_timesteps    | 910000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.26e+03   |\n",
      "|    explained_variance | 0.496       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 181999      |\n",
      "|    policy_loss        | -29.2       |\n",
      "|    reward             | -0.04250752 |\n",
      "|    std                | 1.79e+18    |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 182100       |\n",
      "|    time_elapsed       | 8764         |\n",
      "|    total_timesteps    | 910500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.26e+03    |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 182099       |\n",
      "|    policy_loss        | -34.1        |\n",
      "|    reward             | -0.011786281 |\n",
      "|    std                | 1.84e+18     |\n",
      "|    value_loss         | 0.00179      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 182200      |\n",
      "|    time_elapsed       | 8769        |\n",
      "|    total_timesteps    | 911000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.26e+03   |\n",
      "|    explained_variance | 0.579       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 182199      |\n",
      "|    policy_loss        | -25.3       |\n",
      "|    reward             | -0.13141164 |\n",
      "|    std                | 1.88e+18    |\n",
      "|    value_loss         | 0.000847    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 182300       |\n",
      "|    time_elapsed       | 8774         |\n",
      "|    total_timesteps    | 911500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.26e+03    |\n",
      "|    explained_variance | 0.188        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 182299       |\n",
      "|    policy_loss        | -4.21        |\n",
      "|    reward             | -0.019836333 |\n",
      "|    std                | 1.91e+18     |\n",
      "|    value_loss         | 8.32e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 182400      |\n",
      "|    time_elapsed       | 8779        |\n",
      "|    total_timesteps    | 912000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.26e+03   |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 182399      |\n",
      "|    policy_loss        | -15.4       |\n",
      "|    reward             | -0.02128222 |\n",
      "|    std                | 1.96e+18    |\n",
      "|    value_loss         | 0.000366    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 182500     |\n",
      "|    time_elapsed       | 8784       |\n",
      "|    total_timesteps    | 912500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.26e+03  |\n",
      "|    explained_variance | 0.77       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 182499     |\n",
      "|    policy_loss        | -58.5      |\n",
      "|    reward             | 0.07004852 |\n",
      "|    std                | 2.02e+18   |\n",
      "|    value_loss         | 0.00261    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 182600     |\n",
      "|    time_elapsed       | 8789       |\n",
      "|    total_timesteps    | 913000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.26e+03  |\n",
      "|    explained_variance | 0.85       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 182599     |\n",
      "|    policy_loss        | -1.51      |\n",
      "|    reward             | 0.03778111 |\n",
      "|    std                | 2.09e+18   |\n",
      "|    value_loss         | 0.000829   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 182700     |\n",
      "|    time_elapsed       | 8793       |\n",
      "|    total_timesteps    | 913500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.26e+03  |\n",
      "|    explained_variance | 0.363      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 182699     |\n",
      "|    policy_loss        | -3.81      |\n",
      "|    reward             | 0.06424653 |\n",
      "|    std                | 2.15e+18   |\n",
      "|    value_loss         | 0.0012     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 182800      |\n",
      "|    time_elapsed       | 8798        |\n",
      "|    total_timesteps    | 914000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.732       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 182799      |\n",
      "|    policy_loss        | 64.4        |\n",
      "|    reward             | -0.34920034 |\n",
      "|    std                | 2.2e+18     |\n",
      "|    value_loss         | 0.00446     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 182900       |\n",
      "|    time_elapsed       | 8803         |\n",
      "|    total_timesteps    | 914500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.27e+03    |\n",
      "|    explained_variance | 0.328        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 182899       |\n",
      "|    policy_loss        | 5.35         |\n",
      "|    reward             | -0.008959942 |\n",
      "|    std                | 2.23e+18     |\n",
      "|    value_loss         | 5.12e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183000      |\n",
      "|    time_elapsed       | 8808        |\n",
      "|    total_timesteps    | 915000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.735       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 182999      |\n",
      "|    policy_loss        | 22.3        |\n",
      "|    reward             | 0.010561369 |\n",
      "|    std                | 2.28e+18    |\n",
      "|    value_loss         | 0.000748    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183100      |\n",
      "|    time_elapsed       | 8813        |\n",
      "|    total_timesteps    | 915500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | -0.119      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183099      |\n",
      "|    policy_loss        | -79.4       |\n",
      "|    reward             | -0.04595922 |\n",
      "|    std                | 2.35e+18    |\n",
      "|    value_loss         | 0.00637     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183200      |\n",
      "|    time_elapsed       | 8818        |\n",
      "|    total_timesteps    | 916000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.274       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183199      |\n",
      "|    policy_loss        | 57.4        |\n",
      "|    reward             | 0.056586936 |\n",
      "|    std                | 2.41e+18    |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 183300     |\n",
      "|    time_elapsed       | 8823       |\n",
      "|    total_timesteps    | 916500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.27e+03  |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 183299     |\n",
      "|    policy_loss        | 123        |\n",
      "|    reward             | -0.1053161 |\n",
      "|    std                | 2.46e+18   |\n",
      "|    value_loss         | 0.013      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183400      |\n",
      "|    time_elapsed       | 8827        |\n",
      "|    total_timesteps    | 917000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.615       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183399      |\n",
      "|    policy_loss        | -1.16e+03   |\n",
      "|    reward             | -0.21948536 |\n",
      "|    std                | 2.5e+18     |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183500      |\n",
      "|    time_elapsed       | 8832        |\n",
      "|    total_timesteps    | 917500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.642       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183499      |\n",
      "|    policy_loss        | -7.72       |\n",
      "|    reward             | 0.042011123 |\n",
      "|    std                | 2.55e+18    |\n",
      "|    value_loss         | 0.000156    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183600      |\n",
      "|    time_elapsed       | 8837        |\n",
      "|    total_timesteps    | 918000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183599      |\n",
      "|    policy_loss        | -2.48       |\n",
      "|    reward             | 0.029988015 |\n",
      "|    std                | 2.61e+18    |\n",
      "|    value_loss         | 1.31e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183700      |\n",
      "|    time_elapsed       | 8842        |\n",
      "|    total_timesteps    | 918500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.835       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183699      |\n",
      "|    policy_loss        | -36.8       |\n",
      "|    reward             | 0.003449707 |\n",
      "|    std                | 2.69e+18    |\n",
      "|    value_loss         | 0.00103     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183800      |\n",
      "|    time_elapsed       | 8847        |\n",
      "|    total_timesteps    | 919000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | -0.835      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183799      |\n",
      "|    policy_loss        | 18.9        |\n",
      "|    reward             | 0.018946612 |\n",
      "|    std                | 2.77e+18    |\n",
      "|    value_loss         | 0.000814    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 183900      |\n",
      "|    time_elapsed       | 8852        |\n",
      "|    total_timesteps    | 919500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.27e+03   |\n",
      "|    explained_variance | 0.258       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 183899      |\n",
      "|    policy_loss        | -53.9       |\n",
      "|    reward             | -0.07954717 |\n",
      "|    std                | 2.85e+18    |\n",
      "|    value_loss         | 0.0032      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 184000       |\n",
      "|    time_elapsed       | 8856         |\n",
      "|    total_timesteps    | 920000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.27e+03    |\n",
      "|    explained_variance | 0.0457       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 183999       |\n",
      "|    policy_loss        | -16.7        |\n",
      "|    reward             | -0.013521816 |\n",
      "|    std                | 2.88e+18     |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 103           |\n",
      "|    iterations         | 184100        |\n",
      "|    time_elapsed       | 8861          |\n",
      "|    total_timesteps    | 920500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -1.27e+03     |\n",
      "|    explained_variance | 0.805         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 184099        |\n",
      "|    policy_loss        | -5.45         |\n",
      "|    reward             | -0.0028386298 |\n",
      "|    std                | 2.94e+18      |\n",
      "|    value_loss         | 4.88e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 184200       |\n",
      "|    time_elapsed       | 8866         |\n",
      "|    total_timesteps    | 921000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.27e+03    |\n",
      "|    explained_variance | 0.00245      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 184199       |\n",
      "|    policy_loss        | 23.2         |\n",
      "|    reward             | -0.015593204 |\n",
      "|    std                | 3.01e+18     |\n",
      "|    value_loss         | 0.000666     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 184300      |\n",
      "|    time_elapsed       | 8871        |\n",
      "|    total_timesteps    | 921500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.28e+03   |\n",
      "|    explained_variance | 0.812       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 184299      |\n",
      "|    policy_loss        | -82.6       |\n",
      "|    reward             | -0.19089933 |\n",
      "|    std                | 3.09e+18    |\n",
      "|    value_loss         | 0.00544     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 184400     |\n",
      "|    time_elapsed       | 8876       |\n",
      "|    total_timesteps    | 922000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.28e+03  |\n",
      "|    explained_variance | 0.635      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 184399     |\n",
      "|    policy_loss        | -17.3      |\n",
      "|    reward             | 0.06872623 |\n",
      "|    std                | 3.16e+18   |\n",
      "|    value_loss         | 0.0006     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 103        |\n",
      "|    iterations         | 184500     |\n",
      "|    time_elapsed       | 8881       |\n",
      "|    total_timesteps    | 922500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.28e+03  |\n",
      "|    explained_variance | 0.893      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 184499     |\n",
      "|    policy_loss        | 190        |\n",
      "|    reward             | 0.07951947 |\n",
      "|    std                | 3.21e+18   |\n",
      "|    value_loss         | 0.0367     |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18256445.54\n",
      "total_reward: 8256445.54\n",
      "total_cost: 562410.58\n",
      "total_trades: 82654\n",
      "Sharpe: 0.476\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 103         |\n",
      "|    iterations         | 184600      |\n",
      "|    time_elapsed       | 8885        |\n",
      "|    total_timesteps    | 923000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.28e+03   |\n",
      "|    explained_variance | 0.742       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 184599      |\n",
      "|    policy_loss        | -39.7       |\n",
      "|    reward             | 0.029896725 |\n",
      "|    std                | 3.25e+18    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 103          |\n",
      "|    iterations         | 184700       |\n",
      "|    time_elapsed       | 8890         |\n",
      "|    total_timesteps    | 923500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.28e+03    |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 184699       |\n",
      "|    policy_loss        | 40.7         |\n",
      "|    reward             | -0.025337357 |\n",
      "|    std                | 3.31e+18     |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 184800    |\n",
      "|    time_elapsed       | 8895      |\n",
      "|    total_timesteps    | 924000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28e+03 |\n",
      "|    explained_variance | 0.953     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 184799    |\n",
      "|    policy_loss        | 59.5      |\n",
      "|    reward             | 0.084394  |\n",
      "|    std                | 3.39e+18  |\n",
      "|    value_loss         | 0.00221   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter scale (Tensor of shape (1, 29)) of distribution Normal(loc: torch.Size([1, 29]), scale: torch.Size([1, 29])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([[       nan, 4.1659e+18, 4.1045e+18, 3.3689e+18, 3.7400e+18, 2.9112e+18,\n         2.7592e+18, 3.1748e+18, 4.2155e+18, 3.7375e+18, 2.5572e+18, 2.7258e+18,\n         2.7860e+18, 3.9233e+18, 2.8655e+18, 2.8020e+18, 3.1212e+18, 2.3908e+18,\n         3.8255e+18, 3.1431e+18, 2.5466e+18, 4.5656e+18, 4.8230e+18, 3.4171e+18,\n         2.5781e+18, 3.7552e+18, 2.3659e+18, 3.5194e+18, 4.0348e+18]],\n       device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_a2c \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtrain_model(model\u001b[38;5;241m=\u001b[39mmodel_a2c, tb_log_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma2c\u001b[39m\u001b[38;5;124m'\u001b[39m,total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m if_using_a2c \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\coinTrader\\trading_gym\\models.py:119\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    116\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    117\u001b[0m ):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m이전에 get_model에서 설정한 모델을 훈련 데이터셋에서 훈련\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 119\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    120\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    121\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    122\u001b[0m         callback\u001b[38;5;241m=\u001b[39mTensorboardCallback(),\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[0;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    202\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    203\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    204\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    205\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    206\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    207\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    208\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_rollouts(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, callback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer, n_rollout_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps)\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:179\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 179\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy(obs_tensor)\n\u001b[0;32m    180\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:654\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[0;32m    653\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[1;32m--> 654\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n\u001b[0;32m    655\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[0;32m    656\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:694\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    691\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(mean_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[1;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m Normal(mean_actions, action_std)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\torch\\distributions\\normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(batch_shape, validate_args\u001b[38;5;241m=\u001b[39mvalidate_args)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\torch\\distributions\\distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter scale (Tensor of shape (1, 29)) of distribution Normal(loc: torch.Size([1, 29]), scale: torch.Size([1, 29])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([[       nan, 4.1659e+18, 4.1045e+18, 3.3689e+18, 3.7400e+18, 2.9112e+18,\n         2.7592e+18, 3.1748e+18, 4.2155e+18, 3.7375e+18, 2.5572e+18, 2.7258e+18,\n         2.7860e+18, 3.9233e+18, 2.8655e+18, 2.8020e+18, 3.1212e+18, 2.3908e+18,\n         3.8255e+18, 3.1431e+18, 2.5466e+18, 4.5656e+18, 4.8230e+18, 3.4171e+18,\n         2.5781e+18, 3.7552e+18, 2.3659e+18, 3.5194e+18, 4.0348e+18]],\n       device='cuda:0')"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c',total_timesteps=1000000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_a2c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_a2c\u001b[38;5;241m.\u001b[39msave(config\u001b[38;5;241m.\u001b[39mTRAINED_MODEL_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/agent_a2c\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m if_using_a2c \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trained_a2c' is not defined"
     ]
    }
   ],
   "source": [
    "trained_a2c.save(config.TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001, 'tau': 0.001, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "    # set up logger\n",
    "    tmp_path = config.RESULTS_DIR + '/ddpg'\n",
    "    new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    # Set new logger\n",
    "    model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 72        |\n",
      "|    time_elapsed    | 160       |\n",
      "|    total_timesteps | 11572     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.77e+03 |\n",
      "|    critic_loss     | 6.8e+04   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8679      |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 344       |\n",
      "|    total_timesteps | 23144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.16e+03 |\n",
      "|    critic_loss     | 1.03e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20251     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 38361272.59\n",
      "total_reward: 28361272.59\n",
      "total_cost: 10830.61\n",
      "total_trades: 46668\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 65        |\n",
      "|    time_elapsed    | 529       |\n",
      "|    total_timesteps | 34716     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.36e+03 |\n",
      "|    critic_loss     | 4.75e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 31823     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 712       |\n",
      "|    total_timesteps | 46288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.79e+03 |\n",
      "|    critic_loss     | 7.02e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 43395     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 370\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 38361272.59\n",
      "total_reward: 28361272.59\n",
      "total_cost: 10830.61\n",
      "total_trades: 46668\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 896       |\n",
      "|    total_timesteps | 57860     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.28e+03 |\n",
      "|    critic_loss     | 2.73e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 54967     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 1080      |\n",
      "|    total_timesteps | 69432     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -994      |\n",
      "|    critic_loss     | 1.13e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 66539     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 63        |\n",
      "|    time_elapsed    | 1272      |\n",
      "|    total_timesteps | 81004     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -776      |\n",
      "|    critic_loss     | 2.5e+03   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 78111     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 38361272.59\n",
      "total_reward: 28361272.59\n",
      "total_cost: 10830.61\n",
      "total_trades: 46668\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 63        |\n",
      "|    time_elapsed    | 1467      |\n",
      "|    total_timesteps | 92576     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -592      |\n",
      "|    critic_loss     | 1.45e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 89683     |\n",
      "|    reward          | 20.423101 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                                tb_log_name='ddpg',\n",
    "                                total_timesteps=100000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(config.TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 256}\n",
      "Using cuda device\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "tensorboard is not installed, you can use `pip install tensorboard` to do so",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_using_ppo:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# set up logger\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     tmp_path \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mRESULTS_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/ppo\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     new_logger_ppo \u001b[38;5;241m=\u001b[39m configure(tmp_path, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Set new logger\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     model_ppo\u001b[38;5;241m.\u001b[39mset_logger(new_logger_ppo)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\logger.py:659\u001b[0m, in \u001b[0;36mconfigure\u001b[1;34m(folder, format_strings)\u001b[0m\n\u001b[0;32m    656\u001b[0m     format_strings \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSB3_LOG_FORMAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout,log,csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    658\u001b[0m format_strings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, format_strings))\n\u001b[1;32m--> 659\u001b[0m output_formats \u001b[38;5;241m=\u001b[39m [make_output_format(f, folder, log_suffix) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m format_strings]\n\u001b[0;32m    661\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger(folder\u001b[38;5;241m=\u001b[39mfolder, output_formats\u001b[38;5;241m=\u001b[39moutput_formats)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# Only print when some files will be saved\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\logger.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    656\u001b[0m     format_strings \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSB3_LOG_FORMAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout,log,csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    658\u001b[0m format_strings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, format_strings))\n\u001b[1;32m--> 659\u001b[0m output_formats \u001b[38;5;241m=\u001b[39m [make_output_format(f, folder, log_suffix) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m format_strings]\n\u001b[0;32m    661\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger(folder\u001b[38;5;241m=\u001b[39mfolder, output_formats\u001b[38;5;241m=\u001b[39moutput_formats)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# Only print when some files will be saved\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\logger.py:465\u001b[0m, in \u001b[0;36mmake_output_format\u001b[1;34m(_format, log_dir, log_suffix)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CSVOutputFormat(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(log_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TensorBoardOutputFormat(log_dir)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown format specified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\miniconda3\\envs\\rltrade\\Lib\\site-packages\\stable_baselines3\\common\\logger.py:398\u001b[0m, in \u001b[0;36mTensorBoardOutputFormat.__init__\u001b[1;34m(self, folder)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, folder: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SummaryWriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard is not installed, you can use `pip install tensorboard` to do so\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir\u001b[38;5;241m=\u001b[39mfolder)\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: tensorboard is not installed, you can use `pip install tensorboard` to do so"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "    # set up logger\n",
    "    tmp_path = config.RESULTS_DIR + '/ppo'\n",
    "    new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    # Set new logger\n",
    "    model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_ppo \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ppo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mppo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m if_using_ppo \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\OneDrive\\document\\GitHub\\trading_gym\\models.py:119\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    116\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    117\u001b[0m ):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m이전에 get_model에서 설정한 모델을 훈련 데이터셋에서 훈련\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 119\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:194\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 194\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\rh987\\OneDrive\\document\\GitHub\\trading_gym\\env.py:470\u001b[0m, in \u001b[0;36mStockTradingEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mturbulence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrisk_indicator_col]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# 상태를 업데이트합니다.\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# 스텝 종료 후의 총 자산을 계산합니다.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m end_total_asset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\n\u001b[0;32m    474\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;241m1\u001b[39m : (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) : (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m    476\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rh987\\OneDrive\\document\\GitHub\\trading_gym\\env.py:647\u001b[0m, in \u001b[0;36mStockTradingEnv._update_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m현재 거래일의 주식 가격과 기술적 지표들의 값을 반영하여 환경의 상태를 업데이트하는 메서드입니다.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;124;03m이 메서드는 매 거래일 마다 호출되어 에이전트의 상태를 최신 정보로 업데이트합니다.\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# 여러 주식에 대한 환경일 경우\u001b[39;00m\n\u001b[1;32m--> 647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;66;03m# 현재 보유 현금은 유지하고 주식 가격을 업데이트합니다.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     state \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    650\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;241m0\u001b[39m]]  \u001b[38;5;66;03m# 현재 보유 현금\u001b[39;00m\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclose\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# 새로운 거래일의 각 주식 가격\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    660\u001b[0m         )\n\u001b[0;32m    661\u001b[0m     )\n\u001b[0;32m    663\u001b[0m \u001b[38;5;66;03m# 단일 주식에 대한 환경일 경우\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;66;03m# 현재 보유 현금은 유지하고 주식 가격을 업데이트합니다.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\pandas\\core\\series.py:2398\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2396\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\pandas\\core\\base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\pandas\\core\\algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\pandas\\core\\algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[1;34m(values, mask)\u001b[0m\n\u001b[0;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo,\n",
    "                                tb_log_name='ppo',\n",
    "                                total_timesteps=200000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(config.TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 200, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\":200,\n",
    "              \"buffer_size\": 1000000,\n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "    # set up logger\n",
    "    tmp_path = config.RESULTS_DIR + '/td3'\n",
    "    new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    # Set new logger\n",
    "    model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 460\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 48516633.69\n",
      "total_reward: 38516633.69\n",
      "total_cost: 11799.47\n",
      "total_trades: 35952\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 71       |\n",
      "|    time_elapsed    | 162      |\n",
      "|    total_timesteps | 11572    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.52e+03 |\n",
      "|    critic_loss     | 4.77e+04 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8679     |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 65       |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 23144    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.62e+03 |\n",
      "|    critic_loss     | 8.15e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20251    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 41783971.54\n",
      "total_reward: 31783971.54\n",
      "total_cost: 11962.58\n",
      "total_trades: 40707\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 64       |\n",
      "|    time_elapsed    | 534      |\n",
      "|    total_timesteps | 34716    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 857      |\n",
      "|    critic_loss     | 4.73e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31823    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 64       |\n",
      "|    time_elapsed    | 719      |\n",
      "|    total_timesteps | 46288    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 471      |\n",
      "|    critic_loss     | 2.67e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43395    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 904      |\n",
      "|    total_timesteps | 57860    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 271      |\n",
      "|    critic_loss     | 1.89e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 54967    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 41783971.54\n",
      "total_reward: 31783971.54\n",
      "total_cost: 11962.58\n",
      "total_trades: 40707\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 1089     |\n",
      "|    total_timesteps | 69432    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 179      |\n",
      "|    critic_loss     | 1.55e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 66539    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 1275     |\n",
      "|    total_timesteps | 81004    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 149      |\n",
      "|    critic_loss     | 1.54e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 78111    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 41783971.54\n",
      "total_reward: 31783971.54\n",
      "total_cost: 11962.58\n",
      "total_trades: 40707\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 1460     |\n",
      "|    total_timesteps | 92576    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 168      |\n",
      "|    critic_loss     | 1.14e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 89683    |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 1646     |\n",
      "|    total_timesteps | 104148   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 181      |\n",
      "|    critic_loss     | 923      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 101255   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 1832     |\n",
      "|    total_timesteps | 115720   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 188      |\n",
      "|    critic_loss     | 774      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 112827   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 41783971.54\n",
      "total_reward: 31783971.54\n",
      "total_cost: 11962.58\n",
      "total_trades: 40707\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 2015     |\n",
      "|    total_timesteps | 127292   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 185      |\n",
      "|    critic_loss     | 821      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 124399   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 2200     |\n",
      "|    total_timesteps | 138864   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 211      |\n",
      "|    critic_loss     | 828      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 135971   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 41783971.54\n",
      "total_reward: 31783971.54\n",
      "total_cost: 11962.58\n",
      "total_trades: 40707\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 62       |\n",
      "|    time_elapsed    | 2387     |\n",
      "|    total_timesteps | 150436   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 210      |\n",
      "|    critic_loss     | 709      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 147543   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 62       |\n",
      "|    time_elapsed    | 2575     |\n",
      "|    total_timesteps | 162008   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 206      |\n",
      "|    critic_loss     | 638      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 159115   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 62       |\n",
      "|    time_elapsed    | 2765     |\n",
      "|    total_timesteps | 173580   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 203      |\n",
      "|    critic_loss     | 593      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 170687   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 41783971.54\n",
      "total_reward: 31783971.54\n",
      "total_cost: 11962.58\n",
      "total_trades: 40707\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 62       |\n",
      "|    time_elapsed    | 2951     |\n",
      "|    total_timesteps | 185152   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 201      |\n",
      "|    critic_loss     | 546      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 182259   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 3121     |\n",
      "|    total_timesteps | 196724   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 198      |\n",
      "|    critic_loss     | 514      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 193831   |\n",
      "|    reward          | 65.6913  |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3,\n",
    "                                tb_log_name='td3',\n",
    "                                total_timesteps=200000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(config.TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 512, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to results/sac\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 512,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "    # set up logger\n",
    "    tmp_path = config.RESULTS_DIR + '/sac'\n",
    "    new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    # Set new logger\n",
    "    model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 34        |\n",
      "|    time_elapsed    | 339       |\n",
      "|    total_timesteps | 11572     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.61e+03  |\n",
      "|    critic_loss     | 6.31e+03  |\n",
      "|    ent_coef        | 0.305     |\n",
      "|    ent_coef_loss   | 433       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 11471     |\n",
      "|    reward          | 21.670313 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 46491550.52\n",
      "total_reward: 36491550.52\n",
      "total_cost: 9990.01\n",
      "total_trades: 36965\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 34        |\n",
      "|    time_elapsed    | 673       |\n",
      "|    total_timesteps | 23144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.47e+04  |\n",
      "|    critic_loss     | 2.2e+05   |\n",
      "|    ent_coef        | 0.97      |\n",
      "|    ent_coef_loss   | 11.2      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 23043     |\n",
      "|    reward          | 21.670313 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 34        |\n",
      "|    time_elapsed    | 1009      |\n",
      "|    total_timesteps | 34716     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.26e+04  |\n",
      "|    critic_loss     | 3.18e+05  |\n",
      "|    ent_coef        | 3.08      |\n",
      "|    ent_coef_loss   | -411      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 34615     |\n",
      "|    reward          | 21.670313 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 34        |\n",
      "|    time_elapsed    | 1334      |\n",
      "|    total_timesteps | 46288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.34e+05  |\n",
      "|    critic_loss     | 2.03e+05  |\n",
      "|    ent_coef        | 9.81      |\n",
      "|    ent_coef_loss   | -834      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 46187     |\n",
      "|    reward          | 21.670313 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 46491550.52\n",
      "total_reward: 36491550.52\n",
      "total_cost: 9990.01\n",
      "total_trades: 36965\n",
      "Sharpe: 0.804\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                                tb_log_name='sac',\n",
    "                                total_timesteps=50000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(config.TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "from env import StockTradingEnv\n",
    "from helper_function import check_and_make_directories\n",
    "from models import DRLAgent, DRLEnsembleAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "import config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_data.csv')\n",
    "trade = pd.read_csv('./data/trade_data.csv')\n",
    "backtest = pd.read_csv('./data/backtest_data.csv')\n",
    "\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']\n",
    "backtest = backtest.set_index(backtest.columns[0])\n",
    "backtest.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83897, 18), (9744, 18), (1218, 18))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, trade.shape, backtest.shape #((83897, 18), (9744, 18), (1218, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c = A2C.load(config.TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(config.TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(config.TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
    "trained_td3 = TD3.load(config.TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(config.TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space =  2 * stock_dimension + len(config.INDICATORS) * stock_dimension + 1\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space =  2 * stock_dimension + len(config.INDICATORS) * stock_dimension + 1\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a2c</th>\n",
       "      <th>ddpg</th>\n",
       "      <th>ppo</th>\n",
       "      <th>td3</th>\n",
       "      <th>sac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>1.000605e+06</td>\n",
       "      <td>1.000505e+06</td>\n",
       "      <td>9.999845e+05</td>\n",
       "      <td>1.000616e+06</td>\n",
       "      <td>1.000692e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>1.004745e+06</td>\n",
       "      <td>1.007153e+06</td>\n",
       "      <td>1.001484e+06</td>\n",
       "      <td>1.006339e+06</td>\n",
       "      <td>1.004316e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>9.973455e+05</td>\n",
       "      <td>9.971031e+05</td>\n",
       "      <td>9.998880e+05</td>\n",
       "      <td>9.971507e+05</td>\n",
       "      <td>9.946596e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>1.000388e+06</td>\n",
       "      <td>1.002498e+06</td>\n",
       "      <td>1.001162e+06</td>\n",
       "      <td>1.001873e+06</td>\n",
       "      <td>9.967409e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-21</th>\n",
       "      <td>1.377686e+06</td>\n",
       "      <td>1.432363e+06</td>\n",
       "      <td>1.339935e+06</td>\n",
       "      <td>1.450914e+06</td>\n",
       "      <td>1.357916e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>1.385633e+06</td>\n",
       "      <td>1.435234e+06</td>\n",
       "      <td>1.348031e+06</td>\n",
       "      <td>1.454722e+06</td>\n",
       "      <td>1.364988e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>1.386418e+06</td>\n",
       "      <td>1.441563e+06</td>\n",
       "      <td>1.349106e+06</td>\n",
       "      <td>1.453191e+06</td>\n",
       "      <td>1.368827e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>1.388158e+06</td>\n",
       "      <td>1.438758e+06</td>\n",
       "      <td>1.355731e+06</td>\n",
       "      <td>1.457262e+06</td>\n",
       "      <td>1.367393e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>1.380367e+06</td>\n",
       "      <td>1.417403e+06</td>\n",
       "      <td>1.344711e+06</td>\n",
       "      <td>1.458548e+06</td>\n",
       "      <td>1.356979e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     a2c          ddpg           ppo           td3  \\\n",
       "date                                                                 \n",
       "2020-07-01  1.000000e+06  1.000000e+06  1.000000e+06  1.000000e+06   \n",
       "2020-07-02  1.000605e+06  1.000505e+06  9.999845e+05  1.000616e+06   \n",
       "2020-07-06  1.004745e+06  1.007153e+06  1.001484e+06  1.006339e+06   \n",
       "2020-07-07  9.973455e+05  9.971031e+05  9.998880e+05  9.971507e+05   \n",
       "2020-07-08  1.000388e+06  1.002498e+06  1.001162e+06  1.001873e+06   \n",
       "...                  ...           ...           ...           ...   \n",
       "2021-10-21  1.377686e+06  1.432363e+06  1.339935e+06  1.450914e+06   \n",
       "2021-10-22  1.385633e+06  1.435234e+06  1.348031e+06  1.454722e+06   \n",
       "2021-10-25  1.386418e+06  1.441563e+06  1.349106e+06  1.453191e+06   \n",
       "2021-10-26  1.388158e+06  1.438758e+06  1.355731e+06  1.457262e+06   \n",
       "2021-10-27  1.380367e+06  1.417403e+06  1.344711e+06  1.458548e+06   \n",
       "\n",
       "                     sac  \n",
       "date                      \n",
       "2020-07-01  1.000000e+06  \n",
       "2020-07-02  1.000692e+06  \n",
       "2020-07-06  1.004316e+06  \n",
       "2020-07-07  9.946596e+05  \n",
       "2020-07-08  9.967409e+05  \n",
       "...                  ...  \n",
       "2021-10-21  1.357916e+06  \n",
       "2021-10-22  1.364988e+06  \n",
       "2021-10-25  1.368827e+06  \n",
       "2021-10-26  1.367393e+06  \n",
       "2021-10-27  1.356979e+06  \n",
       "\n",
       "[335 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_a2c = (\n",
    "    df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "    if if_using_a2c\n",
    "    else None\n",
    ")\n",
    "df_result_ddpg = (\n",
    "    df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "    if if_using_ddpg\n",
    "    else None\n",
    ")\n",
    "df_result_ppo = (\n",
    "    df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "    if if_using_ppo\n",
    "    else None\n",
    ")\n",
    "df_result_td3 = (\n",
    "    df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "    if if_using_td3\n",
    "    else None\n",
    ")\n",
    "df_result_sac = (\n",
    "    df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "    if if_using_sac\n",
    "    else None\n",
    ")\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"a2c\": df_result_a2c[\"account_value\"] if if_using_a2c else None,\n",
    "        \"ddpg\": df_result_ddpg[\"account_value\"] if if_using_ddpg else None,\n",
    "        \"ppo\": df_result_ppo[\"account_value\"] if if_using_ppo else None,\n",
    "        \"td3\": df_result_td3[\"account_value\"] if if_using_td3 else None,\n",
    "        \"sac\": df_result_sac[\"account_value\"] if if_using_sac else None,\n",
    "    }\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.743889</td>\n",
       "      <td>746015200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965561</td>\n",
       "      <td>2.638020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.743889</td>\n",
       "      <td>2.743889</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>42.406384</td>\n",
       "      <td>6547900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965561</td>\n",
       "      <td>2.638020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>42.406384</td>\n",
       "      <td>42.406384</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.144917</td>\n",
       "      <td>10955700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965561</td>\n",
       "      <td>2.638020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15.144917</td>\n",
       "      <td>15.144917</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941105</td>\n",
       "      <td>7010200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965561</td>\n",
       "      <td>2.638020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>33.941105</td>\n",
       "      <td>33.941105</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>30.950016</td>\n",
       "      <td>7117200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965561</td>\n",
       "      <td>2.638020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30.950016</td>\n",
       "      <td>30.950016</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>UNH</td>\n",
       "      <td>454.640015</td>\n",
       "      <td>460.440002</td>\n",
       "      <td>453.480011</td>\n",
       "      <td>437.944458</td>\n",
       "      <td>3520400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.262194</td>\n",
       "      <td>448.257368</td>\n",
       "      <td>359.524569</td>\n",
       "      <td>65.085958</td>\n",
       "      <td>174.381470</td>\n",
       "      <td>30.848035</td>\n",
       "      <td>400.928238</td>\n",
       "      <td>401.210696</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>145.430579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>V</td>\n",
       "      <td>224.750000</td>\n",
       "      <td>224.750000</td>\n",
       "      <td>215.660004</td>\n",
       "      <td>211.704575</td>\n",
       "      <td>22958100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>232.560551</td>\n",
       "      <td>214.422810</td>\n",
       "      <td>41.737199</td>\n",
       "      <td>-153.656516</td>\n",
       "      <td>23.662740</td>\n",
       "      <td>222.603772</td>\n",
       "      <td>224.808517</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>145.430579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>VZ</td>\n",
       "      <td>53.169998</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>52.470001</td>\n",
       "      <td>45.713467</td>\n",
       "      <td>15007400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.212331</td>\n",
       "      <td>47.395247</td>\n",
       "      <td>44.442474</td>\n",
       "      <td>44.604906</td>\n",
       "      <td>-49.992631</td>\n",
       "      <td>13.530363</td>\n",
       "      <td>46.145385</td>\n",
       "      <td>46.739158</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>145.430579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>WBA</td>\n",
       "      <td>48.450001</td>\n",
       "      <td>48.459999</td>\n",
       "      <td>47.090000</td>\n",
       "      <td>41.145203</td>\n",
       "      <td>5652000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.014347</td>\n",
       "      <td>43.719330</td>\n",
       "      <td>40.033685</td>\n",
       "      <td>46.167781</td>\n",
       "      <td>-61.908828</td>\n",
       "      <td>4.316183</td>\n",
       "      <td>42.073996</td>\n",
       "      <td>42.385609</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>145.430579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>WMT</td>\n",
       "      <td>49.653332</td>\n",
       "      <td>49.673332</td>\n",
       "      <td>49.130001</td>\n",
       "      <td>47.335766</td>\n",
       "      <td>14565600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.501157</td>\n",
       "      <td>48.425723</td>\n",
       "      <td>42.596410</td>\n",
       "      <td>57.061031</td>\n",
       "      <td>124.822780</td>\n",
       "      <td>16.567772</td>\n",
       "      <td>45.606360</td>\n",
       "      <td>46.492090</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>145.430579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93612 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   tic        open        high         low       close  \\\n",
       "                                                                        \n",
       "0    2009-01-02  AAPL    3.067143    3.251429    3.041429    2.743889   \n",
       "0    2009-01-02  AMGN   58.590000   59.080002   57.750000   42.406384   \n",
       "0    2009-01-02   AXP   18.570000   19.520000   18.400000   15.144917   \n",
       "0    2009-01-02    BA   42.799999   45.560001   42.779999   33.941105   \n",
       "0    2009-01-02   CAT   44.910000   46.980000   44.709999   30.950016   \n",
       "..          ...   ...         ...         ...         ...         ...   \n",
       "334  2021-10-27   UNH  454.640015  460.440002  453.480011  437.944458   \n",
       "334  2021-10-27     V  224.750000  224.750000  215.660004  211.704575   \n",
       "334  2021-10-27    VZ   53.169998   53.200001   52.470001   45.713467   \n",
       "334  2021-10-27   WBA   48.450001   48.459999   47.090000   41.145203   \n",
       "334  2021-10-27   WMT   49.653332   49.673332   49.130001   47.335766   \n",
       "\n",
       "          volume  day       macd     boll_ub     boll_lb      rsi_30  \\\n",
       "                                                                       \n",
       "0    746015200.0  4.0   0.000000    2.965561    2.638020  100.000000   \n",
       "0      6547900.0  4.0   0.000000    2.965561    2.638020  100.000000   \n",
       "0     10955700.0  4.0   0.000000    2.965561    2.638020  100.000000   \n",
       "0      7010200.0  4.0   0.000000    2.965561    2.638020  100.000000   \n",
       "0      7117200.0  4.0   0.000000    2.965561    2.638020  100.000000   \n",
       "..           ...  ...        ...         ...         ...         ...   \n",
       "334    3520400.0  2.0  11.262194  448.257368  359.524569   65.085958   \n",
       "334   22958100.0  2.0   0.013774  232.560551  214.422810   41.737199   \n",
       "334   15007400.0  2.0  -0.212331   47.395247   44.442474   44.604906   \n",
       "334    5652000.0  2.0  -0.014347   43.719330   40.033685   46.167781   \n",
       "334   14565600.0  2.0   0.501157   48.425723   42.596410   57.061031   \n",
       "\n",
       "         cci_30       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "                                                                                \n",
       "0     66.666667  100.000000      2.743889      2.743889  39.189999    0.000000  \n",
       "0     66.666667  100.000000     42.406384     42.406384  39.189999    0.000000  \n",
       "0     66.666667  100.000000     15.144917     15.144917  39.189999    0.000000  \n",
       "0     66.666667  100.000000     33.941105     33.941105  39.189999    0.000000  \n",
       "0     66.666667  100.000000     30.950016     30.950016  39.189999    0.000000  \n",
       "..          ...         ...           ...           ...        ...         ...  \n",
       "334  174.381470   30.848035    400.928238    401.210696  16.980000  145.430579  \n",
       "334 -153.656516   23.662740    222.603772    224.808517  16.980000  145.430579  \n",
       "334  -49.992631   13.530363     46.145385     46.739158  16.980000  145.430579  \n",
       "334  -61.908828    4.316183     42.073996     42.385609  16.980000  145.430579  \n",
       "334  124.822780   16.567772     45.606360     46.492090  16.980000  145.430579  \n",
       "\n",
       "[93612 rows x 18 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train, trade], axis=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=data,\n",
    "                                  train_period=(config.TRAIN_START_DATE,config.TRAIN_END_DATE),\n",
    "                                  val_test_period=(config.TEST_START_DATE,config.TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window, \n",
    "                                  validation_window=validation_window, \n",
    "                                  **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_dict = {'a2c' : 10000, \n",
    "                  'ppo' : 10000, \n",
    "                  'ddpg' : 10000,\n",
    "                  'sac' : 10000,\n",
    "                  'td3' : 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  201.7418446302624\n",
      "======Model training from:  2009-01-01 to  2020-07-02\n",
      "======a2c Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c\\a2c_126_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\rh987\\miniconda3\\envs\\torchrl\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 77          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | -2.49       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 33.6        |\n",
      "|    reward             | -0.11425099 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.913       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -108       |\n",
      "|    reward             | -2.1246612 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 7.9        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -354      |\n",
      "|    reward             | 6.5436683 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 70.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 250        |\n",
      "|    reward             | -2.0997536 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 34.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 403        |\n",
      "|    reward             | -8.9598675 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 147        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 80         |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 33.8       |\n",
      "|    reward             | -0.1490408 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.832      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -46.8     |\n",
      "|    reward             | 1.0139596 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.71      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | -0.467    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 0.8615896 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.78      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 37.4       |\n",
      "|    reward             | -0.4478315 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.97       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 79          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 55.4        |\n",
      "|    reward             | -0.56525487 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0.00123    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -308       |\n",
      "|    reward             | -15.498025 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 58         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 79         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0.0852     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -164       |\n",
      "|    reward             | 0.31252682 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 17.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | -0.93     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 81.3      |\n",
      "|    reward             | 1.9273142 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 7.58      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 244        |\n",
      "|    reward             | 0.69894767 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 40.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -86.8      |\n",
      "|    reward             | -1.5744772 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 17.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 78         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -590       |\n",
      "|    reward             | 0.31345004 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 219        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 49.7     |\n",
      "|    reward             | 8.346116 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 27       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -0.233    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 15.6      |\n",
      "|    reward             | 0.7410156 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.461     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | -0.0104   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 54.5      |\n",
      "|    reward             | 1.4491684 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -114      |\n",
      "|    reward             | 2.7549186 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.44      |\n",
      "-------------------------------------\n",
      "======a2c Validation from:  2020-07-02 to  2020-10-01\n",
      "a2c Sharpe Ratio:  0.13852253563346653\n",
      "======ddpg Training========\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001, 'tau': 0.001, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_126_1\n",
      "day: 2893, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4283087.55\n",
      "total_reward: 3283087.55\n",
      "total_cost: 4425.43\n",
      "total_trades: 53702\n",
      "Sharpe: 0.865\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 60          |\n",
      "|    time_elapsed    | 192         |\n",
      "|    total_timesteps | 11576       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.264      |\n",
      "|    critic_loss     | 214         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 8682        |\n",
      "|    reward          | -0.15214773 |\n",
      "------------------------------------\n",
      "======ddpg Validation from:  2020-07-02 to  2020-10-01\n",
      "ddpg Sharpe Ratio:  0.20794115481112596\n",
      "======td3 Training========\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/td3\\td3_126_1\n",
      "day: 2893, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3838555.50\n",
      "total_reward: 2838555.50\n",
      "total_cost: 6929.78\n",
      "total_trades: 32910\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 63        |\n",
      "|    time_elapsed    | 182       |\n",
      "|    total_timesteps | 11576     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.56      |\n",
      "|    critic_loss     | 277       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8682      |\n",
      "|    reward          | 3.0022774 |\n",
      "----------------------------------\n",
      "======td3 Validation from:  2020-07-02 to  2020-10-01\n",
      "td3 Sharpe Ratio:  0.31451670240992796\n",
      "======sac Training========\n",
      "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/sac\\sac_126_1\n",
      "day: 2893, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3508915.42\n",
      "total_reward: 2508915.42\n",
      "total_cost: 23119.25\n",
      "total_trades: 42472\n",
      "Sharpe: 0.618\n",
      "=================================\n",
      "======sac Validation from:  2020-07-02 to  2020-10-01\n",
      "sac Sharpe Ratio:  0.060591632374204486\n",
      "======ppo Training========\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo\\ppo_126_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 80        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 25        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.2321327 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022329696 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00128     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    reward               | 1.4695786   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "day: 2893, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3317729.31\n",
      "total_reward: 2317729.31\n",
      "total_cost: 327878.82\n",
      "total_trades: 80925\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01841313  |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.000618   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -0.07443262 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020836823 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00497     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -0.79845047 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022334097 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.018      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -1.872047   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "======ppo Validation from:  2020-07-02 to  2020-10-01\n",
      "ppo Sharpe Ratio:  0.22561020493822723\n",
      "======Best Model Retraining from:  2009-01-01 to  2020-10-01\n",
      "======Trading from:  2020-10-01 to  2020-12-31\n",
      "============================================\n",
      "turbulence_threshold:  201.7418446302624\n",
      "======Model training from:  2009-01-01 to  2020-10-01\n",
      "======a2c Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c\\a2c_189_1\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 65         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | -0.0705    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -46.3      |\n",
      "|    reward             | 0.13536833 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2          |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -2.78e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -66.6      |\n",
      "|    reward             | -1.2372043 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.59       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -256     |\n",
      "|    reward             | 8.017851 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 43.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -120     |\n",
      "|    reward             | 2.597078 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 70         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 643        |\n",
      "|    reward             | -10.762478 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 265        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 71          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -51.3       |\n",
      "|    reward             | -0.44143936 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 70         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -1.28      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -104       |\n",
      "|    reward             | -2.4251962 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.76       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0.012     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -63.3     |\n",
      "|    reward             | 1.3950284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.68      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -0.0115   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 5.18      |\n",
      "|    reward             | 6.1449265 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.07      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 71        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 178       |\n",
      "|    reward             | 2.3126626 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 747       |\n",
      "|    reward             | 0.1363774 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 426       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 71         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 84         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -2.78      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 132        |\n",
      "|    reward             | -2.3916767 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 17.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 71        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 27.9      |\n",
      "|    reward             | -0.294763 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.69      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 71         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 44.4       |\n",
      "|    reward             | -1.7677687 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 71         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 105        |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -118       |\n",
      "|    reward             | 0.20065843 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 8.94       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 71         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 20.9       |\n",
      "|    reward             | 0.18995465 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 71        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 168       |\n",
      "|    reward             | 8.872824  |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 71        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 2.81      |\n",
      "|    reward             | 0.8568319 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0.0783    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -109      |\n",
      "|    reward             | 1.3113788 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.46      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 70         |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -260       |\n",
      "|    reward             | -2.2113864 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 48.6       |\n",
      "--------------------------------------\n",
      "======a2c Validation from:  2020-10-01 to  2020-12-31\n",
      "a2c Sharpe Ratio:  0.263080685034587\n",
      "======ddpg Training========\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001, 'tau': 0.001, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_189_1\n",
      "day: 2956, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7632720.15\n",
      "total_reward: 6632720.15\n",
      "total_cost: 5169.95\n",
      "total_trades: 41135\n",
      "Sharpe: 1.106\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 60        |\n",
      "|    time_elapsed    | 196       |\n",
      "|    total_timesteps | 11828     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 29.3      |\n",
      "|    critic_loss     | 74.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8871      |\n",
      "|    reward          | 6.0026937 |\n",
      "----------------------------------\n",
      "======ddpg Validation from:  2020-10-01 to  2020-12-31\n",
      "ddpg Sharpe Ratio:  0.33467596237630753\n",
      "======td3 Training========\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/td3\\td3_189_1\n",
      "day: 2956, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5112151.63\n",
      "total_reward: 4112151.63\n",
      "total_cost: 6156.83\n",
      "total_trades: 37637\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 184       |\n",
      "|    total_timesteps | 11828     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 149       |\n",
      "|    critic_loss     | 1.35e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8871      |\n",
      "|    reward          | 5.4532657 |\n",
      "----------------------------------\n",
      "======td3 Validation from:  2020-10-01 to  2020-12-31\n",
      "td3 Sharpe Ratio:  0.30504991399211123\n",
      "======sac Training========\n",
      "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/sac\\sac_189_1\n",
      "day: 2956, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4868618.72\n",
      "total_reward: 3868618.72\n",
      "total_cost: 22665.25\n",
      "total_trades: 44719\n",
      "Sharpe: 0.600\n",
      "=================================\n",
      "======sac Validation from:  2020-10-01 to  2020-12-31\n",
      "sac Sharpe Ratio:  0.1772782787691733\n",
      "======ppo Training========\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo\\ppo_189_1\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 76         |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 26         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | -0.2715083 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018982742 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.00553    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    reward               | -0.68025804 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "day: 2956, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4824824.00\n",
      "total_reward: 3824824.00\n",
      "total_cost: 343937.07\n",
      "total_trades: 83006\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018063597 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0099     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 1.1516384   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019672547 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.00575     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 2.615145    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022104006 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.023      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -0.9267656  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "======ppo Validation from:  2020-10-01 to  2020-12-31\n",
      "ppo Sharpe Ratio:  0.165124268516502\n",
      "======Best Model Retraining from:  2009-01-01 to  2020-12-31\n",
      "======Trading from:  2020-12-31 to  2021-04-05\n",
      "============================================\n",
      "turbulence_threshold:  201.7418446302624\n",
      "======Model training from:  2009-01-01 to  2020-12-31\n",
      "======a2c Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c\\a2c_252_1\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 64           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.1        |\n",
      "|    explained_variance | -0.0255      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -48.8        |\n",
      "|    reward             | -0.023074377 |\n",
      "|    std                | 0.999        |\n",
      "|    value_loss         | 4.46         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 65         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0.212      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -39.4      |\n",
      "|    reward             | -1.5799559 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 68        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -172      |\n",
      "|    reward             | 5.4620523 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 68        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -26.2     |\n",
      "|    reward             | 1.6973296 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 9.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 398       |\n",
      "|    reward             | -9.925064 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 171       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 310         |\n",
      "|    reward             | -0.36474425 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 105         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 31.1        |\n",
      "|    reward             | -0.46485063 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -76       |\n",
      "|    reward             | 1.8701109 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.37      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 53.6       |\n",
      "|    reward             | -0.9546617 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.66       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -66.5      |\n",
      "|    reward             | -1.2958795 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 8.28       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0.105     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 182       |\n",
      "|    reward             | 10.853601 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 39.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0.0223   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -686     |\n",
      "|    reward             | 8.060127 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 291      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 10.4       |\n",
      "|    reward             | 0.49366575 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.569      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 100        |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 164        |\n",
      "|    reward             | -2.3858194 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 14         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -429      |\n",
      "|    reward             | 6.6528687 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 138       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | -0.0288   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    reward             | -1.038962 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 11.6      |\n",
      "|    reward             | -9.918955 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 70         |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 487        |\n",
      "|    reward             | -12.186446 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 186        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 70         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 48.8       |\n",
      "|    reward             | 0.18745477 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 70         |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 29.4       |\n",
      "|    reward             | -0.7078008 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.62       |\n",
      "--------------------------------------\n",
      "======a2c Validation from:  2020-12-31 to  2021-04-05\n",
      "a2c Sharpe Ratio:  0.22495341236805527\n",
      "======ddpg Training========\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001, 'tau': 0.001, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_252_1\n",
      "day: 3019, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8650964.43\n",
      "total_reward: 7650964.43\n",
      "total_cost: 5211.10\n",
      "total_trades: 56046\n",
      "Sharpe: 1.010\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 61         |\n",
      "|    time_elapsed    | 197        |\n",
      "|    total_timesteps | 12080      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -144       |\n",
      "|    critic_loss     | 2.35e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 9060       |\n",
      "|    reward          | -0.3852896 |\n",
      "-----------------------------------\n",
      "======ddpg Validation from:  2020-12-31 to  2021-04-05\n",
      "ddpg Sharpe Ratio:  0.3773807184376745\n",
      "======td3 Training========\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/td3\\td3_252_1\n",
      "day: 3019, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6091657.99\n",
      "total_reward: 5091657.99\n",
      "total_cost: 5101.93\n",
      "total_trades: 47289\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 62        |\n",
      "|    time_elapsed    | 193       |\n",
      "|    total_timesteps | 12080     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 204       |\n",
      "|    critic_loss     | 6.09e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9060      |\n",
      "|    reward          | 2.2278507 |\n",
      "----------------------------------\n",
      "======td3 Validation from:  2020-12-31 to  2021-04-05\n",
      "td3 Sharpe Ratio:  0.422257230023241\n",
      "======sac Training========\n",
      "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/sac\\sac_252_1\n",
      "day: 3019, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4586758.87\n",
      "total_reward: 3586758.87\n",
      "total_cost: 5945.26\n",
      "total_trades: 50480\n",
      "Sharpe: 0.841\n",
      "=================================\n",
      "======sac Validation from:  2020-12-31 to  2021-04-05\n",
      "sac Sharpe Ratio:  0.24957754680083816\n",
      "======ppo Training========\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo\\ppo_252_1\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 74         |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 27         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.58751607 |\n",
      "-----------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 74         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01966454 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.2      |\n",
      "|    explained_variance   | -0.0104    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.67       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    reward               | -3.9014027 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "day: 3019, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4687875.59\n",
      "total_reward: 3687875.59\n",
      "total_cost: 354707.03\n",
      "total_trades: 84536\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022896975 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00651     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | -0.20352456 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023227872 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00678     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -0.33037394 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023748461 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.0321     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 1.5011356   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "======ppo Validation from:  2020-12-31 to  2021-04-05\n",
      "ppo Sharpe Ratio:  0.3081742448590502\n",
      "======Best Model Retraining from:  2009-01-01 to  2021-04-05\n",
      "======Trading from:  2021-04-05 to  2021-07-02\n",
      "============================================\n",
      "turbulence_threshold:  201.7418446302624\n",
      "======Model training from:  2009-01-01 to  2021-04-05\n",
      "======a2c Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c\\a2c_315_1\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 60          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -37.7       |\n",
      "|    reward             | 0.023488058 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -87.3      |\n",
      "|    reward             | -2.1999977 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.49       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 0.0637   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -357     |\n",
      "|    reward             | 8.426557 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 73.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 64         |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -65.1      |\n",
      "|    reward             | 0.37013558 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 65        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 936       |\n",
      "|    reward             | -18.36028 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 824       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | -1.07e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 60.8      |\n",
      "|    reward             | 13.181875 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 122       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0.00835   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -85.7     |\n",
      "|    reward             | -2.089965 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.75      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 17.9      |\n",
      "|    reward             | 0.7665293 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.407     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | -0.0324   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 199       |\n",
      "|    reward             | 1.2027841 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 33.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 66         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 275        |\n",
      "|    reward             | -1.8423326 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 70.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 138       |\n",
      "|    reward             | 3.6486237 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 18.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 454       |\n",
      "|    reward             | 17.407944 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 184       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -29.2     |\n",
      "|    reward             | 1.5581889 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.45      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -76.6     |\n",
      "|    reward             | 2.5227592 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.92      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 66         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0.00148    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -32.1      |\n",
      "|    reward             | -1.4407735 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 10.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -118      |\n",
      "|    reward             | 1.4165797 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0.00761   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 787       |\n",
      "|    reward             | 7.3792214 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 493       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 66         |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.1      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 965        |\n",
      "|    reward             | -7.9229307 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.43e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 66         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -24.6      |\n",
      "|    reward             | -1.7008816 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.774      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 66        |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 53.8      |\n",
      "|    reward             | 2.4030695 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "======a2c Validation from:  2021-04-05 to  2021-07-02\n",
      "a2c Sharpe Ratio:  0.28536891535955927\n",
      "======ddpg Training========\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001, 'tau': 0.001, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_315_1\n",
      "day: 3082, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5761961.36\n",
      "total_reward: 4761961.36\n",
      "total_cost: 7747.52\n",
      "total_trades: 48743\n",
      "Sharpe: 0.886\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 215       |\n",
      "|    total_timesteps | 12332     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 27        |\n",
      "|    critic_loss     | 233       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9249      |\n",
      "|    reward          | 2.0886035 |\n",
      "----------------------------------\n",
      "======ddpg Validation from:  2021-04-05 to  2021-07-02\n",
      "ddpg Sharpe Ratio:  0.2787551119097248\n",
      "======td3 Training========\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/td3\\td3_315_1\n",
      "day: 3082, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4547186.69\n",
      "total_reward: 3547186.69\n",
      "total_cost: 6633.37\n",
      "total_trades: 30682\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 209      |\n",
      "|    total_timesteps | 12332    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 164      |\n",
      "|    critic_loss     | 2.02e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9249     |\n",
      "|    reward          | 4.524651 |\n",
      "---------------------------------\n",
      "======td3 Validation from:  2021-04-05 to  2021-07-02\n",
      "td3 Sharpe Ratio:  0.2221262917860182\n",
      "======sac Training========\n",
      "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/sac\\sac_315_1\n",
      "day: 3082, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5868732.55\n",
      "total_reward: 4868732.55\n",
      "total_cost: 19764.46\n",
      "total_trades: 45841\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "======sac Validation from:  2021-04-05 to  2021-07-02\n",
      "sac Sharpe Ratio:  0.10447244663261863\n",
      "======ppo Training========\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo\\ppo_315_1\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 75          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 26          |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.028060392 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019916771 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    reward               | -0.1602013  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017005796 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.0058      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -1.3046541  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "day: 3082, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4148425.38\n",
      "total_reward: 3148425.38\n",
      "total_cost: 354750.50\n",
      "total_trades: 85480\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01768795 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.2      |\n",
      "|    explained_variance   | -0.00718   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.6       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    reward               | 0.8116749  |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 117        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02441414 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.3      |\n",
      "|    explained_variance   | 0.0187     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.68       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    reward               | 0.36064985 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 15.1       |\n",
      "----------------------------------------\n",
      "======ppo Validation from:  2021-04-05 to  2021-07-02\n",
      "ppo Sharpe Ratio:  0.10527456985399974\n",
      "======Best Model Retraining from:  2009-01-01 to  2021-07-02\n",
      "======Trading from:  2021-07-02 to  2021-10-01\n",
      "Ensemble Strategy took:  67.77896611690521  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(config.A2C_PARAMS,\n",
    "                                                  config.PPO_PARAMS,\n",
    "                                                  config.DDPG_PARAMS,\n",
    "                                                  config.SAC_PARAMS,\n",
    "                                                  config.TD3_PARAMS,\n",
    "                                                  timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "      <th>SAC Sharpe</th>\n",
       "      <th>TD3 Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>TD3</td>\n",
       "      <td>0.138523</td>\n",
       "      <td>0.22561</td>\n",
       "      <td>0.207941</td>\n",
       "      <td>0.060592</td>\n",
       "      <td>0.314517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.263081</td>\n",
       "      <td>0.165124</td>\n",
       "      <td>0.334676</td>\n",
       "      <td>0.177278</td>\n",
       "      <td>0.30505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>TD3</td>\n",
       "      <td>0.224953</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.377381</td>\n",
       "      <td>0.249578</td>\n",
       "      <td>0.422257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.285369</td>\n",
       "      <td>0.105275</td>\n",
       "      <td>0.278755</td>\n",
       "      <td>0.104472</td>\n",
       "      <td>0.222126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe  \\\n",
       "0  126  2020-07-02  2020-10-01        TD3   0.138523    0.22561    0.207941   \n",
       "1  189  2020-10-01  2020-12-31       DDPG   0.263081   0.165124    0.334676   \n",
       "2  252  2020-12-31  2021-04-05        TD3   0.224953   0.308174    0.377381   \n",
       "3  315  2021-04-05  2021-07-02        A2C   0.285369   0.105275    0.278755   \n",
       "\n",
       "  SAC Sharpe TD3 Sharpe  \n",
       "0   0.060592   0.314517  \n",
       "1   0.177278    0.30505  \n",
       "2   0.249578   0.422257  \n",
       "3   0.104472   0.222126  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "from env import StockTradingEnv\n",
    "from stable_baselines3.common.logger import configure\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_data.csv')\n",
    "trade = pd.read_csv('./data/trade_data.csv')\n",
    "backtest = pd.read_csv('./data/backtest_data.csv')\n",
    "\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']\n",
    "backtest = backtest.set_index(backtest.columns[0])\n",
    "backtest.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  1.129529642080717\n"
     ]
    }
   ],
   "source": [
    "unique_trade_date = trade.date.unique()\n",
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(config.REBALANCE_WINDOW+config.VALIDATION_WINDOW, len(unique_trade_date)+1,config.REBALANCE_WINDOW):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = pd.concat([df_account_value,temp],ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[config.VALIDATION_WINDOW:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.993548e+05</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>2020-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.006246e+06</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>2020-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.949070e+05</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>2020-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.013812e+06</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>2020-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   1.000000e+06  2020-10-01           NaN  2020-09-30\n",
       "1   9.993548e+05  2020-10-02     -0.000645  2020-10-01\n",
       "2   1.006246e+06  2020-10-05      0.006896  2020-10-02\n",
       "3   9.949070e+05  2020-10-06     -0.011269  2020-10-05\n",
       "4   1.013812e+06  2020-10-07      0.019002  2020-10-06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "import pyfolio\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "from pyfolio import timeseries\n",
    "\n",
    "from helper_function import backtest_stats, get_baseline\n",
    "\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 10000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.163224\n",
      "Cumulative returns     0.163224\n",
      "Annual volatility      0.143522\n",
      "Sharpe ratio           1.129530\n",
      "Calmar ratio           2.096055\n",
      "Stability              0.764828\n",
      "Max drawdown          -0.077872\n",
      "Omega ratio            1.207423\n",
      "Sortino ratio          1.657294\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.102412\n",
      "Daily value at risk   -0.017439\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (251, 8)\n",
      "Annual return          0.237370\n",
      "Cumulative returns     0.236325\n",
      "Annual volatility      0.133856\n",
      "Sharpe ratio           1.664932\n",
      "Calmar ratio           2.930392\n",
      "Stability              0.887390\n",
      "Max drawdown          -0.081003\n",
      "Omega ratio            1.324332\n",
      "Sortino ratio          2.484791\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.118609\n",
      "Daily value at risk   -0.015980\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "df_dji_ = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(df_dji_, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_dji: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>9.951796e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>1.011926e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>9.984132e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>1.017492e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>1.250966e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>1.253532e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>1.233063e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>1.236325e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date           dji\n",
       "0    2020-10-01  1.000000e+07\n",
       "1    2020-10-02  9.951796e+06\n",
       "2    2020-10-05  1.011926e+07\n",
       "3    2020-10-06  9.984132e+06\n",
       "4    2020-10-07  1.017492e+07\n",
       "..          ...           ...\n",
       "247  2021-09-24  1.250966e+07\n",
       "248  2021-09-27  1.253532e+07\n",
       "249  2021-09-28  1.233063e+07\n",
       "250  2021-09-29  1.236325e+07\n",
       "251  2021-09-30           NaN\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df_dji: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02</th>\n",
       "      <td>9.951796e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05</th>\n",
       "      <td>1.011926e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-06</th>\n",
       "      <td>9.984132e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-07</th>\n",
       "      <td>1.017492e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>1.250966e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-27</th>\n",
       "      <td>1.253532e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-28</th>\n",
       "      <td>1.233063e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>1.236325e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dji\n",
       "date                    \n",
       "2020-10-01  1.000000e+07\n",
       "2020-10-02  9.951796e+06\n",
       "2020-10-05  1.011926e+07\n",
       "2020-10-06  9.984132e+06\n",
       "2020-10-07  1.017492e+07\n",
       "...                  ...\n",
       "2021-09-24  1.250966e+07\n",
       "2021-09-27  1.253532e+07\n",
       "2021-09-28  1.233063e+07\n",
       "2021-09-29  1.236325e+07\n",
       "2021-09-30           NaN\n",
       "\n",
       "[252 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dji = pd.DataFrame()\n",
    "df_dji['date'] = df_account_value['date']\n",
    "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_dji.to_csv(\"df_dji.csv\")\n",
    "df_dji = df_dji.set_index(df_dji.columns[0])\n",
    "display(\"df_dji: \", df_dji)\n",
    "df_dji.to_csv(\"df_dji+.csv\")\n",
    "\n",
    "df_account_value.to_csv('df_account_value.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rltrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
