# 2025-10-06

## Focus
Stand up customizable inference workflows that respect live portfolios, add valuation reporting, and refresh evaluation artifacts.

## Context
- Yesterday clarified training timestep accounting and stabilized evaluation traces with explicit trading dates.
- Regeneration of evaluation outputs is pending because the RL environment lacks key dependencies.
- Today will implement inference overrides, plotting, and regressions, then reprovision the tooling to regenerate artifacts.

## Design Notes
- Extend MultiStockTradingEnv.reset to accept portfolio-state overrides (cash, holdings, allocation weights, optional start index) without clobbering history buffers.
- Provide translation helpers that map allocation weights into integer share positions given current prices and leverage constraints.
- Build an inference pipeline that loads checkpoints, applies the overrides, and emits updated state snapshots alongside run metrics.
- Hook valuation curve rendering onto the evaluation/inference path, annotating peak NAV and storing plots next to CSV traces.
- Recreate the RL environment with required dependencies and rerun evaluation scripts to refresh artifacts, then codify monotonic-date expectations through regression tests.

## Next Steps (Sequence)
1. Prototype the portfolio_state API and cover reset overrides with tests.
2. Build the inference CLI and verify it respects arbitrary holding configurations.
3. Add plotting dependencies and script the valuation chart export.
4. Reprovision dependencies, rerun evaluations, and enforce monotonic-date regression coverage.

## Implementation Log
- Integrated portfolio overrides into `MultiStockTradingEnv` with queued state application, symbol index lookup, leverage guardrails, and baseline normalization tweaks (`src/env/multi_stock_env.py`).
- Added customizable inference runner and CLI hooks so checkpoints load with user-specified holdings/allocations via JSON payloads, wiring the overrides through deterministic evaluation (`src/pipelines/evaluation.py`, `src/pipelines/inference.py`).
- Extended the evaluation stack with valuation plot generation (peak NAV annotations, per-episode charts, optional CLI toggle) stored alongside trace artifacts (`src/pipelines/evaluation.py`, `src/pipelines/inference.py`).
- Reprovisioned the RL toolchain on Python 3.13 by installing Torch 2.6.0, Stable-Baselines3 2.7.0, Gymnasium, Matplotlib, PyYAML, and PyTest after working around the pinned Torch 2.4.1 incompatibility; documented the compatible wheel swap for future runs.
- Executed the new inference CLI against `trial_v3_01_ppo` with custom allocations JSON, capturing refreshed traces and valuation plots under `artifacts/results/inference_trial_v3_custom` (`src/pipelines/inference.py`).
- Added regression coverage to ensure evaluation traces remain date-monotonic using a stubbed policy and dummy dataset (`tests/test_evaluation_monotonic.py`).
- Hardened portfolio overrides to demand explicit per-symbol share counts plus cash (no implicit allocations) and backstopped behaviour with new environment tests (`src/env/multi_stock_env.py`, `tests/test_env.py`).
- Wired per-epoch evaluation to drop valuation PNGs beside CSV traces and persist `.pt` checkpoints for every cadence trigger (`src/pipelines/training.py`).
- Ran `debug_two_epoch_v2` training (4,096 steps) to produce two evaluation cycles, check-point drops, and profit charts under `validation_traces/`.
- Generated a full-coverage holdings JSON (every symbol enumerated) and executed inference with the best checkpoint, producing NAV outputs under `artifacts/results/inference_debug_two_epoch`.

## Checklist
- [x] Implement portfolio-state overrides in MultiStockTradingEnv and wire them through the inference pipeline.
- [x] Build the dedicated inference entry point that accepts custom holdings/allocation configs and runs deterministic rollouts from checkpoints.
- [x] Generate and store valuation-curve plots with peak NAV annotations alongside evaluation artifacts once customized inference is in place.
- [x] Recreate the RL environment with required deps (stable_baselines3, pytest) before executing the new inference/evaluation flows.
- [x] Rerun scripts.evaluate (or the new inference CLI) to refresh traces after environment reprovisioning.
- [x] Backfill regression tests enforcing monotonic evaluation dates given the updated metadata path.
- [x] Require explicit per-symbol share counts (including zeros) in portfolio state overrides and validate via automated tests.
- [x] Complete a two-project-epoch debug training run with evaluation-trigger checkpoints and co-located profit charts for each epoch.
- [x] Run inference on the best debug checkpoint using the full holdings manifest and archive outputs/plots.
