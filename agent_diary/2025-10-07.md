# 2025-10-07 — Daily Log

## Focus

Consolidate the finalized execution spec across environment, evaluation, and inference while hardening regression coverage and operator tooling.

## Plan

- Consolidate the post-return, one-way cost pipeline into a single helper, sweep env/eval/inference for legacy paths, and backstop with unit coverage.
- Build the τ limiter property-based suite (randomized weight deltas around the τ boundary) and wire it into CI so failures surface quickly.
- Add VecNormalize parity guards to inference/evaluation loaders, including smoke runs that deliberately mismatch stats to verify the failure path.
- Verify the integerized evaluation flow: ensure `--integerize` hits the rounding layer, log `{q, w_exec, cash_end}`, and rerun the best-checkpoint evaluation to refresh artifacts.
- Promote `configs/ppo.yaml` as canonical, document override/integerization usage plus cost toggles, and add CLI UX guards for holdings JSON (coverage, non-negativity, cash consistency).

## KPIs

- All `pytest` suites (including new τ property tests) complete cleanly in ≤10 minutes.
- Property test executes ≥100 randomized τ scenarios with zero violations logged.
- Latest evaluation artifacts regenerated with integerization enabled; NAV traces diff <1e-6 versus prior deterministic baseline.
- Documentation/CLI updates merged with review notes addressed and zero lint issues.

## Checklist

- [x] Implement shared cost-accounting helper and update env/eval/inference callers.
- [x] Author τ limiter property tests and register them with pytest markers.
- [x] Introduce VecNormalize loader checks plus negative test demonstrating guard behavior.
- [x] Confirm integerized evaluation path emits detailed logs and refreshed `{csv,png,q.json}` bundles.
- [x] Harden CLI holdings validation and add weight→integer helper workflow notes.
- [x] Update `configs/ppo.yaml`, docs, and dependency manifest, then rerun evaluation smoke test.

---

## Decision — Action Space Baseline

We will standardize on **continuous allocation weights** (softmax over assets + cash) as the primary action mode. The environment will convert policy weights to executable share orders via a τ-limiter and integerization layer, debit transaction costs immediately, and expose weight/cost diagnostics in traces.

### Plan

- Add `action_mode` to `EnvironmentConfig` with `"weights"` (default) vs `"shares"` for backwards compatibility.
- Rework `MultiStockTradingEnv.step`:
  - Clamp target weights with `apply_tau_limit`.
  - Convert to integer trades via `integerize_allocations`.
  - Execute trades, apply commission/slippage instantly, update diagnostics.
- Switch rewards to per-step `log(V_t/V_{t-1}) - λ·turnover_t` (post-return NAV basis).
- Update configs/docs/tests to reflect continuous actions, τ default, turnover penalty, and cost assumptions.
- Ensure evaluation/inference paths surface weights/cash fractions and honor `action_mode`.

### KPIs

- PPO training stability: KL drift near target (0.02) with rising log-return rewards and controlled turnover.
- VecNormalize statistics saved/loaded consistently; inference fails fast on mismatch.
- Trace outputs include per-step `{weights, cash_fraction, cost_ratio}` and match deterministic replays.
- pytest suite passes within 15 minutes, including new reward/action tests.

### Checklist

- [x] Implement weight-based action mode with τ limiter and integer execution in `MultiStockTradingEnv`.
- [x] Apply log-return reward and turnover penalty; add unit coverage.
- [x] Refresh configs (`base`, `debug`, `full_training`, `ppo`) with new parameters (τ, λ_turnover, action_mode).
- [x] Document behavior in environment guide and add evaluation/inference clarifications.
- [x] Update tests to cover weight mode, reward computation, and maintain cost assertions.
- [x] Run `python -m pytest` to validate pipeline end-to-end.

---

## Outcomes

- ✅ Environment now operates in weight-based action mode with τ-governed integer execution, per-step log-return rewards, and cumulative episode logging feeding PPO metrics.
- ✅ Evaluation averages three deterministic episodes, records traces/plots only on new peaks, and applies patience-based rollback + early stopping driven by validation reward trends.
- ✅ PPO configs (debug/full) target CPU with `target_kl=0.02`, `n_epochs=2`, `clip_range=0.15`, tightened `tau=0.08`, `lambda_turnover=0.03`, and consistent VecNormalize handling.
- ✅ `python -m pytest` passes in ~15s, and the smoke run `weights_debug_smoke_patience2` validates the new evaluation gating/rollback flow ahead of full training.

---

## Addendum — Implementation Summary (Later on 2025‑10‑07)

What changed today
- Action projection: added `project_to_simplex` and `project_to_l1_ball` (long‑only) and wired into env before τ → integerization. Configurable via `environment.projection.*`. No shorting planned.
- Time feature: introduced `EpisodeProgressWrapper` and enabled via `environment.time_feature_wrapper: true` in configs.
- Training CLI: `--algo` override; agent factory registers PPO/SAC/TD3 and optional sb3‑contrib TQC/RecurrentPPO.
- Statistical reporting: added `compute_sharpe`, `compute_psr`, `compute_dsr`, and moving‑block bootstrap CIs; integrated into evaluation CLI summary and training validation logs (metrics.csv now includes `sharpe, psr0, dsr`).
- Docs: updated architecture/plan/checklist; Agent checklist now mandates a 2‑epoch debug run after changes.

Validation
- Unit/property tests: projections + τ limiter + pipeline all pass.
- Debug train: ran `python -m scripts.train --config configs/debug_two_epoch.yaml --run-name baseline_update_stats_smoke --algo PPO`.
  - Artifacts: `artifacts/runs/20251007-140227_baseline_update_stats_smoke/` with traces, checkpoints, and `metrics.csv` including `sharpe, psr0, dsr`.

Decisions
- Short positions are out of scope for now; projection remains long‑only.
- Keep acceptance based on reward for now; PSR/DSR gating to be considered after selection infra lands.

Backlog (later)
- Selection: Purged K‑Fold + embargo; CPCV evaluation after.
- Acceptance gating: add PSR/DSR thresholds to “best” model updates (configurable).
- EMA/SWA toggles for inference; snapshot ensembles; PB2/PBT after selection metrics stabilize.

---

## Addendum — Data Pipeline Integration (End of Day)

What changed now
- Integrated legacy data builders into the codebase:
  - `src/data/ingest.py` (FDR symbol master + optional KIS daily collector).
  - `src/data/feature_engineering.py` (schema‑compatible indicators for processed CSV).
  - `src/data/selection.py` (top‑N selection + weights; sector‑neutral scoring).
  - `src/data/turbulence.py` (hybrid turbulence — all vs subset — saved separately).
  - `scripts/build_data.py` orchestrates end‑to‑end builds with flags.
- Kept training CSV backward‑compatible with schema; flow ratio columns remain present but NaN‑filled (until a provider is wired).
- Updated docs (architecture/plan/checklist) and README Quickstart for data build.

Validation
- Pytest: `PYTHONPATH=. pytest -q` → 30 passed, ~17s.
- Debug train: `python -m scripts.train --config configs/debug_two_epoch.yaml --run-name baseline_update_data_smoke --algo PPO`.
  - Artifacts: `artifacts/runs/20251007-173749_baseline_update_data_smoke/` with traces and checkpoints present.

Notes
- We will remove `sample_code/` and `sample_code2/` after the new pipeline fully replaces them in workflows.
- Shorting is out of scope; projection stays long‑only.
