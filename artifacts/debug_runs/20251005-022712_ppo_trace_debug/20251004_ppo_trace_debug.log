[2025-10-04 02:27:12] alias=ppo_trace_debug
[2025-10-04 02:27:12] Config snapshot written to config.yaml
[2025-10-04 02:27:12] Initialising training for ppo_trace_debug: epochsâ‰ˆ2, episode_steps=600
[2025-10-04 02:27:23] Episode completed with train_reward=13616785.0880 at step 600
[2025-10-04 02:27:23] Epoch 1 recorded at 600 steps (train/clip_fraction=0.7523, train/clip_range=0.2000, train/entropy_loss=-142.9502, train/explained_variance=-4.3331, train/learning_rate=0.0003, train/loss=-0.1633, train/n_updates=40.0000, train/policy_gradient_loss=-0.1366, train/value_loss=0.0069)
[2025-10-04 02:27:23] Validation @ epoch 1: reward=613545684.2818, std=0.0000
[2025-10-04 02:27:23] New best model saved at best_model_600.zip (reward 613545684.2818)
[2025-10-04 02:27:23] New best model saved at best_model_600.zip (mean reward 613545684.2818)
[2025-10-04 02:27:33] Episode completed with train_reward=-299129.9820 at step 1200
[2025-10-04 02:27:33] Epoch 2 recorded at 1200 steps (train/clip_fraction=0.7344, train/clip_range=0.2000, train/entropy_loss=-142.9546, train/explained_variance=0.7446, train/learning_rate=0.0003, train/loss=-0.1491, train/n_updates=90.0000, train/policy_gradient_loss=-0.1304, train/value_loss=0.0060)
[2025-10-04 02:27:33] Validation @ epoch 2: reward=716346862.6345, std=0.0000
[2025-10-04 02:27:33] New best model saved at best_model_1200.zip (reward 716346862.6345)
[2025-10-04 02:27:33] New best model saved at best_model_1200.zip (mean reward 716346862.6345)
[2025-10-04 02:27:35] Final epoch 3 metrics captured at 1280 steps (train/clip_fraction=0.0234, train/clip_range=0.2000, train/entropy_loss=-142.9919, train/explained_variance=-0.0000, train/learning_rate=0.0003, train/loss=3501855744.0000, train/n_updates=100.0000, train/policy_gradient_loss=0.0012, train/value_loss=6037740684.8000)
[2025-10-04 02:27:35] Final validation reward=698274073.8520, std=0.0000
[2025-10-04 02:27:35] Performance summary:
[2025-10-04 02:27:35] alias=ppo_trace_debug
[2025-10-04 02:27:35] start_timesteps=0
[2025-10-04 02:27:35] epoch_length=600
[2025-10-04 02:27:35] episode_steps=600
[2025-10-04 02:27:35] planned_epochs=2
[2025-10-04 02:27:35] log_interval_epochs=1
[2025-10-04 02:27:35] eval_interval_epochs=1
[2025-10-04 02:27:35] checkpoint_interval_epochs=1
[2025-10-04 02:27:35] last_train_reward=-299129.98197746277
[2025-10-04 02:27:35] last_checkpoint=1200
[2025-10-04 02:27:35] last_valid_reward=698274073.8520241
[2025-10-04 02:27:35] run_completed=True
[2025-10-04 02:27:35] train_timesteps=1200
[2025-10-04 02:27:35] train_epochs=2
[2025-10-04 02:27:35] train_reward=-299129.98197746277
[2025-10-04 02:27:35] valid_reward=698274073.8520241
[2025-10-04 02:27:35] eval_std_reward=0.0
[2025-10-04 02:27:35] final_checkpoint=artifacts\debug_runs\20251004-022712_ppo_trace_debug\checkpoints\step_001200\model.pt
[2025-10-04 02:27:35] date=2025-10-04
[2025-10-04 02:27:35] Training complete
